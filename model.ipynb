{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools==58.0.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (58.0.4)\n",
      "Requirement already satisfied: keras-cv==0.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: absl-py==2.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: alembic==1.13.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.13.3)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.7.0)\n",
      "Collecting ansible==10.5.0 (from -r requirements.txt (line 6))\n",
      "  Using cached ansible-10.5.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting ansible-core==2.17.5 (from -r requirements.txt (line 7))\n",
      "  Using cached ansible_core-2.17.5-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.4.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.6.3)\n",
      "Requirement already satisfied: attrs==23.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.12.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (4.12.3)\n",
      "Requirement already satisfied: promise==2.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.3)\n",
      "Requirement already satisfied: bleach==6.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (6.1.0)\n",
      "Requirement already satisfied: blinker==1.8.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (1.8.2)\n",
      "Collecting boto3==1.35.44 (from -r requirements.txt (line 15))\n",
      "  Using cached boto3-1.35.44-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore==1.35.44 (from -r requirements.txt (line 16))\n",
      "  Using cached botocore-1.35.44-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: cachetools==5.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (5.5.0)\n",
      "Requirement already satisfied: certifi==2024.8.30 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (2024.8.30)\n",
      "Requirement already satisfied: cffi==1.17.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 19)) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 20)) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 21)) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (2.2.1)\n",
      "Requirement already satisfied: colorama==0.4.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 23)) (0.4.6)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 25)) (1.3.0)\n",
      "Collecting cryptography==43.0.3 (from -r requirements.txt (line 26))\n",
      "  Using cached cryptography-43.0.3-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: cycler==0.12.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (0.12.1)\n",
      "Requirement already satisfied: databricks-sdk==0.35.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.35.0)\n",
      "Collecting debugpy==1.8.5 (from -r requirements.txt (line 29))\n",
      "  Using cached debugpy-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 30)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 31)) (0.7.1)\n",
      "Requirement already satisfied: Deprecated==1.2.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 32)) (1.2.14)\n",
      "Collecting dill==0.3.9 (from -r requirements.txt (line 33))\n",
      "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: dm-tree==0.1.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 34)) (0.1.8)\n",
      "Requirement already satisfied: docker==7.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 35)) (7.1.0)\n",
      "Requirement already satisfied: docstring_parser==0.16 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 36)) (0.16)\n",
      "Requirement already satisfied: etils==1.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 37)) (1.10.0)\n",
      "Requirement already satisfied: executing==2.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 38)) (2.1.0)\n",
      "Requirement already satisfied: fastjsonschema==2.20.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 39)) (2.20.0)\n",
      "Requirement already satisfied: Flask==3.0.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 40)) (3.0.3)\n",
      "Requirement already satisfied: flatbuffers==24.3.25 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 41)) (24.3.25)\n",
      "Collecting fonttools==4.53.1 (from -r requirements.txt (line 42))\n",
      "  Using cached fonttools-4.53.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (162 kB)\n",
      "Requirement already satisfied: fsspec==2024.9.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 43)) (2024.9.0)\n",
      "Requirement already satisfied: gast==0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 44)) (0.6.0)\n",
      "Requirement already satisfied: gitdb==4.0.11 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 45)) (4.0.11)\n",
      "Requirement already satisfied: GitPython==3.1.43 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 46)) (3.1.43)\n",
      "Requirement already satisfied: google-auth==2.35.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 47)) (2.35.0)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 48)) (0.2.0)\n",
      "Collecting googleapis-common-protos==1.65.0 (from -r requirements.txt (line 49))\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphene==3.4 (from -r requirements.txt (line 50))\n",
      "  Using cached graphene-3.4-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: graphql-core==3.2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 51)) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay==3.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 52)) (3.2.0)\n",
      "Requirement already satisfied: greenlet==3.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 53)) (3.1.1)\n",
      "Requirement already satisfied: grpcio==1.66.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 54)) (1.66.1)\n",
      "Requirement already satisfied: h5py==3.11.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 55)) (3.11.0)\n",
      "Requirement already satisfied: idna==3.10 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 56)) (3.10)\n",
      "Requirement already satisfied: immutabledict==4.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 57)) (4.2.0)\n",
      "Requirement already satisfied: importlib-metadata==6.11.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 58)) (6.11.0)\n",
      "Requirement already satisfied: importlib_resources==6.4.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 59)) (6.4.5)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 60)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.27.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 61)) (8.27.0)\n",
      "Requirement already satisfied: itsdangerous==2.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 62)) (2.2.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 63)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 64)) (3.1.4)\n",
      "Requirement already satisfied: jmespath==1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 65)) (1.0.1)\n",
      "Requirement already satisfied: joblib==1.4.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 66)) (1.4.2)\n",
      "Requirement already satisfied: jsonschema==4.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 67)) (4.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2023.12.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 68)) (2023.12.1)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 69)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 70)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 71)) (0.3.0)\n",
      "Requirement already satisfied: kagglehub==0.3.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 72)) (0.3.3)\n",
      "Requirement already satisfied: keras==3.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 73)) (3.5.0)\n",
      "Requirement already satisfied: keras-core==0.1.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 74)) (0.1.7)\n",
      "Requirement already satisfied: kiwisolver==1.4.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 75)) (1.4.7)\n",
      "Requirement already satisfied: libclang==18.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 76)) (18.1.1)\n",
      "Requirement already satisfied: Mako==1.3.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 77)) (1.3.5)\n",
      "Requirement already satisfied: Markdown==3.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 78)) (3.7)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 79)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 80)) (2.1.5)\n",
      "Collecting matplotlib==3.8.4 (from -r requirements.txt (line 81))\n",
      "  Using cached matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 82)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 83)) (0.1.2)\n",
      "Requirement already satisfied: mistune==3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 84)) (3.0.2)\n",
      "Collecting ml-dtypes==0.4.1 (from -r requirements.txt (line 85))\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: mlflow==2.17.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 86)) (2.17.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.17.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 87)) (2.17.0)\n",
      "Requirement already satisfied: mock==4.0.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 88)) (4.0.3)\n",
      "Collecting multiprocess==0.70.17 (from -r requirements.txt (line 89))\n",
      "  Using cached multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: namex==0.0.8 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 90)) (0.0.8)\n",
      "Requirement already satisfied: nbclient==0.10.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 91)) (0.10.0)\n",
      "Requirement already satisfied: nbconvert==7.16.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 92)) (7.16.4)\n",
      "Requirement already satisfied: nbformat==5.10.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 93)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 94)) (1.6.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 95)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python==4.10.0.84 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 96)) (4.10.0.84)\n",
      "Requirement already satisfied: opentelemetry-api==1.27.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 97)) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.27.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 98)) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 99)) (0.48b0)\n",
      "Collecting opt-einsum==3.3.0 (from -r requirements.txt (line 100))\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: optree==0.12.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 101)) (0.12.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting packaging==24.1 (from -r requirements.txt (line 102))\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pandas==2.2.2 (from -r requirements.txt (line 103))\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pandocfilters==1.5.1 (from -r requirements.txt (line 104))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 105)) (0.8.4)\n",
      "Collecting pathos==0.3.3 (from -r requirements.txt (line 106))\n",
      "  Using cached pathos-0.3.3-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow==10.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 107)) (10.4.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 108)) (4.3.6)\n",
      "Collecting pox==0.3.5 (from -r requirements.txt (line 109))\n",
      "  Using cached pox-0.3.5-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting ppft==1.7.6.9 (from -r requirements.txt (line 110))\n",
      "  Using cached ppft-1.7.6.9-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting prompt_toolkit==3.0.47 (from -r requirements.txt (line 111))\n",
      "  Using cached prompt_toolkit-3.0.47-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting protobuf==4.25.5 (from -r requirements.txt (line 112))\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: psutil==6.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 113)) (6.0.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 114)) (0.2.3)\n",
      "Requirement already satisfied: pyarrow==17.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 115)) (17.0.0)\n",
      "Requirement already satisfied: pyasn1==0.6.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 116)) (0.6.1)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 117)) (0.4.1)\n",
      "Requirement already satisfied: pycparser==2.22 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 118)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.9.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 119)) (2.9.2)\n",
      "Requirement already satisfied: pydantic_core==2.23.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 120)) (2.23.4)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 121)) (2.18.0)\n",
      "Requirement already satisfied: pyparsing==3.1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 122)) (3.1.4)\n",
      "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 123))\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: pytz==2024.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from -r requirements.txt (line 124)) (2024.2)\n",
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 11.0.0a1 Requires-Python >=3.11; 11.0.0a2 Requires-Python >=3.11; 2.18.0b1 Requires-Python >=3.11; 2.18.0rc1 Requires-Python >=3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==306 (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==306\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:11:53.484067: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-26 16:11:53.712757: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-26 16:11:53.714561: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 16:11:54.086868: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-26 16:11:55.926247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import boto3\n",
    "import sagemaker\n",
    "import fsspec\n",
    "import gc\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_recall_curve, roc_auc_score, auc, make_scorer, roc_curve\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "import random\n",
    "from collections.abc import Generator\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fraction of data to use (CEDRIC can reduce to speed up tests... go to 0.02!)\n",
    "train_frac_to_use = 1   #Reduce training data to this fraction. Set to \"1\" to use all data.\n",
    "val_frac_to_use = 1     #Reduce validation data to this fraction. Set to \"1\" to use all data.\n",
    "test_frac_to_use = 1     #Reduce validation data to this fraction. Set to \"1\" to use all data.\n",
    "\n",
    "#Memory management (Speeds up model. Need 16GB of RAM for validation data and likely 64GB of RAM for training data)\n",
    "save_train_in_memory = False #Place all training data directly in memory to accelerate the validation step in the model\n",
    "save_val_in_memory = True  #Place all validation data directly in memory to accelerate the validation step in the model\n",
    "\n",
    "#Saves management (weights only, all other saves are performed by default)\n",
    "wt_save_freq = 1 #Save model weights every X epochs. Set to 0 for no saving during epochs.\n",
    "final_wt_save = True\n",
    "\n",
    "#Splitting of train-validate-test\n",
    "split_seed = 88                 #Seed to use for all train-validate-test splits, including the split of reserved Target=1 data\n",
    "reserve_frac = 0.1              #Fraction of total original data of Target = 1 (reserved for use in validation data)\n",
    "test_frac = 0.2                 #Fraction of total original data, excluding the reserved fraction, to use as the test data\n",
    "nb_of_augments = 100            #Number of augments to perform on Target = 1 images in train-validate sets\n",
    "val_frac = 0.33                 #Fraction of augmented train-validate list to use as the validation data. The rest becomes the training data.\n",
    "nb_of_augments_reserved = 15    #Number of augmentations to perform on reserved validation fraction (Target = 1). Note: this is added to the validation data.\n",
    "reduce_frac = 0.8               #Fraction of Target = 0 samples to remove from the validation data (improves balance)\n",
    "\n",
    "#Image resizing: all images are adjusted to this size so the the CNN receives same number of data points each time\n",
    "imgSize = 100\n",
    "\n",
    "#Hair removal (applies to all images)\n",
    "apply_hair_removal = True\n",
    "\n",
    "#Batch sizes\n",
    "train_batch_size = 32\n",
    "val_batch_size = 32\n",
    "test_batch_size = 32\n",
    "\n",
    "#Choice of model\n",
    "#0 = in series (convolutions on images followed by concatenation with metadata followed by deep NN layers, followed by final layer)\n",
    "#1 = in parallel (metadata run separately in deep NN layers, then concatenated with results from image convolutions, followed by final layer)\n",
    "model_choice = 1\n",
    "\n",
    "#Neural Network Parameters\n",
    "nb_neurons_hidden_layers = 36  #Number of neurons in each hidden layer\n",
    "dropout = 0.1                  #Fraction of neurons to drop\n",
    "\n",
    "#Optimizer Parameters\n",
    "learning_rate = 0.005           #Initial learning rate for the Adam optimizer\n",
    "\n",
    "#Epoch management (CEDRIC... reduce number of epochs if needed)\n",
    "nb_epochs = 20\n",
    "early_break = False #End early in case of increasing validation loss\n",
    "\n",
    "#Debugging\n",
    "cheat = False #add the target to the metadata so the model can precisely learn the correct response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) IMPORT DATA & DECLARE SAVES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Declare file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Local copy hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier /home/ec2-user/SageMaker/train-image.hdf5 existe déjà. Téléchargement sauté.\n"
     ]
    }
   ],
   "source": [
    "# Configuration S3 et chemin local\n",
    "session = sagemaker.Session()\n",
    "bucket = 'images-projet-deep-learning-01'\n",
    "hdf5_key = 'train-image.hdf5'\n",
    "local_hdf5_path = os.path.join(os.getcwd(), 'train-image.hdf5')\n",
    "\n",
    "# Vérifie si le fichier est déjà présent\n",
    "if os.path.exists(local_hdf5_path):\n",
    "    print(f\"Le fichier {local_hdf5_path} existe déjà. Téléchargement sauté.\")\n",
    "else:\n",
    "    # Télécharger le fichier HDF5 depuis S3\n",
    "    print(f\"Téléchargement de {hdf5_key} depuis S3 vers {local_hdf5_path}...\")\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file(bucket, hdf5_key, local_hdf5_path)\n",
    "    print(\"Téléchargement terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/results/\n",
      "/home/ec2-user/SageMaker/results/test_results_save.csv\n"
     ]
    }
   ],
   "source": [
    "#IMPORT FILES\n",
    "#Directory for data files - FULL DATA\n",
    "dataPath = \"s3://images-projet-deep-learning-01/\" #slash required at end\n",
    "#Metadata file paths\n",
    "metaPath = dataPath + \"cleaned-metadata.csv\"\n",
    "#Image file path\n",
    "hdf5_file = \"train-image.hdf5\"\n",
    "\n",
    "#SAVE FILES\n",
    "#Directory for saved files \n",
    "# savePath = \"s3://dsti-a23-deep-learning-outputs-01/\" #slash required at end\n",
    "folder = '/results/'\n",
    "savePath = os.getcwd() + folder\n",
    "#Model results\n",
    "modelResPath = savePath + \"model_results_save.csv\"\n",
    "#Test ids (isic_ids + target + mod_toggle)\n",
    "test_ids_Path = savePath + \"test_ids.csv\"\n",
    "#Test results (y_test, y_pred)\n",
    "testResPath = savePath + \"test_results_save.csv\"\n",
    "\n",
    "print(savePath)\n",
    "print(testResPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Load metadata from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/fsspec/registry.py:279: UserWarning: Your installed version of s3fs is very old and known to cause\n",
      "severe performance issues, see also https://github.com/dask/dask/issues/10276\n",
      "\n",
      "To fix, you should specify a lower version bound on s3fs, or\n",
      "update the current installation.\n",
      "\n",
      "  warnings.warn(s3_msg)\n"
     ]
    }
   ],
   "source": [
    "#Import metadata from file\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                         0\n",
      "target                          0\n",
      "clin_size_long_diam_mm          0\n",
      "tbp_lv_A                        0\n",
      "tbp_lv_Aext                     0\n",
      "tbp_lv_B                        0\n",
      "tbp_lv_H                        0\n",
      "tbp_lv_Hext                     0\n",
      "tbp_lv_areaMM2                  0\n",
      "tbp_lv_area_perim_ratio         0\n",
      "tbp_lv_color_std_mean           0\n",
      "tbp_lv_deltaB                   0\n",
      "tbp_lv_deltaLBnorm              0\n",
      "tbp_lv_minorAxisMM              0\n",
      "tbp_lv_norm_color               0\n",
      "tbp_lv_perimeterMM              0\n",
      "tbp_lv_radial_color_std_max     0\n",
      "tbp_lv_stdLExt                  0\n",
      "tbp_lv_y                        0\n",
      "tbp_lv_dnn_lesion_confidence    0\n",
      "normalized_contrast             0\n",
      "size_to_area_ratio              0\n",
      "luminance_ratio                 0\n",
      "chroma_B_ratio                  0\n",
      "category_Head & Neck            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activate for debugging of the predict function\n",
    "if cheat:\n",
    "    metadata[\"target_cheat\"] = metadata[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the total number of features in the metadata (subtract 'isic_id' and 'target')\n",
    "num_features = len(metadata.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Train, Validate, Test Split + Preparation of Data Augmentation\n",
    "1. Make two separate lists of isic_ids for target=0 and target=1. Transform into tuples (isic_id, target, mod toggle). Base data has mod toggle = 0, meaning no adjustment will be made.\n",
    "2. Reserve 10% of target = 1 for validate\n",
    "3. Split into train-validate & test on both lists (0 and 1). Take the test lists (0 and 1), concatenate and shuffle them\n",
    "4. Create augmentation preparation function for target = 1: mod toggle = strictly positive integer (this adds more isic_ids to the list, with mod toggle non zero))\n",
    "5. Run augmentation preparation function on train-validate and the reserved validation data: mod toggle = strictly positive integer\n",
    "6. Split train-validate on both lists (0 and 1)\n",
    "7. Reduce the validation data on target = 0 by value specified in reduce_frac\n",
    "8. Concatenate and shuffle the train lists and validation lists\n",
    "9. Limit training and validation data to speed up training (take only fraction of prepared lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Make two separate lists of isic_ids for target=0 (mod_toggle = -1) and target=1 (mod_toggle = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ids with target = 0: 381533\n",
      "Total ids with target = 1: 381\n"
     ]
    }
   ],
   "source": [
    "#Make a list of isic_ids for each target value (0 and 1)\n",
    "isic_id_target_0 = metadata[metadata['target'] == 0]['isic_id'].tolist()\n",
    "isic_id_target_1 = metadata[metadata['target'] == 1]['isic_id'].tolist()\n",
    "\n",
    "#Retrieve dataframe with isic id and target\n",
    "temp_0 = metadata[metadata[\"isic_id\"].isin(isic_id_target_0)].loc[:,[\"isic_id\",\"target\"]]\n",
    "temp_1 = metadata[metadata[\"isic_id\"].isin(isic_id_target_1)].loc[:,[\"isic_id\",\"target\"]]\n",
    "\n",
    "#Convert into list of tuples... this makes it compatible with data augmentations\n",
    "#Form: (isic_id, target, mod toggle)\n",
    "isic_id_target_0 = list(zip(temp_0.iloc[:,0], temp_0.iloc[:,1], [-1]*len(temp_0)))\n",
    "isic_id_target_1 = list(zip(temp_1.iloc[:,0], temp_1.iloc[:,1], [0]*len(temp_1)))\n",
    "\n",
    "#Delete temporary dataframes (the original metadata dataframe is untouched)\n",
    "del temp_0\n",
    "del temp_1\n",
    "\n",
    "#Count the number of occurrences for each target value\n",
    "print(\"Total ids with target = 0:\", len(isic_id_target_0))\n",
    "print(\"Total ids with target = 1:\", len(isic_id_target_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Reserve 10% of target = 1 for validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ids with target = 0: 381533\n",
      "Total ids with target = 1: 342\n",
      "Total reserved target = 1: 39\n"
     ]
    }
   ],
   "source": [
    "#Keep 10% of isic_Id of target=1 without duplication\n",
    "isic_id_target_1, isic_id_target_1_reserved = train_test_split(isic_id_target_1, test_size = reserve_frac, random_state=split_seed, shuffle=False)\n",
    "\n",
    "#Count the number of occurrences for each target value (AFTER RESERVATION)\n",
    "print(\"Total ids with target = 0:\", len(isic_id_target_0))\n",
    "print(\"Total ids with target = 1:\", len(isic_id_target_1))\n",
    "print(\"Total reserved target = 1:\", len(isic_id_target_1_reserved))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Split into train-validate & test on both lists (0 and 1). Take the test lists (0 and 1), concatenate and shuffle them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split out the test ids\n",
    "trainval_0, test_0 = train_test_split(isic_id_target_0, test_size = test_frac, random_state=split_seed, shuffle=True)\n",
    "trainval_1, test_1 = train_test_split(isic_id_target_1, test_size = test_frac, random_state=split_seed, shuffle=True)\n",
    "\n",
    "test_ids = test_0 + test_1\n",
    "np.random.shuffle(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Create augmentation preparation function for target = 1: mod toggle = strictly positive integer\n",
    "(this adds more isic_ids to the list, with mod toggle non zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a list containing augmentation toggles. Apply only to training and validation sets.\n",
    "def augment_prep(tuple_list, nb_of_augments = 30, shuffle_seed=None):\n",
    "    augment_list = []\n",
    "    \n",
    "    #If augmentation is desired, then the mod toggle is a strictly positive integer\n",
    "    augment_list = [(item[0], item[1], i) for item in tuple_list for i in range(1, nb_of_augments + 1)]\n",
    "    \n",
    "    #Shuffle the list\n",
    "    augment_list.extend(tuple_list)\n",
    "    np.random.seed(shuffle_seed)\n",
    "    np.random.shuffle(augment_list)\n",
    "\n",
    "    return augment_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 - Run augmentation preparation function on train-validate and the reserved validation data: mod toggle = strictly positive integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augment the training and validation list\n",
    "trainval_1 = augment_prep(trainval_1, nb_of_augments=nb_of_augments, shuffle_seed=50)\n",
    "\n",
    "#Duplicate the reserved training data\n",
    "reserved_1 = augment_prep(isic_id_target_1_reserved, nb_of_augments=nb_of_augments_reserved, shuffle_seed=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 - Split train-validate on both lists (0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and validation lists\n",
    "train_0, val_0 = train_test_split(trainval_0, test_size = val_frac, random_state=split_seed, shuffle=True)\n",
    "train_1, val_1 = train_test_split(trainval_1, test_size = val_frac, random_state=split_seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 - Reduce the validation data on target = 0 by value specified in reduce_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the validation data of type Target = 0\n",
    "nb_samples = int((1 - reduce_frac) * len(val_0))\n",
    "val_0 = random.sample(val_0, nb_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 - Concatenate and shuffle the train and validation lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate\n",
    "train_ids=train_0.copy()\n",
    "train_ids.extend(train_1)\n",
    "val_ids=list(itertools.chain(val_0, val_1, reserved_1))\n",
    "\n",
    "#Shuffle\n",
    "np.random.seed(60)\n",
    "np.random.shuffle(train_ids)\n",
    "np.random.shuffle(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Validate/Test Counts: 222974 / 29868 / 76376\n",
      "Train/Validate/Test Fractions: 0.68 / 0.09 / 0.23\n",
      "Proportion of Target = 1 in training data: 0.08284822445666311\n",
      "Proportion of Target = 1 in validation data: 0.3255658229543324\n",
      "Proportion of Target = 1 in test data: 0.0009034251597360428\n"
     ]
    }
   ],
   "source": [
    "#Calculate the proportaion of Target=1 in each set (training, validation, test)\n",
    "def calc_frac_target1(ids):\n",
    "    return sum([item[1] for item in ids]) / len(ids)\n",
    "\n",
    "tot_samples = len(train_ids) + len(val_ids) + len(test_ids)\n",
    "\n",
    "print(\"Train/Validate/Test Counts:\", len(train_ids), \"/\", len(val_ids), \"/\", len(test_ids))\n",
    "print(\"Train/Validate/Test Fractions:\", round(len(train_ids)/tot_samples,2), \"/\", round(len(val_ids)/tot_samples,2), \"/\", round(len(test_ids)/tot_samples,2))\n",
    "print(\"Proportion of Target = 1 in training data:\", calc_frac_target1(train_ids))\n",
    "print(\"Proportion of Target = 1 in validation data:\", calc_frac_target1(val_ids))\n",
    "print(\"Proportion of Target = 1 in test data:\", calc_frac_target1(test_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 - Limit training and validation data to speed up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ids length before: 222974\n",
      "Train ids length after: 222974\n",
      "Validate ids length before: 29868\n",
      "Validate ids length after: 29868\n",
      "Test ids length before: 76376\n",
      "Test ids length after: 76376\n"
     ]
    }
   ],
   "source": [
    "#Choose a portion of TRAINING ids to load into memory\n",
    "def take_fewer_samples(ids, frac_to_use, seed):\n",
    "    if frac_to_use < 1 and frac_to_use > 0:\n",
    "        random.seed(seed)\n",
    "        k = int(frac_to_use * len(ids))\n",
    "        ids_short = random.choices(ids, k=k)\n",
    "        return ids_short\n",
    "    return ids\n",
    "\n",
    "print(\"Train ids length before:\", len(train_ids))\n",
    "train_ids = take_fewer_samples(train_ids, train_frac_to_use, seed=12)\n",
    "print(\"Train ids length after:\", len(train_ids))\n",
    "\n",
    "print(\"Validate ids length before:\", len(val_ids))\n",
    "val_ids = take_fewer_samples(val_ids, val_frac_to_use, seed=12)\n",
    "print(\"Validate ids length after:\", len(val_ids))\n",
    "\n",
    "print(\"Test ids length before:\", len(test_ids))\n",
    "test_ids = take_fewer_samples(test_ids, test_frac_to_use, seed=12)\n",
    "print(\"Test ids length after:\", len(test_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Augmentation functions (used during dataset creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hair_removal(image, crop_pixels=10):\n",
    "    height_pixels = len(image)  # Image rows\n",
    "    width_pixels = len(image[0])  # Image columns\n",
    "\n",
    "    # Image cropping\n",
    "    height = [crop_pixels, height_pixels - crop_pixels]\n",
    "    width = [crop_pixels, width_pixels - crop_pixels]\n",
    "    img = image[height[0]:height[1], width[0]:width[1]]\n",
    "\n",
    "    # Gray scale\n",
    "    grayScale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Black hat filter\n",
    "    kernel = cv2.getStructuringElement(1, (9, 9))\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "    # Gaussian filter\n",
    "    bhg = cv2.GaussianBlur(blackhat, (3, 3), cv2.BORDER_DEFAULT)\n",
    "    # Binary thresholding (MASK)\n",
    "    ret, mask = cv2.threshold(bhg, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Replace pixels of the mask\n",
    "    dst = cv2.inpaint(img, mask, 6, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation function\n",
    "def augment_image(image, mod_toggle, is_training=False):\n",
    "    \"\"\"\n",
    "    Apply a series of augmentations to create diverse variations of the input image.\n",
    "    Includes random flips, rotations, brightness adjustments, and other transformations.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    if is_training==True:\n",
    "        #Cutout values\n",
    "        height_factor_cut=(0.02, 0.06)\n",
    "        width_factor_cut=(0.02, 0.06)\n",
    "        random_cutout = keras_cv.layers.RandomCutout(height_factor=height_factor_cut, width_factor=width_factor_cut)\n",
    "        #Brightness values\n",
    "        min_delta_bright=0.05\n",
    "        max_delta_bright=0.25\n",
    "        #Saturation values\n",
    "        weak_sat_low=0.7\n",
    "        weak_sat_high=0.95\n",
    "        strong_sat_low=1.05\n",
    "        strong_sat_high=1.8\n",
    "        #Contrast values\n",
    "        weak_cont_low=0.7\n",
    "        weak_cont_high=0.95\n",
    "        strong_cont_low=1.05\n",
    "        strong_cont_high=1.8\n",
    "\n",
    "    else:\n",
    "        #Brightness values\n",
    "        min_delta_bright=0.05\n",
    "        max_delta_bright=0.15\n",
    "        #Saturation values\n",
    "        weak_sat_low=0.8\n",
    "        weak_sat_high=0.95\n",
    "        strong_sat_low=1.05\n",
    "        strong_sat_high=1.2\n",
    "        #Contrast values\n",
    "        weak_cont_low=0.8\n",
    "        weak_cont_high=0.95\n",
    "        strong_cont_low=1.05\n",
    "        strong_cont_high=1.2\n",
    "\n",
    "    #List of base augmentations\n",
    "    base_augments = [\n",
    "        lambda img: tf.image.flip_left_right(img),\n",
    "        lambda img: tf.image.flip_up_down(img),\n",
    "        lambda img: tf.image.rot90(img, k=1),\n",
    "        lambda img: tf.image.rot90(img, k=2),\n",
    "        lambda img: tf.image.rot90(img, k=3),\n",
    "        lambda img: random_cutout(img)\n",
    "    ]\n",
    "\n",
    "    #List of other augmentations that can be performed multiple times\n",
    "    other_augments = [\n",
    "        lambda img: tf.image.adjust_brightness(img, -random.uniform(min_delta_bright, max_delta_bright)),\n",
    "        lambda img: tf.image.adjust_brightness(img, random.uniform(min_delta_bright, max_delta_bright)),\n",
    "        lambda img: tf.image.random_contrast(img, lower=weak_cont_low, upper=weak_cont_high),\n",
    "        lambda img: tf.image.random_contrast(img, lower=strong_cont_low, upper=strong_cont_high),\n",
    "        lambda img: tf.image.random_saturation(img, lower=weak_sat_low, upper=weak_sat_high),\n",
    "        lambda img: tf.image.random_saturation(img, lower=strong_sat_low, upper=strong_sat_high)\n",
    "    ]\n",
    "\n",
    "    #Select augmentations to use based on whether it is training data or not\n",
    "    if is_training:\n",
    "        base_augments = base_augments\n",
    "        other_augments = other_augments \n",
    "    else:\n",
    "        base_selection = [0,1]  #Positions of the augmentations to use in the base_augments list\n",
    "        base_augments = [base_augments[i] for i in base_selection]\n",
    "        other_augments = other_augments\n",
    "\n",
    "    #Engage the augment based on the mod_toggle. The base_augments are always done first.\n",
    "    nb_base_aug = len(base_augments)\n",
    "    \n",
    "    if mod_toggle <= nb_base_aug and mod_toggle > 0:\n",
    "        augmentation = base_augments[mod_toggle - 1] #Mod toggles start at 1\n",
    "        image = augmentation(image)\n",
    "    else:\n",
    "        augmentation = random.choice(other_augments)\n",
    "        image = augmentation(image)\n",
    "        #Apply a second transformation with a certain probability\n",
    "        if tf.random.uniform([]) < 0.85:\n",
    "            augmentation2 = random.choice(base_augments)\n",
    "            image = augmentation2(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid_try = \"ISIC_5675460\"\\nwith h5py.File(hdf5_file, \\'r\\') as h5file:\\n    img_try = np.array(Image.open(io.BytesIO(h5file[id_try][()])))\\n\\nfor mod_toggle in range(500):\\n    img = hair_removal(img_try)\\n    img = cv2.resize(img, (100, 100), interpolation= cv2.INTER_AREA)\\n    augment_image(img, mod_toggle, is_training=True)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTING OF AUGMENT_IMAGE FUNCTION\n",
    "\"\"\"\n",
    "id_try = \"ISIC_5675460\"\n",
    "with h5py.File(hdf5_file, 'r') as h5file:\n",
    "    img_try = np.array(Image.open(io.BytesIO(h5file[id_try][()])))\n",
    "\n",
    "for mod_toggle in range(500):\n",
    "    img = hair_removal(img_try)\n",
    "    img = cv2.resize(img, (100, 100), interpolation= cv2.INTER_AREA)\n",
    "    augment_image(img, mod_toggle, is_training=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid_try = \"ISIC_5675460\"\\nwith h5py.File(hdf5_file, \\'r\\') as h5file:\\n    img_try = np.array(Image.open(io.BytesIO(h5file[id_try][()])))\\n\\nheight_factor_cut=(0.02, 0.06)\\nwidth_factor_cut=(0.02, 0.06)\\nrandom_cutout = keras_cv.layers.RandomCutout(height_factor=height_factor_cut, width_factor=width_factor_cut)\\n\\nbase_augments = [\\n    lambda img: img,\\n    lambda img: tf.image.flip_left_right(img),\\n    lambda img: tf.image.flip_up_down(img),\\n    lambda img: tf.image.rot90(img, k=1),\\n    lambda img: tf.image.rot90(img, k=2),\\n    lambda img: tf.image.rot90(img, k=3),\\n    lambda img: random_cutout(img).numpy().astype(int),\\n]\\n\\nimages = []\\nfor augmentation in base_augments:\\n    image = augmentation(img_try)\\n    images.append(image)\\n\\n#Show the images\\nfor image in images:\\n    plt.imshow(image, interpolation=None)\\n    plt.grid(None)\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING OF BASE AUGMENTS\n",
    "\"\"\"\n",
    "id_try = \"ISIC_5675460\"\n",
    "with h5py.File(hdf5_file, 'r') as h5file:\n",
    "    img_try = np.array(Image.open(io.BytesIO(h5file[id_try][()])))\n",
    "\n",
    "height_factor_cut=(0.02, 0.06)\n",
    "width_factor_cut=(0.02, 0.06)\n",
    "random_cutout = keras_cv.layers.RandomCutout(height_factor=height_factor_cut, width_factor=width_factor_cut)\n",
    "\n",
    "base_augments = [\n",
    "    lambda img: img,\n",
    "    lambda img: tf.image.flip_left_right(img),\n",
    "    lambda img: tf.image.flip_up_down(img),\n",
    "    lambda img: tf.image.rot90(img, k=1),\n",
    "    lambda img: tf.image.rot90(img, k=2),\n",
    "    lambda img: tf.image.rot90(img, k=3),\n",
    "    lambda img: random_cutout(img).numpy().astype(int),\n",
    "]\n",
    "\n",
    "images = []\n",
    "for augmentation in base_augments:\n",
    "    image = augmentation(img_try)\n",
    "    images.append(image)\n",
    "\n",
    "#Show the images\n",
    "for image in images:\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid_try = \"ISIC_5675460\"\\nwith h5py.File(hdf5_file, \\'r\\') as h5file:\\n    img_try = np.array(Image.open(io.BytesIO(h5file[id_try][()])))\\n\\n#Brightness values\\nmin_delta_bright=0.05\\nmax_delta_bright=0.25\\n#Saturation values\\nweak_sat_low=0.7\\nweak_sat_high=0.95\\nstrong_sat_low=1.05\\nstrong_sat_high=1.8\\n#Contrast values\\nweak_cont_low=0.7\\nweak_cont_high=0.95\\nstrong_cont_low=1.05\\nstrong_cont_high=1.8\\n\\n#List of other augmentations that can be performed multiple times\\nother_augments = [\\n    lambda img: tf.image.adjust_brightness(img, -random.uniform(min_delta_bright, max_delta_bright)),\\n    lambda img: tf.image.adjust_brightness(img, random.uniform(min_delta_bright, max_delta_bright)),\\n    lambda img: tf.image.random_contrast(img, lower=weak_cont_low, upper=weak_cont_high),\\n    lambda img: tf.image.random_contrast(img, lower=strong_cont_low, upper=strong_cont_high),\\n    lambda img: tf.image.random_saturation(img, lower=weak_sat_low, upper=weak_sat_high),\\n    lambda img: tf.image.random_saturation(img, lower=strong_sat_low, upper=strong_sat_high)\\n]\\n\\nimages = []\\nfor augmentation in other_augments:\\n    image = augmentation(img_try)\\n    if tf.random.uniform([]) < 1:\\n        augmentation2 = random.choice(base_augments)\\n        image = augmentation2(image)\\n    images.append(image)\\n\\n#Show the images\\nfor image in images:\\n    plt.imshow(image, interpolation=None)\\n    plt.grid(None)\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TESTING OF OTHER AUGMENTS\n",
    "\"\"\"\n",
    "id_try = \"ISIC_5675460\"\n",
    "with h5py.File(hdf5_file, 'r') as h5file:\n",
    "    img_try = np.array(Image.open(io.BytesIO(h5file[id_try][()])))\n",
    "\n",
    "#Brightness values\n",
    "min_delta_bright=0.05\n",
    "max_delta_bright=0.25\n",
    "#Saturation values\n",
    "weak_sat_low=0.7\n",
    "weak_sat_high=0.95\n",
    "strong_sat_low=1.05\n",
    "strong_sat_high=1.8\n",
    "#Contrast values\n",
    "weak_cont_low=0.7\n",
    "weak_cont_high=0.95\n",
    "strong_cont_low=1.05\n",
    "strong_cont_high=1.8\n",
    "\n",
    "#List of other augmentations that can be performed multiple times\n",
    "other_augments = [\n",
    "    lambda img: tf.image.adjust_brightness(img, -random.uniform(min_delta_bright, max_delta_bright)),\n",
    "    lambda img: tf.image.adjust_brightness(img, random.uniform(min_delta_bright, max_delta_bright)),\n",
    "    lambda img: tf.image.random_contrast(img, lower=weak_cont_low, upper=weak_cont_high),\n",
    "    lambda img: tf.image.random_contrast(img, lower=strong_cont_low, upper=strong_cont_high),\n",
    "    lambda img: tf.image.random_saturation(img, lower=weak_sat_low, upper=weak_sat_high),\n",
    "    lambda img: tf.image.random_saturation(img, lower=strong_sat_low, upper=strong_sat_high)\n",
    "]\n",
    "\n",
    "images = []\n",
    "for augmentation in other_augments:\n",
    "    image = augmentation(img_try)\n",
    "    if tf.random.uniform([]) < 1:\n",
    "        augmentation2 = random.choice(base_augments)\n",
    "        image = augmentation2(image)\n",
    "    images.append(image)\n",
    "\n",
    "#Show the images\n",
    "for image in images:\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Metadata Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a metadata dictionary for efficient lookup\n",
    "#Structure: {index: value} where value is (mod_toggle, metadata array)\n",
    "\n",
    "#Objective: We need \"train_ids\" to efficiently retrieve and augment images from the HDF5 file. This already exists.\n",
    "#           We need to accesss metadata through a dictionary to improve speed. A common reference is needed for both.\n",
    "\n",
    "#Idea:      Since train_ids is a LIST of tuples (isic_id, target, mod toggle), it is accessed via indices (ex. train_ids[10]).\n",
    "#           We need to make a dictionary that, for each train_ids index, lists all the metadata associated to the isic_id.\n",
    "#           Thus, when train_ids[10] is called, we call the dictionary and request key=10 to get the metadata.\n",
    "#           Result: very fast data retrieval\n",
    "\n",
    "def make_meta_dict(metadata, isic_ids_tuple):\n",
    "    #Reindex. The metadata must be contiguously indexed. Holes in index numbering will not work.\n",
    "    metadata = metadata.reset_index(drop=True)\n",
    "\n",
    "    #Get the column number for \"isic_id\" and \"target\" in the metadata dataframe.\n",
    "    #This allows us to know where these items are located in the metadata retrieved for each item.\n",
    "    #This is used later to filter out these items from the metadata.\n",
    "    col_num_id = metadata.columns.get_loc(\"isic_id\")\n",
    "    col_num_target = metadata.columns.get_loc(\"target\")\n",
    "\n",
    "    #The metadata contains all unique isic_ids. Since the dataframe is reindexed, it is possible to make\n",
    "    #a dictionary of (isic_id: row number) for fast retrieval of all metadata associated to an isic_id.\n",
    "\n",
    "    #Take the metadata dataframe and create a dictionary that stores (isic_id, row number).\n",
    "    metadata_index_dict = metadata[\"isic_id\"].to_dict()\n",
    "    metadata_index_dict = dict((v, k) for k, v in metadata_index_dict.items())\n",
    "\n",
    "    #Make a dictionary of (index: (mod toggle, metadata)), where index is the position of a sample in train_ids and metadata is the metadata\n",
    "    #associated to the sample's isic_id. We thus create a dict_of_meta that is a mirror image of the \"isic_ids_tuple\" list.\n",
    "    #We must be careful to not shuffle \"isic_ids_tuple\".\n",
    "    dict_of_meta = {}\n",
    "    for pos, tup in enumerate(isic_ids_tuple):\n",
    "        # Use the lookup table to directly find the index\n",
    "        index = metadata_index_dict.get(tup[0], -1)  # -1 if not found\n",
    "\n",
    "        if index != -1:\n",
    "            # Access the row directly without masking\n",
    "            dict_of_meta.update({pos: (tup[2], np.array(metadata.iloc[index].values))})\n",
    "            # Process the row as needed\n",
    "        else:\n",
    "            raise Exception(\"isic_id values are not all unique\")\n",
    "    return dict_of_meta, col_num_id, col_num_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the metadata dictionaries for train-validate-test\n",
    "train_meta_dict, train_pos_isic_id, train_pos_target = make_meta_dict(metadata, train_ids)\n",
    "val_meta_dict, val_pos_isic_id, val_pos_target = make_meta_dict(metadata, val_ids)\n",
    "test_meta_dict, test_pos_isic_id, test_pos_target = make_meta_dict(metadata, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE OF ITEMS FROM VALIDATION META DICTIONARY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: (61,\n",
       "  array(['ISIC_6397037', 1, 2.4382335136397706, 0.22812746467181,\n",
       "         -1.1126160012299564, -1.011203855248917, -1.2582703065867809,\n",
       "         0.8349987470947446, 3.747163237103989, -0.747354368588485,\n",
       "         2.0859385674302127, -1.2467653122094744, 5.217041355676107,\n",
       "         3.809504258600349, 1.3897054479733373, 2.3784811335709235,\n",
       "         0.4190379680040542, 0.0509311228974838, 0.7907118881952164,\n",
       "         0.3162400822235623, -2.562333125172432, -1.9705527372684155,\n",
       "         -5.3034176978504535, -1.2782249290621466, 0], dtype=object)),\n",
       " 1: (-1,\n",
       "  array(['ISIC_4420035', 0, -0.4775966954281103, -0.9913796393234418,\n",
       "         -0.626776602175792, -0.255226191343274, 0.8364706406522436,\n",
       "         0.2740460700675186, -0.5616945679287801, -0.0157442749562496,\n",
       "         -1.4040674715875925, 0.4979518899980893, -0.8952602052786262,\n",
       "         -1.256532386064231, -1.5126717561761245, -0.7071744158518197,\n",
       "         -1.3848528487599947, -0.5591509683837209, -0.7763821819884091,\n",
       "         -1.496994903746825, 0.7537277282180027, 1.822751292824251,\n",
       "         0.9056099732653016, 0.605468889759651, 0], dtype=object)),\n",
       " 2: (75,\n",
       "  array(['ISIC_0699524', 1, -1.468635253716408, -0.3570839201197412,\n",
       "         -0.1612181240473807, -3.1942258757432693, -4.14208996870035,\n",
       "         -3.4717795714188013, -0.7672476209100848, -1.242071550988128,\n",
       "         -1.4040674715875925, -1.1471623075817825, -0.9384436294942072,\n",
       "         -1.4638664228198015, -1.5126717561761245, -1.3737661051540624,\n",
       "         -1.3848528487599947, -0.0351290486659014, -1.3241616341081297,\n",
       "         -6.198164082657938, 0.3824514871322718, 2.857510159617601,\n",
       "         0.3321699069639958, -1.698122547026343, 0], dtype=object))}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look some dictionary elements to understand the structure {index, (mod_toggle, metadata)}\n",
    "print(\"SAMPLE OF ITEMS FROM VALIDATION META DICTIONARY\")\n",
    "dict(filter(lambda item: item[0] in {0, 1, 2}, val_meta_dict.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Dataset generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE generator in a class\n",
    "class hdf5_generator_all_included(Generator):\n",
    "    def __init__(self, file, meta_dict, dict_pos_isic_id, dict_pos_target, num_features, imgSize, is_training=False, shuffle_seed=None, apply_hair_removal=False):\n",
    "        self.file = file\n",
    "        self.meta_dict = meta_dict\n",
    "        self.pos_mod_toggle = 0                     #Position of 'mod_toggle' within dictionary: structure {key: value} where value is (mod_toggle, metadata array)\n",
    "        self.pos_metadata_array = 1                 #Position of 'metadata array' within dictionary: structure {key: value} where value is (mod_toggle, metadata array)\n",
    "        self.dict_pos_isic_id = dict_pos_isic_id    #Set position of 'isic_id\" within the metadata array: structure [var0, var1, var2, var3, ...]\n",
    "        self.dict_pos_target = dict_pos_target      #Set position of 'target\" within the metadata array: structure [var0, var1, var2, var3, ...]\n",
    "        self.num_features = num_features\n",
    "        self.imgSize = imgSize\n",
    "        self.is_training = is_training\n",
    "        self.shuffle_seed = shuffle_seed\n",
    "        self.apply_hair_removal = apply_hair_removal\n",
    "        self.len = len(meta_dict)\n",
    "        self.start = 0\n",
    "        self.stop = self.len\n",
    "        self.i = self.start\n",
    "        self.error_check()\n",
    "        self.open_hdf5()\n",
    "        self.order_and_shuffle()\n",
    "        \n",
    "    def send(self, value):\n",
    "        if self.i < self.stop:\n",
    "            if self.i == self.start:\n",
    "                self.open_hdf5()\n",
    "\n",
    "            #Retrieve index of isic_id according to the shuffled order\n",
    "            index = self.order[self.i]\n",
    "\n",
    "            #Retrieve target... remember that each item of the the meta_dict is a tuple of (mod toggle, metadata)\n",
    "            target = self.meta_dict[index][self.pos_metadata_array][self.dict_pos_target]\n",
    "            target = np.reshape(target, (1,1))\n",
    "            target = tf.cast(target, dtype=tf.int32)\n",
    "\n",
    "            #Retrieve metadata... remember that each item of the the meta_dict is a tuple of (mod toggle, metadata)\n",
    "            meta = np.delete(self.meta_dict[index][self.pos_metadata_array], [self.dict_pos_isic_id, self.dict_pos_target], 0)\n",
    "            meta = meta.astype(dtype=float)\n",
    "            meta = tf.cast(meta, dtype=tf.float32)\n",
    "            meta = tf.reshape(meta, shape=(1, self.num_features))\n",
    "\n",
    "            try:\n",
    "                #Retrieve isic_id\n",
    "                img_name = self.meta_dict[index][self.pos_metadata_array][self.dict_pos_isic_id]\n",
    "                \n",
    "                # Load image data from HDF5\n",
    "                img = np.array(Image.open(io.BytesIO(self.h5file[img_name][()])))\n",
    "\n",
    "                # Clean image\n",
    "                if self.apply_hair_removal:\n",
    "                    img = hair_removal(img)\n",
    "\n",
    "                # Resize the image\n",
    "                img = cv2.resize(img, (self.imgSize, self.imgSize), interpolation= cv2.INTER_AREA)\n",
    "\n",
    "                # Apply augmentations if needed\n",
    "                mod_toggle = self.meta_dict[index][self.pos_mod_toggle]\n",
    "                if mod_toggle > 0:\n",
    "                    img=augment_image(img, mod_toggle, self.is_training)\n",
    "                    \n",
    "                # Standardize and return as TensorFlow constant\n",
    "                img = tf.constant(img / 255, dtype=tf.float32)\n",
    "                \n",
    "                #Augment counter\n",
    "                self.i = self.i + 1\n",
    "                return (img, meta), target\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_name}: {e}\")\n",
    "                # log the error to a file for later analysis\n",
    "                with open('image_errors.log', 'a') as f:\n",
    "                    f.write(f\"Error loading image {img_name}: {e}\\n\")\n",
    "\n",
    "            if self.i == self.stop:\n",
    "                self.h5file.close()\n",
    "        raise StopIteration\n",
    "\n",
    "    def throw(self, typ, val=None, tb=None):\n",
    "        #Close HDF5 file and terminate generator\n",
    "        try:\n",
    "            self.h5file.close()\n",
    "            super().throw(typ, val, tb)\n",
    "        except:\n",
    "            super().throw(typ, val, tb)\n",
    "\n",
    "    def error_check(self):\n",
    "        #Seed type check\n",
    "        try:\n",
    "            int(self.shuffle_seed) == self.shuffle_seed\n",
    "        except:\n",
    "            if self.shuffle_seed != None:\n",
    "                raise Exception(\"Seed must either be an integer or None\")\n",
    "\n",
    "    def order_and_shuffle(self):\n",
    "        np.random.seed(self.shuffle_seed)\n",
    "        self.order = np.array(list(self.meta_dict.keys()), dtype=int)\n",
    "        if self.shuffle_seed != None:\n",
    "            np.random.shuffle(self.order)\n",
    "\n",
    "    def open_hdf5(self):\n",
    "        self.h5file = h5py.File(self.file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(hdf5_file, meta_dict, dict_pos_isic_id, dict_pos_target, imgSize=100, batch_size=32, is_training=False, shuffle_seed = None, apply_hair_removal=False):\n",
    "    num_features = len(val_meta_dict[0][1]) - 2 #Subtract isic_id and target\n",
    "\n",
    "    combined_generator = hdf5_generator_all_included(hdf5_file, meta_dict, dict_pos_isic_id, dict_pos_target, num_features, imgSize, is_training, shuffle_seed, apply_hair_removal)\n",
    "\n",
    "    # Generate image dataset\n",
    "    element_spec = ((tf.TensorSpec(shape=(imgSize, imgSize, 3), dtype=tf.float32),\n",
    "                    tf.TensorSpec(shape=(1, num_features), dtype=tf.float32)),\n",
    "                    tf.TensorSpec(shape=(1, 1), dtype=tf.int32))\n",
    "\n",
    "\n",
    "    img_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: combined_generator,\n",
    "        output_signature=element_spec\n",
    "    )\n",
    "\n",
    "    return img_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Alternative dataset function to load all in memory (not a generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_in_memory_dataset(hdf5_file, meta_dict, dict_pos_isic_id, dict_pos_target, imgSize=100, batch_size=32, is_training=False, shuffle_seed=None, apply_hair_removal=False):\n",
    "    #Position of elements in the value part of the dictionary (it is a tuple with multiple elements)\n",
    "    pos_mod_toggle = 0\n",
    "    pos_metadata_array = 1\n",
    "\n",
    "    num_features = len(meta_dict[0][pos_metadata_array]) - 2  # Subtract isic_id and target columns\n",
    "\n",
    "    # Initialize lists to hold images, metadata, and targets\n",
    "    images = []\n",
    "    metas = []\n",
    "    targets = []\n",
    "\n",
    "    np.random.seed(shuffle_seed)\n",
    "    order = np.array(list(meta_dict.keys()), dtype=int)\n",
    "    if shuffle_seed is not None:\n",
    "        np.random.shuffle(order)\n",
    "        \n",
    "    with h5py.File(hdf5_file, 'r') as h5file:\n",
    "        for i in range(len(meta_dict)):\n",
    "            index = order[i]\n",
    "            \n",
    "            # Retrieve target\n",
    "            target = meta_dict[index][pos_metadata_array][dict_pos_target]\n",
    "            target = np.reshape(target, (1, 1))\n",
    "            target = tf.cast(target, dtype=tf.int32)\n",
    "\n",
    "            # Retrieve metadata\n",
    "            meta = np.delete(meta_dict[index][pos_metadata_array], [dict_pos_isic_id, dict_pos_target], 0)\n",
    "            meta = meta.astype(dtype=float)\n",
    "            meta = tf.cast(meta, dtype=tf.float32)\n",
    "            meta = tf.reshape(meta, shape=(1, num_features))\n",
    "\n",
    "            try:\n",
    "                # Retrieve isic_id and load image\n",
    "                img_name = meta_dict[index][pos_metadata_array][dict_pos_isic_id]\n",
    "                \n",
    "                # Load image data from HDF5\n",
    "                img = np.array(Image.open(io.BytesIO(h5file[img_name][()])))\n",
    "\n",
    "                # Clean image\n",
    "                if apply_hair_removal:\n",
    "                    img = hair_removal(img)\n",
    "\n",
    "                # Resize the image\n",
    "                img = cv2.resize(img, (imgSize, imgSize), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Apply augmentations if needed\n",
    "                mod_toggle = meta_dict[index][pos_mod_toggle]\n",
    "                if mod_toggle > 0:\n",
    "                    img=augment_image(img, mod_toggle, is_training)\n",
    "\n",
    "                # Normalize the image\n",
    "                img = tf.constant(img / 255, dtype=tf.float32)\n",
    "\n",
    "                # Add processed data to lists\n",
    "                images.append(img)\n",
    "                metas.append(meta)\n",
    "                targets.append(target)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img_name}: {e}\")\n",
    "                with open('image_errors.log', 'a') as f:\n",
    "                    f.write(f\"Error loading image {img_name}: {e}\\n\")\n",
    "                continue\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    images_tensor = tf.stack(images, axis=0)\n",
    "    metas_tensor = tf.stack(metas, axis=0)\n",
    "    targets_tensor = tf.stack(targets, axis=0)\n",
    "\n",
    "    # Combine the images, metadata, and targets into a tf.data.Dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(((images_tensor, metas_tensor), targets_tensor))\n",
    "\n",
    "    # Batch and prefetch the dataset\n",
    "    return dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) CNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 - Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid CNN model than runs images through convolutional layers, then concatenates output with metadata, and runs the data through a NN\n",
    "@tf.keras.utils.register_keras_serializable(package=\"MyLayers\", name=\"KernelMult\")\n",
    "class Hybrid_model_series(tf.keras.Model):\n",
    "    def __init__(self, neurons, dropout, num_features, activ = 'leaky_relu', img_size = 100, img_channels = 3, **kwargs):\n",
    "        #Run the constructor of the parent class\n",
    "        super(). __init__(**kwargs)\n",
    "        \n",
    "        #Save inputs\n",
    "        self.neurons = neurons\n",
    "        self.dropout = dropout\n",
    "        self.activ = activ\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "        self.num_features = num_features\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        self.kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        self.bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "        #Layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(self.img_size, self.img_size, self.img_channels),\n",
    "                                            kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 5, activation='relu', kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(self.neurons, activation = self.activ, kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.dropout)\n",
    "        self.dense2 = tf.keras.layers.Dense(self.neurons, activation = self.activ, kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.dropout)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.concatenate = keras.layers.Concatenate(axis=1)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        flattened_inputs = tf.nest.flatten(inputs)\n",
    "        x_image, x_meta = flattened_inputs\n",
    "        # Convolutions & pooling\n",
    "        x = self.conv1(x_image)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x = self.flatten(x)\n",
    "        # Reshape metadata to match dimensions\n",
    "        x_meta = keras.layers.Reshape(target_shape=([x_meta.shape[-1]]))(x_meta)\n",
    "        # Concatenate image and metadata\n",
    "        x_all = self.concatenate([x, x_meta])\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        x_all = self.dropout1(x_all, training=training)\n",
    "        x_all = self.dense2(x_all)\n",
    "        x_all = self.dropout2(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid CNN model than runs metadata through a NN, images through convolutional layers, then concatenates results before a final layer (1 neuron)\n",
    "@tf.keras.utils.register_keras_serializable(package=\"MyLayers\", name=\"KernelMult\")\n",
    "class Hybrid_model_parallel(tf.keras.Model):\n",
    "    def __init__(self, neurons, dropout, num_features, activ = 'leaky_relu', img_size = 100, img_channels = 3, **kwargs):\n",
    "        #Run the constructor of the parent class\n",
    "        super(). __init__(**kwargs)\n",
    "        \n",
    "        #Save inputs\n",
    "        self.neurons = neurons\n",
    "        self.dropout = dropout\n",
    "        self.activ = activ\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "        self.num_features = num_features\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        self.kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        self.bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "        #Convolution Layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(self.img_size, self.img_size, self.img_channels),\n",
    "                                            kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 5, activation='relu', kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "        #Neural network layers (metadata)\n",
    "        self.dense1 = tf.keras.layers.Dense(self.neurons, activation = self.activ, input_shape=(1,self.num_features), kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.dropout)\n",
    "        self.dense2 = tf.keras.layers.Dense(self.neurons, activation = self.activ, kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.dropout)\n",
    "\n",
    "        #Final layer\n",
    "        self.concatenate = keras.layers.Concatenate(axis=1)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=self.kernel_initializer, bias_initializer=self.bias_initializer)\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        flattened_inputs = tf.nest.flatten(inputs)\n",
    "        x_image, x_meta = flattened_inputs\n",
    "        #CONVOLUTIONAL LAYERS (IMAGES)\n",
    "        # Convolutions & pooling\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = self.pool(x1)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        #NEURAL NETWORK LAYERS (METADATA ONLY)\n",
    "        # Neural Network\n",
    "        x2 = keras.layers.Reshape(target_shape=([x_meta.shape[-1]]))(x_meta)\n",
    "        x2 = self.dense1(x2)\n",
    "        x2 = self.dropout1(x2, training=training)\n",
    "        x2 = self.dense2(x2)\n",
    "        x2 = self.dropout2(x2, training=training)\n",
    "\n",
    "        #FINAL LAYER (OUTPUT)\n",
    "        # Concatenate image and metadata\n",
    "        x_all = self.concatenate([x1, x2])\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 - Model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 16:12:40.325989: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "if model_choice == 0:\n",
    "    model = Hybrid_model_series(neurons=nb_neurons_hidden_layers, dropout=dropout, num_features=num_features, activ='leaky_relu')\n",
    "else:\n",
    "    model = Hybrid_model_parallel(neurons=nb_neurons_hidden_layers, dropout=dropout, num_features=num_features, activ='leaky_relu')\n",
    "\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives(),\n",
    "                  tf.keras.metrics.AUC(curve='ROC', name='AUC_ROC'),\n",
    "                  tf.keras.metrics.AUC(curve='PR', name='AUC_PR'),\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 - Model loss function weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to calculate weights to use in loss function\n",
    "def compute_class_weights(meta_dict, pos_target):\n",
    "    # Initialize counters for target=0 and target=1\n",
    "    target_0_count = 0\n",
    "    target_1_count = 0\n",
    "\n",
    "    # Calculate total number of images\n",
    "    total = len(meta_dict)\n",
    "    # Calculate number of target = 1 by summing the target value for each dict item\n",
    "    target_1_count = sum([meta_dict[key][1][pos_target] for key in range(total)])\n",
    "    # Calculate number of target = 1\n",
    "    target_0_count = total - target_1_count\n",
    "\n",
    "    # Calculate class weights based on the counts, avoid division by zero\n",
    "    if target_1_count > 0 :\n",
    "        if target_1_count < target_0_count:\n",
    "            weight_for_0 = 1\n",
    "            weight_for_1 = target_0_count/target_1_count\n",
    "        elif target_0_count > 0:\n",
    "            weight_for_0 = target_1_count/target_0_count\n",
    "            weight_for_1 = 1\n",
    "        else:\n",
    "            weight_for_0 = 0\n",
    "            weight_for_1=target_1_count\n",
    "    else:\n",
    "        weight_for_0 = target_0_count\n",
    "        weight_for_1 = 0\n",
    "        \n",
    "\n",
    "    return weight_for_0, weight_for_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get weights for training\n",
    "weight_for_0, weight_for_1 = compute_class_weights(train_meta_dict, train_pos_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 - Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training batches in dataset: 6968\n",
      "Total validate batches in dataset: 934\n"
     ]
    }
   ],
   "source": [
    "#Determine the number of batches (includes last incomplete batch)\n",
    "nb_training_batches = int(np.ceil(len(train_meta_dict)/train_batch_size))\n",
    "nb_validate_batches = int(np.ceil(len(val_meta_dict)/val_batch_size))\n",
    "\n",
    "#Print results\n",
    "print(\"Total training batches in dataset:\", nb_training_batches)\n",
    "print(\"Total validate batches in dataset:\", nb_validate_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load training dataset into memory to speed up the model\n",
    "if save_train_in_memory:\n",
    "    train_in_memory = make_in_memory_dataset(hdf5_file, train_meta_dict, train_pos_isic_id, train_pos_target, apply_hair_removal=apply_hair_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load validation dataset into memory to speed up the validation steps of the model\n",
    "if save_val_in_memory:\n",
    "    val_in_memory = make_in_memory_dataset(hdf5_file, val_meta_dict, val_pos_isic_id, val_pos_target, apply_hair_removal=apply_hair_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear the memory leak in Keras\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "    #print(f\"Epoch {epoch+1} finished. Validation loss: {logs['val_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor epoch in range(1, nb_epochs + 1):\\n    #Make datasets\\n    print(\"EPOCH\", epoch)\\n\\n    #Reinitialize the training dataset with a new shuffle each time\\n    shuffle_seed = 8 + epoch #Next initialization of datasets will have a different shuffle\\n    \\n    #Reinitialize dataset generators (case when the dataset is not all stored in RAM)\\n    if save_train_in_memory == False:\\n        train_dataset = make_dataset(hdf5_file, train_meta_dict, train_pos_isic_id, train_pos_target, batch_size = train_batch_size, is_training=True, shuffle_seed=shuffle_seed, apply_hair_removal=apply_hair_removal)\\n    if save_val_in_memory == False:\\n        val_dataset = make_dataset(hdf5_file, val_meta_dict, val_pos_isic_id, val_pos_target, batch_size = val_batch_size, is_training=False, shuffle_seed=shuffle_seed, apply_hair_removal=apply_hair_removal)\\n\\n\\n    #Fit the model, using validation data either stored in memory or on the hard disk\\n    if save_val_in_memory:\\n        if save_train_in_memory:\\n            mod = model.fit(train_in_memory, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_in_memory, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\\n                        class_weight={0: weight_for_0, 1: weight_for_1})\\n        else:\\n            mod = model.fit(train_dataset, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_in_memory, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\\n                        class_weight={0: weight_for_0, 1: weight_for_1})\\n    else:\\n        if save_train_in_memory:\\n            mod = model.fit(train_in_memory, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_dataset, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\\n                        class_weight={0: weight_for_0, 1: weight_for_1})\\n        else:\\n            mod = model.fit(train_dataset, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_dataset, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\\n                        class_weight={0: weight_for_0, 1: weight_for_1})\\n    \\n    #Save results\\n    if epoch == 1:\\n        results = mod.history\\n    else:\\n        for key in mod.history:   \\n            results[key] += mod.history[key]\\n            \\n    #Export model structure (json) - REIMPORT NOT WORKING\\n    \"\"\"\\n    if epoch == 1:\\n        model_json = model.to_json()\\n        with open(savePath + \"model.json\", \"w\") as json_file:\\n            json_file.write(model_json)\\n    \"\"\"\\n    \\n    #Export weights (occassionally    \\n    if wt_save_freq > 0:\\n        if (epoch % wt_save_freq == 0):\\n            #if apply_hair_removal:\\n            #    modifier = \"with_hair_removal_\"\\n            #else:\\n            #    modifier = \"no_hair_removal_\"\\n            #now = datetime.datetime.now()\\n            #filename = \"Model_\" + modifier + \"Epoch_\" + str(epoch) + \"_\" + now.strftime(\"%Y-%m-%d_%Hh%Mm%Ss\") + \".weights.h5\"\\n            filename = \"Model_\" + \"Epoch_\" + str(epoch) + \".weights.h5\"\\n            model.save_weights(savePath + filename)\\n    if final_wt_save and epoch == nb_epochs:\\n        filename = \"Model_\" + \"Last_Epoch\" + \".weights.h5\"\\n        model.save_weights(savePath + filename)\\n    \\n\\n    #Clean memory after use\\n    del mod\\n    #If save_val_in_memory is false, we have a generator. In this case, we want to delete the generator.\\n    if save_train_in_memory == False:\\n        del train_dataset\\n    #If save_val_in_memory is false, we have a generator. In this case, we want to delete the generator.\\n    if save_val_in_memory == False:\\n        del val_dataset\\n    tf.keras.backend.clear_session()\\n    gc.collect()\\n\\n    #Early termination (check after 15 epochs)\\n    if epoch >= 15 and early_break == True:\\n        #Calculate previous three changes, if positive, then loss is increasing\\n        change1 = results[\"val_loss\"][-1] - results[\"val_loss\"][-2]\\n        change2 = results[\"val_loss\"][-2] - results[\"val_loss\"][-3]\\n        change3 = results[\"val_loss\"][-3] - results[\"val_loss\"][-4]\\n\\n        #Three consecutive increases in validation loss will stop the model\\n        if change1 > 0 and change2 > 0 and change3 > 0:\\n            break\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the model through epochs\n",
    "'''\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    #Make datasets\n",
    "    print(\"EPOCH\", epoch)\n",
    "\n",
    "    #Reinitialize the training dataset with a new shuffle each time\n",
    "    shuffle_seed = 8 + epoch #Next initialization of datasets will have a different shuffle\n",
    "    \n",
    "    #Reinitialize dataset generators (case when the dataset is not all stored in RAM)\n",
    "    if save_train_in_memory == False:\n",
    "        train_dataset = make_dataset(hdf5_file, train_meta_dict, train_pos_isic_id, train_pos_target, batch_size = train_batch_size, is_training=True, shuffle_seed=shuffle_seed, apply_hair_removal=apply_hair_removal)\n",
    "    if save_val_in_memory == False:\n",
    "        val_dataset = make_dataset(hdf5_file, val_meta_dict, val_pos_isic_id, val_pos_target, batch_size = val_batch_size, is_training=False, shuffle_seed=shuffle_seed, apply_hair_removal=apply_hair_removal)\n",
    "\n",
    "\n",
    "    #Fit the model, using validation data either stored in memory or on the hard disk\n",
    "    if save_val_in_memory:\n",
    "        if save_train_in_memory:\n",
    "            mod = model.fit(train_in_memory, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_in_memory, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\n",
    "                        class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "        else:\n",
    "            mod = model.fit(train_dataset, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_in_memory, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\n",
    "                        class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "    else:\n",
    "        if save_train_in_memory:\n",
    "            mod = model.fit(train_in_memory, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_dataset, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\n",
    "                        class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "        else:\n",
    "            mod = model.fit(train_dataset, epochs=1, steps_per_epoch = nb_training_batches, validation_data = val_dataset, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\n",
    "                        class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "    \n",
    "    #Save results\n",
    "    if epoch == 1:\n",
    "        results = mod.history\n",
    "    else:\n",
    "        for key in mod.history:   \n",
    "            results[key] += mod.history[key]\n",
    "            \n",
    "    #Export model structure (json) - REIMPORT NOT WORKING\n",
    "    \"\"\"\n",
    "    if epoch == 1:\n",
    "        model_json = model.to_json()\n",
    "        with open(savePath + \"model.json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Export weights (occassionally    \n",
    "    if wt_save_freq > 0:\n",
    "        if (epoch % wt_save_freq == 0):\n",
    "            #if apply_hair_removal:\n",
    "            #    modifier = \"with_hair_removal_\"\n",
    "            #else:\n",
    "            #    modifier = \"no_hair_removal_\"\n",
    "            #now = datetime.datetime.now()\n",
    "            #filename = \"Model_\" + modifier + \"Epoch_\" + str(epoch) + \"_\" + now.strftime(\"%Y-%m-%d_%Hh%Mm%Ss\") + \".weights.h5\"\n",
    "            filename = \"Model_\" + \"Epoch_\" + str(epoch) + \".weights.h5\"\n",
    "            model.save_weights(savePath + filename)\n",
    "    if final_wt_save and epoch == nb_epochs:\n",
    "        filename = \"Model_\" + \"Last_Epoch\" + \".weights.h5\"\n",
    "        model.save_weights(savePath + filename)\n",
    "    \n",
    "\n",
    "    #Clean memory after use\n",
    "    del mod\n",
    "    #If save_val_in_memory is false, we have a generator. In this case, we want to delete the generator.\n",
    "    if save_train_in_memory == False:\n",
    "        del train_dataset\n",
    "    #If save_val_in_memory is false, we have a generator. In this case, we want to delete the generator.\n",
    "    if save_val_in_memory == False:\n",
    "        del val_dataset\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    #Early termination (check after 15 epochs)\n",
    "    if epoch >= 15 and early_break == True:\n",
    "        #Calculate previous three changes, if positive, then loss is increasing\n",
    "        change1 = results[\"val_loss\"][-1] - results[\"val_loss\"][-2]\n",
    "        change2 = results[\"val_loss\"][-2] - results[\"val_loss\"][-3]\n",
    "        change3 = results[\"val_loss\"][-3] - results[\"val_loss\"][-4]\n",
    "\n",
    "        #Three consecutive increases in validation loss will stop the model\n",
    "        if change1 > 0 and change2 > 0 and change3 > 0:\n",
    "            break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6968/6968 [==============================] - 2647s 377ms/step - loss: 0.4866 - binary_accuracy: 0.8877 - false_negatives: 1957.0000 - false_positives: 23094.0000 - true_negatives: 181407.0000 - true_positives: 16516.0000 - AUC_ROC: 0.9577 - AUC_PR: 0.7285 - val_loss: 0.2130 - val_binary_accuracy: 0.9167 - val_false_negatives: 757.0000 - val_false_positives: 1732.0000 - val_true_negatives: 18412.0000 - val_true_positives: 8967.0000 - val_AUC_ROC: 0.9722 - val_AUC_PR: 0.9386\n",
      "EPOCH 2\n",
      "6968/6968 [==============================] - 2592s 372ms/step - loss: 0.3779 - binary_accuracy: 0.9083 - false_negatives: 1227.0000 - false_positives: 19209.0000 - true_negatives: 185292.0000 - true_positives: 17246.0000 - AUC_ROC: 0.9735 - AUC_PR: 0.7817 - val_loss: 0.2214 - val_binary_accuracy: 0.9174 - val_false_negatives: 609.0000 - val_false_positives: 1859.0000 - val_true_negatives: 18285.0000 - val_true_positives: 9115.0000 - val_AUC_ROC: 0.9736 - val_AUC_PR: 0.9413\n",
      "EPOCH 3\n",
      "6968/6968 [==============================] - 2604s 374ms/step - loss: 0.3421 - binary_accuracy: 0.9173 - false_negatives: 1039.0000 - false_positives: 17408.0000 - true_negatives: 187093.0000 - true_positives: 17434.0000 - AUC_ROC: 0.9776 - AUC_PR: 0.7943 - val_loss: 0.1665 - val_binary_accuracy: 0.9351 - val_false_negatives: 792.0000 - val_false_positives: 1146.0000 - val_true_negatives: 18998.0000 - val_true_positives: 8932.0000 - val_AUC_ROC: 0.9807 - val_AUC_PR: 0.9549\n",
      "EPOCH 4\n",
      "6968/6968 [==============================] - 2607s 374ms/step - loss: 0.3200 - binary_accuracy: 0.9230 - false_negatives: 936.0000 - false_positives: 16235.0000 - true_negatives: 188266.0000 - true_positives: 17537.0000 - AUC_ROC: 0.9799 - AUC_PR: 0.8031 - val_loss: 0.1776 - val_binary_accuracy: 0.9376 - val_false_negatives: 231.0000 - val_false_positives: 1634.0000 - val_true_negatives: 18510.0000 - val_true_positives: 9493.0000 - val_AUC_ROC: 0.9821 - val_AUC_PR: 0.9575\n",
      "EPOCH 5\n",
      "6968/6968 [==============================] - 2605s 374ms/step - loss: 0.3101 - binary_accuracy: 0.9261 - false_negatives: 892.0000 - false_positives: 15589.0000 - true_negatives: 188912.0000 - true_positives: 17581.0000 - AUC_ROC: 0.9810 - AUC_PR: 0.8105 - val_loss: 0.1974 - val_binary_accuracy: 0.9329 - val_false_negatives: 406.0000 - val_false_positives: 1598.0000 - val_true_negatives: 18546.0000 - val_true_positives: 9318.0000 - val_AUC_ROC: 0.9773 - val_AUC_PR: 0.9472\n",
      "EPOCH 6\n",
      "6968/6968 [==============================] - 2613s 375ms/step - loss: 0.3038 - binary_accuracy: 0.9275 - false_negatives: 863.0000 - false_positives: 15298.0000 - true_negatives: 189203.0000 - true_positives: 17610.0000 - AUC_ROC: 0.9815 - AUC_PR: 0.8110 - val_loss: 0.1693 - val_binary_accuracy: 0.9444 - val_false_negatives: 246.0000 - val_false_positives: 1416.0000 - val_true_negatives: 18728.0000 - val_true_positives: 9478.0000 - val_AUC_ROC: 0.9821 - val_AUC_PR: 0.9600\n",
      "EPOCH 7\n",
      "6968/6968 [==============================] - 2609s 374ms/step - loss: 0.2979 - binary_accuracy: 0.9293 - false_negatives: 826.0000 - false_positives: 14930.0000 - true_negatives: 189571.0000 - true_positives: 17647.0000 - AUC_ROC: 0.9822 - AUC_PR: 0.8168 - val_loss: 0.1416 - val_binary_accuracy: 0.9528 - val_false_negatives: 336.0000 - val_false_positives: 1073.0000 - val_true_negatives: 19071.0000 - val_true_positives: 9388.0000 - val_AUC_ROC: 0.9844 - val_AUC_PR: 0.9650\n",
      "EPOCH 8\n",
      "6968/6968 [==============================] - 2617s 375ms/step - loss: 0.2902 - binary_accuracy: 0.9316 - false_negatives: 820.0000 - false_positives: 14439.0000 - true_negatives: 190062.0000 - true_positives: 17653.0000 - AUC_ROC: 0.9829 - AUC_PR: 0.8208 - val_loss: 0.1558 - val_binary_accuracy: 0.9491 - val_false_negatives: 254.0000 - val_false_positives: 1267.0000 - val_true_negatives: 18877.0000 - val_true_positives: 9470.0000 - val_AUC_ROC: 0.9848 - val_AUC_PR: 0.9624\n",
      "EPOCH 9\n",
      "6968/6968 [==============================] - 2609s 374ms/step - loss: 0.2820 - binary_accuracy: 0.9346 - false_negatives: 768.0000 - false_positives: 13825.0000 - true_negatives: 190676.0000 - true_positives: 17705.0000 - AUC_ROC: 0.9841 - AUC_PR: 0.8304 - val_loss: 0.1490 - val_binary_accuracy: 0.9524 - val_false_negatives: 280.0000 - val_false_positives: 1142.0000 - val_true_negatives: 19002.0000 - val_true_positives: 9444.0000 - val_AUC_ROC: 0.9846 - val_AUC_PR: 0.9647\n",
      "EPOCH 10\n",
      "6968/6968 [==============================] - 2609s 374ms/step - loss: 0.2751 - binary_accuracy: 0.9355 - false_negatives: 765.0000 - false_positives: 13607.0000 - true_negatives: 190894.0000 - true_positives: 17708.0000 - AUC_ROC: 0.9846 - AUC_PR: 0.8394 - val_loss: 0.1571 - val_binary_accuracy: 0.9484 - val_false_negatives: 429.0000 - val_false_positives: 1111.0000 - val_true_negatives: 19033.0000 - val_true_positives: 9295.0000 - val_AUC_ROC: 0.9835 - val_AUC_PR: 0.9608\n",
      "EPOCH 11\n",
      "6968/6968 [==============================] - 2619s 376ms/step - loss: 0.2722 - binary_accuracy: 0.9365 - false_negatives: 800.0000 - false_positives: 13356.0000 - true_negatives: 191145.0000 - true_positives: 17673.0000 - AUC_ROC: 0.9852 - AUC_PR: 0.8480 - val_loss: 0.1352 - val_binary_accuracy: 0.9582 - val_false_negatives: 226.0000 - val_false_positives: 1021.0000 - val_true_negatives: 19123.0000 - val_true_positives: 9498.0000 - val_AUC_ROC: 0.9857 - val_AUC_PR: 0.9653\n",
      "EPOCH 12\n",
      "6968/6968 [==============================] - 2612s 375ms/step - loss: 0.2634 - binary_accuracy: 0.9392 - false_negatives: 757.0000 - false_positives: 12809.0000 - true_negatives: 191692.0000 - true_positives: 17716.0000 - AUC_ROC: 0.9859 - AUC_PR: 0.8514 - val_loss: 0.1581 - val_binary_accuracy: 0.9521 - val_false_negatives: 256.0000 - val_false_positives: 1175.0000 - val_true_negatives: 18969.0000 - val_true_positives: 9468.0000 - val_AUC_ROC: 0.9840 - val_AUC_PR: 0.9632\n",
      "EPOCH 13\n",
      "6968/6968 [==============================] - 2622s 376ms/step - loss: 0.2585 - binary_accuracy: 0.9406 - false_negatives: 736.0000 - false_positives: 12501.0000 - true_negatives: 192000.0000 - true_positives: 17737.0000 - AUC_ROC: 0.9862 - AUC_PR: 0.8525 - val_loss: 0.1698 - val_binary_accuracy: 0.9498 - val_false_negatives: 181.0000 - val_false_positives: 1318.0000 - val_true_negatives: 18826.0000 - val_true_positives: 9543.0000 - val_AUC_ROC: 0.9840 - val_AUC_PR: 0.9604\n",
      "EPOCH 14\n",
      " 687/6968 [=>............................] - ETA: 39:00 - loss: 0.2636 - binary_accuracy: 0.9416 - false_negatives: 67.0000 - false_positives: 1217.0000 - true_negatives: 18936.0000 - true_positives: 1764.0000 - AUC_ROC: 0.9859 - AUC_PR: 0.8495"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Configuration du bucket S3 et client boto3\n",
    "bucket = 'dsti-a23-deep-learning-outputs-01'\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Chemin local pour enregistrer temporairement les fichiers de poids\n",
    "localsavePath = os.getcwd() + '/hd5_files'\n",
    "os.makedirs(savePath, exist_ok=True)  # Crée le dossier s'il n'existe pas\n",
    "\n",
    "# Boucle d'entraînement du modèle\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    # Make datasets et autres configurations\n",
    "    print(\"EPOCH\", epoch)\n",
    "    \n",
    "    # Initialisation des datasets (exemple avec condition de mémoire)\n",
    "    shuffle_seed = 8 + epoch  # Re-shuffle à chaque époque\n",
    "    if save_train_in_memory == False:\n",
    "        train_dataset = make_dataset(hdf5_file, train_meta_dict, train_pos_isic_id, train_pos_target,\n",
    "                                     batch_size=train_batch_size, is_training=True, shuffle_seed=shuffle_seed,\n",
    "                                     apply_hair_removal=apply_hair_removal)\n",
    "    if save_val_in_memory == False:\n",
    "        val_dataset = make_dataset(hdf5_file, val_meta_dict, val_pos_isic_id, val_pos_target,\n",
    "                                   batch_size=val_batch_size, is_training=False, shuffle_seed=shuffle_seed,\n",
    "                                   apply_hair_removal=apply_hair_removal)\n",
    "\n",
    "    # Entraînement du modèle\n",
    "    if save_val_in_memory:\n",
    "        if save_train_in_memory:\n",
    "            mod = model.fit(train_in_memory, epochs=1, steps_per_epoch=nb_training_batches, \n",
    "                            validation_data=val_in_memory, validation_steps=nb_validate_batches, \n",
    "                            callbacks=[CustomCallback()], class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "        else:\n",
    "            mod = model.fit(train_dataset, epochs=1, steps_per_epoch=nb_training_batches, \n",
    "                            validation_data=val_in_memory, validation_steps=nb_validate_batches, \n",
    "                            callbacks=[CustomCallback()], class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "    else:\n",
    "        if save_train_in_memory:\n",
    "            mod = model.fit(train_in_memory, epochs=1, steps_per_epoch=nb_training_batches, \n",
    "                            validation_data=val_dataset, validation_steps=nb_validate_batches, \n",
    "                            callbacks=[CustomCallback()], class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "        else:\n",
    "            mod = model.fit(train_dataset, epochs=1, steps_per_epoch=nb_training_batches, \n",
    "                            validation_data=val_dataset, validation_steps=nb_validate_batches, \n",
    "                            callbacks=[CustomCallback()], class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "\n",
    "    # Sauvegarde des résultats d'entraînement\n",
    "    if epoch == 1:\n",
    "        results = mod.history\n",
    "    else:\n",
    "        for key in mod.history:\n",
    "            results[key] += mod.history[key]\n",
    "\n",
    "    # Enregistrement périodique des poids du modèle dans S3\n",
    "    if wt_save_freq > 0 and (epoch % wt_save_freq == 0):\n",
    "        filename = f\"Model_Epoch_{epoch}.weights.h5\"\n",
    "        local_weight_path = os.path.join(localsavePath, filename)\n",
    "\n",
    "        # Enregistrer les poids localement\n",
    "        model.save_weights(local_weight_path)\n",
    "\n",
    "        # Téléverser les poids dans S3\n",
    "        s3.upload_file(local_weight_path, bucket, f\"enregistrement/{filename}\")\n",
    "\n",
    "        # Supprimer le fichier local pour économiser de l'espace\n",
    "        #os.remove(local_weight_path)\n",
    "\n",
    "    # Enregistrement final des poids si demandé\n",
    "    if final_wt_save and epoch == nb_epochs:\n",
    "        filename = \"Model_Last_Epoch.weights.h5\"\n",
    "        local_weight_path = os.path.join(localsavePath, filename)\n",
    "\n",
    "        # Enregistrer les poids localement\n",
    "        model.save_weights(local_weight_path)\n",
    "\n",
    "        # Téléverser le fichier final dans S3\n",
    "        s3.upload_file(local_weight_path, bucket, f\"enregistrement/{filename}\")\n",
    "\n",
    "        # Supprimer le fichier local\n",
    "        #os.remove(local_weight_path)\n",
    "\n",
    "    # Nettoyage de la mémoire après chaque epoch\n",
    "    del mod\n",
    "    if not save_train_in_memory:\n",
    "        del train_dataset\n",
    "    if not save_val_in_memory:\n",
    "        del val_dataset\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # Arrêt anticipé si la perte de validation augmente sur trois époques consécutives (après 15 époques)\n",
    "    if epoch >= 15 and early_break == True:\n",
    "        change1 = results[\"val_loss\"][-1] - results[\"val_loss\"][-2]\n",
    "        change2 = results[\"val_loss\"][-2] - results[\"val_loss\"][-3]\n",
    "        change3 = results[\"val_loss\"][-3] - results[\"val_loss\"][-4]\n",
    "\n",
    "        # Trois augmentations consécutives de la perte de validation arrêtent le modèle\n",
    "        if change1 > 0 and change2 > 0 and change3 > 0:\n",
    "            print(\"Arrêt anticipé en raison d'une perte de validation croissante.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"hybrid_model_parallel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  2432      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  51264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  multiple                  0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  864       \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  1332      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " concatenate (Concatenate)   multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  33893     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89785 (350.72 KB)\n",
      "Trainable params: 89785 (350.72 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hybrid_model_parallel/conv2d/kernel:0' shape=(5, 5, 3, 32) dtype=float32, numpy=\n",
       " array([[[[ 8.15663300e-03, -1.14340670e-01, -5.63759618e-02, ...,\n",
       "           -5.93535453e-02, -2.65203584e-02, -3.78741771e-01],\n",
       "          [-6.30118400e-02,  8.13502595e-02, -5.25872558e-02, ...,\n",
       "           -1.42721444e-01,  4.83172899e-03, -2.56622523e-01],\n",
       "          [-6.77720904e-02, -4.60867770e-02, -3.17242704e-02, ...,\n",
       "           -1.28468141e-01, -2.63857339e-02, -1.44186929e-01]],\n",
       " \n",
       "         [[-9.72957909e-02, -1.60735920e-02,  4.47857529e-02, ...,\n",
       "            1.24118729e-02,  5.32332212e-02, -8.75451028e-01],\n",
       "          [-1.46912083e-01, -2.62510981e-02,  3.18208225e-02, ...,\n",
       "            2.77622994e-02, -8.44104290e-02, -1.21724308e+00],\n",
       "          [-6.09194972e-02,  2.56100595e-02, -3.55284251e-02, ...,\n",
       "            1.25135900e-02, -2.78994013e-02, -1.17256951e+00]],\n",
       " \n",
       "         [[ 2.99379397e-02, -1.18932039e-01,  1.00598177e-02, ...,\n",
       "           -4.94668446e-02, -5.92764514e-03, -8.98044825e-01],\n",
       "          [-9.44664106e-02, -3.33305337e-02,  4.62267967e-03, ...,\n",
       "            3.44924144e-02, -7.97704086e-02, -1.68793547e+00],\n",
       "          [-1.45646119e-02, -4.76759635e-02, -5.98224774e-02, ...,\n",
       "           -3.36617939e-02, -1.03200741e-01, -4.41886544e-01]],\n",
       " \n",
       "         [[-1.14142232e-01,  5.73521340e-03, -3.40990275e-02, ...,\n",
       "           -5.14426418e-02, -1.20918795e-01, -1.64545071e+00],\n",
       "          [-1.01381309e-01, -6.09644018e-02, -8.21355283e-02, ...,\n",
       "           -3.70692648e-02, -2.04242463e-03, -1.30143821e+00],\n",
       "          [ 1.37841434e-03, -1.71812236e-01, -2.74767373e-02, ...,\n",
       "            5.86616201e-03, -4.30441834e-02, -8.50701809e-01]],\n",
       " \n",
       "         [[-1.06596701e-01, -5.68293184e-02, -1.25187948e-01, ...,\n",
       "           -1.97421592e-02, -4.14850153e-02, -3.53689849e-01],\n",
       "          [-1.10169239e-01, -2.17155926e-03, -9.90569517e-02, ...,\n",
       "           -2.19252687e-02,  3.63286547e-02, -4.30335820e-01],\n",
       "          [ 1.00151477e-02, -8.97213370e-02, -6.86031580e-02, ...,\n",
       "            1.44898882e-02, -2.89379153e-02, -1.68268666e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.50294164e-02, -6.13281988e-02, -4.61702608e-02, ...,\n",
       "            4.45217686e-03, -4.75903153e-02, -3.59280646e-01],\n",
       "          [-5.94448559e-02, -3.44905816e-02, -4.25326787e-02, ...,\n",
       "           -1.21842185e-02,  4.19592997e-03, -2.42026463e-01],\n",
       "          [-5.69807105e-02,  1.30979065e-02, -7.37965629e-02, ...,\n",
       "           -2.68833246e-02, -9.21837334e-03, -1.70597300e-01]],\n",
       " \n",
       "         [[-7.26800412e-02,  6.62051365e-02, -3.91259231e-02, ...,\n",
       "            6.13575727e-02, -4.12870012e-02, -7.16832578e-01],\n",
       "          [-6.70596361e-02, -8.72504339e-02, -8.08801204e-02, ...,\n",
       "           -6.72417209e-02, -1.13203220e-01, -7.89967120e-01],\n",
       "          [ 1.31803369e-02, -5.02553619e-02, -5.75123243e-02, ...,\n",
       "           -6.65503517e-02,  4.11906140e-03, -1.01319683e+00]],\n",
       " \n",
       "         [[ 4.74092364e-03,  8.00486282e-02, -7.56679894e-03, ...,\n",
       "           -2.56934781e-02,  5.46553470e-02, -6.55687511e-01],\n",
       "          [-1.58665385e-02, -1.01231769e-01, -3.36234905e-02, ...,\n",
       "           -1.55246044e-02, -4.23179306e-02, -1.14130104e+00],\n",
       "          [-3.35979462e-02, -1.64460298e-02,  6.34302851e-04, ...,\n",
       "           -5.89647219e-02, -3.09284795e-02, -2.87331939e-01]],\n",
       " \n",
       "         [[-7.74044767e-02, -1.38765723e-01, -2.83924043e-02, ...,\n",
       "            1.09832129e-02, -6.89865798e-02, -1.64799094e+00],\n",
       "          [ 5.68035059e-02, -1.29825115e-01,  5.87530900e-04, ...,\n",
       "            3.88714559e-02,  1.68896597e-02, -1.14489186e+00],\n",
       "          [-5.99548928e-02, -1.87584981e-02,  2.72207847e-03, ...,\n",
       "           -1.11785054e-01,  2.57118139e-02, -2.32081294e-01]],\n",
       " \n",
       "         [[-7.95987397e-02,  1.69267356e-02, -5.99529482e-02, ...,\n",
       "           -4.35268767e-02, -9.68237687e-03, -5.50553538e-02],\n",
       "          [-8.45504999e-02, -5.70640787e-02,  2.52262149e-02, ...,\n",
       "           -4.66117673e-02, -1.21236937e-02, -1.35773152e-01],\n",
       "          [-4.30113748e-02, -3.01255491e-02,  9.70378667e-02, ...,\n",
       "            1.33587271e-02, -1.00168521e-02, -2.47879967e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.14616863e-01, -1.64879575e-01, -6.61138445e-02, ...,\n",
       "           -8.71688575e-02, -1.26931429e-01,  2.11702004e-01],\n",
       "          [-1.94300879e-02, -1.18552536e-01, -1.77032314e-02, ...,\n",
       "            5.01272716e-02,  1.28630241e-02,  5.21093726e-01],\n",
       "          [-7.09817111e-02, -1.62040487e-01, -6.73049837e-02, ...,\n",
       "            2.16241732e-01,  4.52775583e-02,  4.59629357e-01]],\n",
       " \n",
       "         [[-7.49902353e-02, -1.64946511e-01, -9.13138390e-02, ...,\n",
       "           -9.74525139e-02, -8.25105533e-02, -1.40521514e+00],\n",
       "          [-1.79228205e-02, -1.08515456e-01, -4.11480181e-02, ...,\n",
       "            1.31945303e-02,  5.56092747e-02, -8.56738925e-01],\n",
       "          [-4.08222638e-02, -1.61566019e-01, -1.09675843e-02, ...,\n",
       "           -1.04403839e-01, -3.94275449e-02, -2.35940647e+00]],\n",
       " \n",
       "         [[-9.70298648e-02, -1.12486348e-01, -5.28680161e-02, ...,\n",
       "           -1.94165349e-01, -3.52386199e-02, -2.11250377e+00],\n",
       "          [-7.86558017e-02, -2.80912519e-01, -4.13724519e-02, ...,\n",
       "           -1.02434732e-01, -3.62148434e-02, -1.32444668e+00],\n",
       "          [-3.14683169e-02, -6.34714812e-02, -5.18022887e-02, ...,\n",
       "           -1.81314170e-01, -5.44799417e-02, -1.96321821e+00]],\n",
       " \n",
       "         [[-9.51280519e-02, -1.61660854e-02, -1.61168091e-02, ...,\n",
       "            9.33437143e-03, -2.90020183e-02, -1.82673633e+00],\n",
       "          [ 5.17308749e-02, -6.48403168e-02, -3.29791643e-02, ...,\n",
       "            2.39885598e-02, -3.16202827e-02, -3.40524346e-01],\n",
       "          [ 1.38955908e-02,  2.82909535e-02, -2.73242425e-02, ...,\n",
       "           -3.43823098e-02,  1.31999077e-02, -8.90603960e-01]],\n",
       " \n",
       "         [[-1.19484253e-01, -8.43396708e-02, -6.50247186e-02, ...,\n",
       "            2.77471021e-02, -6.49356022e-02,  9.48340476e-01],\n",
       "          [-1.34776430e-02,  9.96460789e-04,  3.67513555e-03, ...,\n",
       "           -2.60803457e-02, -4.62889671e-02,  7.82278061e-01],\n",
       "          [ 3.89295779e-02, -2.94106118e-02, -9.29859802e-02, ...,\n",
       "           -7.45998174e-02, -3.09327375e-02,  8.67364943e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 2.12160428e-03, -2.55078096e-02, -1.60065919e-01, ...,\n",
       "           -6.64737821e-03, -8.36910531e-02,  3.48471642e-01],\n",
       "          [-7.88370594e-02,  2.97713131e-02, -3.55223157e-02, ...,\n",
       "           -4.33958247e-02, -7.97187164e-02,  2.12812424e-01],\n",
       "          [-2.28701849e-02, -1.47997972e-03, -7.79718235e-02, ...,\n",
       "            1.41804799e-01, -5.00128828e-02,  1.63419440e-01]],\n",
       " \n",
       "         [[-1.27171483e-02, -6.27652109e-02,  6.20812690e-03, ...,\n",
       "           -1.46187684e-02, -4.69149314e-02, -1.87757695e+00],\n",
       "          [-5.33218943e-02,  1.64938010e-02, -2.26802956e-02, ...,\n",
       "           -5.56069240e-02, -6.43266691e-03, -1.82958412e+00],\n",
       "          [-4.72573265e-02,  1.65151134e-02,  3.93804647e-02, ...,\n",
       "            3.91282961e-02, -7.99513534e-02, -3.44442344e+00]],\n",
       " \n",
       "         [[-8.34904686e-02, -1.14123866e-01, -3.01873148e-03, ...,\n",
       "           -7.21409619e-02,  4.08066325e-02, -4.03172779e+00],\n",
       "          [-3.57801616e-02, -8.52413848e-02, -3.84031236e-02, ...,\n",
       "           -1.38190031e-01, -2.55411323e-02, -3.11193395e+00],\n",
       "          [-4.26252484e-02, -2.51161382e-02, -9.77893919e-02, ...,\n",
       "            2.36019548e-02, -4.60053757e-02, -4.15115404e+00]],\n",
       " \n",
       "         [[-7.12252557e-02, -4.75974604e-02, -3.35708670e-02, ...,\n",
       "            3.34175229e-02, -7.61827156e-02, -4.20037842e+00],\n",
       "          [-1.97411738e-02, -7.29025453e-02, -2.10412089e-02, ...,\n",
       "           -4.67455424e-02,  2.93278117e-02, -2.04417419e+00],\n",
       "          [-8.56614634e-02, -8.61366466e-02,  4.47788797e-02, ...,\n",
       "           -1.92594726e-03, -6.21446371e-02, -2.88726401e+00]],\n",
       " \n",
       "         [[ 4.18447442e-02,  2.92369705e-02, -4.08470025e-03, ...,\n",
       "           -2.62392182e-02,  6.22583665e-02,  5.53483784e-01],\n",
       "          [-1.21757023e-01,  4.81644608e-02, -7.27200806e-02, ...,\n",
       "            7.89307349e-04,  1.65987667e-02,  4.96603310e-01],\n",
       "          [-8.63282010e-02, -9.22801644e-02, -8.73133019e-02, ...,\n",
       "            3.32699902e-02, -5.60088344e-02,  3.71048540e-01]]],\n",
       " \n",
       " \n",
       "        [[[-7.58982301e-02, -2.28428245e-02,  2.15325807e-03, ...,\n",
       "           -1.04630359e-01,  2.45246030e-02,  2.60087311e-01],\n",
       "          [-8.78464952e-02, -1.71624683e-02, -9.41853523e-02, ...,\n",
       "           -6.57850429e-02, -4.62058410e-02,  2.10057199e-01],\n",
       "          [ 3.13689597e-02, -1.97880417e-02,  4.16564830e-02, ...,\n",
       "           -3.34255723e-03,  5.23330159e-02,  1.86095685e-01]],\n",
       " \n",
       "         [[-1.32101610e-01,  2.69521424e-03, -4.37848233e-02, ...,\n",
       "           -2.04222295e-02, -7.98869282e-02, -1.93941486e+00],\n",
       "          [-2.84814201e-02, -1.77791342e-02,  1.16230167e-01, ...,\n",
       "           -1.17648907e-01, -3.63305584e-02, -1.84454525e+00],\n",
       "          [-4.34448011e-02, -4.03289422e-02,  4.92514297e-02, ...,\n",
       "            3.18833813e-02, -5.97435124e-02, -3.68763304e+00]],\n",
       " \n",
       "         [[-1.10887267e-01, -3.41687910e-02, -7.11904839e-03, ...,\n",
       "           -5.11298999e-02, -6.64260387e-02, -4.03638124e+00],\n",
       "          [-2.26071533e-02, -2.28705350e-03, -3.26209106e-02, ...,\n",
       "           -5.27289473e-02,  3.91861126e-02, -3.05632043e+00],\n",
       "          [ 8.40023253e-03, -9.75358263e-02,  1.58630479e-02, ...,\n",
       "           -5.24706841e-02, -8.24764967e-02, -3.94611740e+00]],\n",
       " \n",
       "         [[-7.06396103e-02,  1.89227387e-02, -6.81716800e-02, ...,\n",
       "           -1.42299514e-02, -7.04082148e-03, -4.04164267e+00],\n",
       "          [ 1.26972143e-02, -2.94423569e-02, -3.64353471e-02, ...,\n",
       "           -7.63393119e-02, -1.27645885e-03, -2.30204082e+00],\n",
       "          [-5.81681393e-02, -6.12619519e-02,  5.77797298e-04, ...,\n",
       "           -5.83185777e-02,  3.03997844e-03, -2.72614574e+00]],\n",
       " \n",
       "         [[-8.70921016e-02, -7.77030438e-02, -1.41191199e-01, ...,\n",
       "           -8.38116743e-03, -6.86038891e-03,  6.88418865e-01],\n",
       "          [-4.44181040e-02, -9.11469534e-02, -9.86150578e-02, ...,\n",
       "           -2.62777451e-02,  3.53355892e-02,  5.92979014e-01],\n",
       "          [ 7.86196217e-02, -8.53132680e-02,  6.41516671e-02, ...,\n",
       "           -4.47665192e-02, -8.59264210e-02,  5.14511585e-01]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/conv2d/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.01960012, -0.18954006, -0.078858  , -0.02593935, -0.06478031,\n",
       "        -0.08150309, -0.05917806, -0.17028378, -0.05446465, -0.17478219,\n",
       "        -0.04088821, -0.02328774, -0.02184688, -1.4616894 , -0.03676906,\n",
       "        -0.15434195, -0.06919747, -0.05726908, -0.09799132, -0.05997583,\n",
       "        -0.05950096, -0.08029727, -0.08243148, -0.03654255, -0.04597952,\n",
       "        -0.05691711, -0.0754484 , -0.13152899, -0.02224114, -0.08122546,\n",
       "        -0.02790328, -0.8676072 ], dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/conv2d_1/kernel:0' shape=(5, 5, 32, 64) dtype=float32, numpy=\n",
       " array([[[[ 3.05321719e-02, -1.05115190e-01, -4.01554555e-02, ...,\n",
       "           -1.00929454e-01,  6.04752377e-02, -2.81562703e-03],\n",
       "          [ 1.30470553e-02, -4.00951467e-02, -3.13292034e-02, ...,\n",
       "            5.33880070e-02,  5.23918718e-02,  2.07437612e-02],\n",
       "          [-1.27855837e-01,  1.30918045e-02,  6.18573502e-02, ...,\n",
       "            5.31805269e-02, -2.78812591e-02,  2.68081180e-03],\n",
       "          ...,\n",
       "          [-1.26785353e-01,  5.89367896e-02, -7.25709274e-02, ...,\n",
       "            7.28285536e-02, -5.60953841e-02,  3.95407155e-02],\n",
       "          [-3.96762416e-02,  1.06813526e-02,  1.45388655e-02, ...,\n",
       "           -2.51184702e-02, -4.61893901e-02, -2.28906772e-03],\n",
       "          [-4.89529036e-02, -1.12943891e-02,  9.42929268e-01, ...,\n",
       "            1.94299556e-02, -7.98480809e-02,  5.88691607e-02]],\n",
       " \n",
       "         [[ 8.71203374e-03, -8.56276415e-03,  1.43480197e-01, ...,\n",
       "            7.12985322e-02,  3.68218380e-03,  7.00566545e-02],\n",
       "          [-6.56252652e-02, -3.07072010e-02,  2.80202040e-03, ...,\n",
       "           -1.25783458e-02,  3.85649838e-02, -4.60166708e-02],\n",
       "          [ 4.62445877e-02, -6.30585700e-02,  5.92464916e-02, ...,\n",
       "            2.55935248e-02,  2.30726097e-02,  3.92647237e-02],\n",
       "          ...,\n",
       "          [ 1.06098637e-01,  6.12814501e-02,  7.11514950e-02, ...,\n",
       "           -9.84576866e-02, -2.52073556e-02, -1.33191869e-02],\n",
       "          [ 2.09349990e-02,  1.42700449e-02, -7.67790452e-02, ...,\n",
       "           -1.02543287e-01, -4.40956987e-02,  3.33409347e-02],\n",
       "          [-2.82899253e-02, -9.44091231e-02,  4.35470464e-03, ...,\n",
       "           -7.62546295e-03, -2.62266733e-02, -3.77770700e-02]],\n",
       " \n",
       "         [[-1.06122106e-01, -3.20221297e-02, -3.32261473e-02, ...,\n",
       "            8.27804580e-03,  7.34061375e-02, -2.73267888e-02],\n",
       "          [-7.43410587e-02, -1.18765458e-01,  5.84511040e-03, ...,\n",
       "           -1.37195261e-02, -2.03576707e-03,  7.47802556e-02],\n",
       "          [-9.37610120e-03,  4.38359529e-02,  3.57106887e-02, ...,\n",
       "            3.10522262e-02, -3.02134510e-02, -6.29086792e-02],\n",
       "          ...,\n",
       "          [ 2.17956100e-02, -3.23160738e-02, -1.72243081e-02, ...,\n",
       "            2.88365013e-03, -1.12548694e-01,  4.52662297e-02],\n",
       "          [-7.64481351e-02,  2.28853188e-02,  4.32312526e-02, ...,\n",
       "            3.10471747e-02, -1.14615075e-02, -8.92532524e-03],\n",
       "          [-5.87723479e-02, -1.55240064e-03,  7.89721087e-02, ...,\n",
       "            2.23524496e-03, -2.25235969e-02,  7.99796451e-03]],\n",
       " \n",
       "         [[ 2.47619171e-02, -8.22774023e-02,  1.22140199e-02, ...,\n",
       "            2.39145923e-02,  3.03847939e-02,  8.65152329e-02],\n",
       "          [ 1.01683196e-02, -4.42029275e-02, -2.17803214e-02, ...,\n",
       "           -2.16758940e-02, -1.05455844e-02,  3.47889448e-03],\n",
       "          [-1.77189708e-02, -5.30943833e-02, -4.30093855e-02, ...,\n",
       "            1.16430316e-02, -2.02833116e-02, -2.29825582e-02],\n",
       "          ...,\n",
       "          [-2.65862123e-04, -7.96175823e-02,  4.55939956e-02, ...,\n",
       "            6.34983256e-02,  7.49125928e-02, -1.12193180e-02],\n",
       "          [-3.95710059e-02,  3.32532972e-02, -8.30529779e-02, ...,\n",
       "           -5.51132066e-03,  1.16863854e-01,  5.12962826e-02],\n",
       "          [ 9.66769084e-02, -4.87773456e-02,  2.64826834e-01, ...,\n",
       "            2.53639910e-02, -3.88180800e-02,  3.69159062e-03]],\n",
       " \n",
       "         [[-8.76835138e-02, -6.66505247e-02, -1.20138615e-01, ...,\n",
       "            3.66195440e-02,  5.21311387e-02, -1.22008231e-02],\n",
       "          [ 1.88302062e-02,  2.47190753e-03, -2.37325802e-02, ...,\n",
       "           -2.50674933e-02, -7.82657638e-02,  1.69636104e-02],\n",
       "          [ 2.09802613e-02, -9.10471752e-02, -5.46158068e-02, ...,\n",
       "            6.12750314e-02, -1.32764899e-03,  4.53833155e-02],\n",
       "          ...,\n",
       "          [-8.47213436e-03, -6.99385032e-02, -1.43388147e-02, ...,\n",
       "            9.30665713e-03, -3.14037427e-02, -9.65823140e-03],\n",
       "          [-7.33577907e-02,  5.06153964e-02,  3.48936804e-02, ...,\n",
       "            3.31610329e-02, -6.14763722e-02,  1.84184089e-02],\n",
       "          [ 5.13073318e-02, -5.55153377e-02, -3.63705009e-01, ...,\n",
       "           -4.54110466e-02,  9.68076009e-03, -5.08861616e-02]]],\n",
       " \n",
       " \n",
       "        [[[-1.37882056e-02,  2.43926933e-03,  3.69155109e-02, ...,\n",
       "           -3.26917358e-02, -1.37859387e-02,  6.29806425e-03],\n",
       "          [ 5.74915495e-04,  1.04164472e-02, -8.49182904e-03, ...,\n",
       "           -1.21009443e-02,  6.56454591e-03, -1.47657795e-02],\n",
       "          [-1.63843319e-01, -1.18224435e-02, -3.58260050e-02, ...,\n",
       "            6.11743927e-02,  1.08896308e-02, -5.02458178e-02],\n",
       "          ...,\n",
       "          [-7.30834454e-02, -4.20266986e-02, -2.83365957e-02, ...,\n",
       "           -1.66111048e-02, -7.83116594e-02, -1.89858582e-02],\n",
       "          [ 3.12569528e-03,  5.49288020e-02, -6.55790837e-03, ...,\n",
       "           -6.48823101e-04, -3.68238501e-02, -3.87815759e-02],\n",
       "          [-6.26408756e-02,  5.79592958e-02,  4.74606335e-01, ...,\n",
       "            5.10284379e-02, -6.95902109e-03,  1.66522171e-02]],\n",
       " \n",
       "         [[-5.83415329e-02, -5.12844399e-02,  6.15240857e-02, ...,\n",
       "            1.88006107e-02, -6.07414171e-03,  1.87129900e-02],\n",
       "          [-9.80028957e-02, -3.01984046e-02, -2.35580187e-02, ...,\n",
       "            1.42937973e-02, -2.84514446e-02, -3.74862477e-02],\n",
       "          [-3.60734053e-02, -1.89016499e-02, -3.27914990e-02, ...,\n",
       "            2.42958423e-02,  6.06455766e-02, -1.84396040e-02],\n",
       "          ...,\n",
       "          [-7.30730370e-02, -5.72929531e-02, -3.40255871e-02, ...,\n",
       "            2.33163219e-02, -9.38210785e-02,  6.95562512e-02],\n",
       "          [-6.78270757e-02, -2.18178518e-02, -1.37499616e-01, ...,\n",
       "            8.35531875e-02, -6.88411742e-02,  8.31029341e-02],\n",
       "          [ 5.79945967e-02, -6.19392134e-02,  2.32711032e-01, ...,\n",
       "            3.94096263e-02, -5.07348366e-02, -5.03288507e-02]],\n",
       " \n",
       "         [[-8.31996575e-02, -6.89715743e-02, -2.35647466e-02, ...,\n",
       "           -6.61096200e-02,  4.80054468e-02,  5.55187315e-02],\n",
       "          [ 7.41613060e-02, -7.00045470e-03, -7.92349428e-02, ...,\n",
       "            5.07724471e-02, -6.32816106e-02,  4.03866209e-02],\n",
       "          [-1.13880277e-01,  3.41638364e-02,  1.19249169e-02, ...,\n",
       "            2.57679466e-02, -2.14220881e-02, -6.26358539e-02],\n",
       "          ...,\n",
       "          [-2.81271245e-02, -6.18764833e-02, -1.10263944e-01, ...,\n",
       "            1.03715397e-01, -7.19658332e-03,  4.54471912e-03],\n",
       "          [-3.24705392e-02,  3.53669263e-02, -6.52884096e-02, ...,\n",
       "           -1.94140263e-02, -7.04350770e-02,  8.29105228e-02],\n",
       "          [ 1.86726581e-02, -1.64808217e-03,  5.97613096e-01, ...,\n",
       "           -8.52836668e-02, -5.70168272e-02, -1.46395583e-02]],\n",
       " \n",
       "         [[-5.02766557e-02, -6.45522773e-02, -6.63866773e-02, ...,\n",
       "           -6.82266355e-02,  8.35462064e-02, -6.91475645e-02],\n",
       "          [ 5.60713559e-02, -1.11024149e-01, -2.75148693e-02, ...,\n",
       "            5.73175550e-02, -5.89332655e-02, -1.16927577e-02],\n",
       "          [ 4.60105352e-02,  2.07929742e-02,  2.85390448e-02, ...,\n",
       "            4.43459712e-02,  6.95563108e-02,  4.19023968e-02],\n",
       "          ...,\n",
       "          [-4.92299274e-02, -1.71112008e-02, -1.43588027e-02, ...,\n",
       "            4.15729173e-03, -5.59737980e-02,  1.32665977e-01],\n",
       "          [-5.93592301e-02, -1.58257522e-02, -3.47198285e-02, ...,\n",
       "            2.33650096e-02,  4.30891141e-02,  2.31331605e-02],\n",
       "          [ 8.57113898e-02, -6.45671636e-02,  2.57561523e-02, ...,\n",
       "            4.47533429e-02,  1.98542308e-02,  2.58400664e-02]],\n",
       " \n",
       "         [[ 9.31719039e-03, -4.67984788e-02,  3.39559540e-02, ...,\n",
       "            2.96496432e-02,  6.93813935e-02,  2.69673914e-02],\n",
       "          [-1.44034973e-03,  3.53935035e-03, -4.18920815e-02, ...,\n",
       "           -9.75273456e-03, -1.30258217e-01, -8.88395938e-04],\n",
       "          [ 7.75714219e-02, -1.73944179e-02,  4.45835926e-02, ...,\n",
       "            6.98278472e-03, -9.12947506e-02, -1.99347585e-02],\n",
       "          ...,\n",
       "          [-2.65119411e-03, -9.88993421e-02, -1.41198300e-02, ...,\n",
       "           -6.97792917e-02, -1.15594408e-02,  3.10626123e-02],\n",
       "          [ 1.44579057e-02,  2.88946088e-02, -5.99249415e-02, ...,\n",
       "           -5.38669340e-02, -7.57503808e-02, -1.00154113e-02],\n",
       "          [ 4.91123237e-02, -2.98305117e-02, -2.79924184e-01, ...,\n",
       "            8.09876621e-02,  6.07119426e-02,  1.05935670e-01]]],\n",
       " \n",
       " \n",
       "        [[[-3.02562285e-02, -4.35699662e-03,  4.48303334e-02, ...,\n",
       "            1.45987188e-02, -6.58369064e-02,  1.86405331e-02],\n",
       "          [ 2.86918171e-02, -9.95535627e-02, -2.93720178e-02, ...,\n",
       "            5.08814417e-02, -2.61816550e-02,  2.06772741e-02],\n",
       "          [ 5.56759574e-02, -1.09406430e-02, -8.81907493e-02, ...,\n",
       "            2.37895735e-03,  2.27722432e-02,  4.13164077e-03],\n",
       "          ...,\n",
       "          [ 2.57038493e-02, -8.85569751e-02, -1.09392986e-01, ...,\n",
       "            1.76659487e-02, -3.93691733e-02,  2.01096311e-02],\n",
       "          [-6.45695999e-02, -1.27176896e-01, -9.59607027e-03, ...,\n",
       "            1.08070433e-01, -2.01517045e-02, -3.52598615e-02],\n",
       "          [ 3.09743565e-02, -8.56506824e-02, -1.32355288e-01, ...,\n",
       "            8.25744029e-03, -7.34857544e-02,  3.59356590e-02]],\n",
       " \n",
       "         [[-3.67696509e-02, -1.60428789e-03, -5.56538056e-04, ...,\n",
       "           -2.00646650e-02,  5.29265329e-02,  6.81532640e-03],\n",
       "          [-6.27766997e-02,  2.94855032e-02, -4.22045179e-02, ...,\n",
       "           -6.29302440e-03, -2.48975754e-02,  1.21806741e-01],\n",
       "          [-2.38620350e-03,  5.27910888e-02,  3.10952007e-03, ...,\n",
       "           -5.63159995e-02, -6.75408021e-02, -6.42868225e-03],\n",
       "          ...,\n",
       "          [-3.97139341e-02, -7.18892664e-02, -4.47033010e-02, ...,\n",
       "           -3.29204462e-02, -4.87072878e-02,  5.58226481e-02],\n",
       "          [-5.78812063e-02,  9.60041806e-02, -1.02383517e-01, ...,\n",
       "            3.65705080e-02,  5.10328449e-02,  1.93807911e-02],\n",
       "          [ 6.06395006e-02, -2.26240885e-02, -6.53910742e-04, ...,\n",
       "            3.86324786e-02, -1.01698816e-01, -7.42835924e-03]],\n",
       " \n",
       "         [[-2.57691499e-02,  7.14776479e-03,  1.24140810e-02, ...,\n",
       "           -1.39016643e-01,  2.68470589e-02, -2.27399766e-02],\n",
       "          [ 4.89839073e-03, -1.43370986e-01, -4.12622094e-02, ...,\n",
       "           -1.62248302e-03, -1.25445485e-01, -2.27288138e-02],\n",
       "          [-4.69864765e-03, -6.71835020e-02,  1.06121682e-01, ...,\n",
       "            8.66261721e-02,  6.82054609e-02,  3.55890319e-02],\n",
       "          ...,\n",
       "          [ 2.13493854e-02,  4.44302745e-02, -2.79180855e-02, ...,\n",
       "           -4.95756492e-02,  6.61562663e-03, -6.56931922e-02],\n",
       "          [-5.30616753e-02,  4.16769311e-02,  2.00639758e-02, ...,\n",
       "           -2.97648553e-02, -1.35420961e-03, -7.10671917e-02],\n",
       "          [ 9.74951312e-02, -1.37205198e-01,  4.87492740e-01, ...,\n",
       "           -5.12146242e-02,  1.46759627e-02,  3.18269851e-03]],\n",
       " \n",
       "         [[ 1.77828837e-02, -9.61467847e-02,  1.65288243e-02, ...,\n",
       "            3.79753970e-02,  5.55748716e-02,  1.50978062e-02],\n",
       "          [-9.87027586e-02, -2.79757585e-02, -1.25870749e-01, ...,\n",
       "           -7.08267540e-02, -1.36505431e-02,  6.33728355e-02],\n",
       "          [-4.02823463e-02, -2.17393767e-02,  1.11981645e-01, ...,\n",
       "           -8.78590625e-03,  2.88533848e-02,  8.10266100e-03],\n",
       "          ...,\n",
       "          [-6.09156750e-02,  3.84347029e-02, -6.21799231e-02, ...,\n",
       "           -6.25947192e-02,  4.29740287e-02, -5.09844497e-02],\n",
       "          [-1.00345023e-01,  7.16521740e-02, -6.64611086e-02, ...,\n",
       "           -5.72031625e-02, -5.01420256e-03,  2.83491202e-02],\n",
       "          [-1.34067442e-02,  3.06480401e-03, -1.80096045e-01, ...,\n",
       "           -3.98408026e-02, -8.49182531e-02,  8.74769986e-02]],\n",
       " \n",
       "         [[-3.67901521e-03, -2.80861091e-02,  1.34779857e-02, ...,\n",
       "            2.25622710e-02,  3.15725282e-02,  6.05464168e-03],\n",
       "          [ 4.69553322e-02, -2.08667349e-02, -1.05017528e-01, ...,\n",
       "            3.91548276e-02, -6.75184652e-02,  8.63841772e-02],\n",
       "          [-4.14977260e-02, -5.99272363e-02, -3.01637258e-02, ...,\n",
       "            1.88276526e-02, -8.18575174e-02,  2.37238058e-03],\n",
       "          ...,\n",
       "          [ 1.06190462e-02, -3.80339250e-02,  2.60210540e-02, ...,\n",
       "           -4.24088612e-02, -3.25944833e-02,  1.80036053e-02],\n",
       "          [-2.76548602e-02,  2.29659472e-02, -4.96979915e-02, ...,\n",
       "            1.02665365e-01, -6.36390671e-02, -2.32437928e-03],\n",
       "          [ 3.80384512e-02, -1.00344948e-01, -2.33256184e-02, ...,\n",
       "           -1.85862444e-02, -1.59538083e-03,  4.72617634e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.65957678e-02, -9.95907094e-03,  1.74204949e-02, ...,\n",
       "            6.45388430e-03, -1.35068996e-02, -6.12015165e-02],\n",
       "          [-6.70708716e-02, -3.22660021e-02,  3.45059335e-02, ...,\n",
       "            8.90841801e-03, -1.22271225e-01,  9.44621861e-02],\n",
       "          [-5.87904751e-02, -7.53340572e-02,  5.66510521e-02, ...,\n",
       "           -1.53106963e-02, -9.60753635e-02,  1.62797272e-01],\n",
       "          ...,\n",
       "          [-8.51271898e-02, -8.10897350e-02, -6.22144453e-02, ...,\n",
       "           -9.66843516e-02,  1.81800942e-03, -5.87863475e-02],\n",
       "          [ 4.79353108e-02,  1.59699339e-02, -1.40920170e-02, ...,\n",
       "            1.33356405e-02, -4.07705456e-02, -3.98399793e-02],\n",
       "          [-1.49641810e-02, -6.24053814e-02, -1.11048505e-01, ...,\n",
       "           -1.35718333e-02, -6.12258427e-02, -6.30544350e-02]],\n",
       " \n",
       "         [[ 1.46164924e-01, -1.14939045e-02,  1.00746997e-01, ...,\n",
       "           -4.04690951e-02,  2.19523050e-02, -4.86849472e-02],\n",
       "          [-8.07504579e-02, -3.61654647e-02, -5.08715026e-02, ...,\n",
       "            4.48962376e-02, -4.05588746e-03,  4.56651859e-02],\n",
       "          [-1.35279810e-02, -1.38199106e-02,  5.34569882e-02, ...,\n",
       "           -2.60753687e-02, -5.19634364e-03,  4.10280786e-02],\n",
       "          ...,\n",
       "          [-7.74417818e-02, -7.76808411e-02,  3.99648258e-03, ...,\n",
       "            8.37674662e-02, -4.16869782e-02,  8.13164264e-02],\n",
       "          [ 9.35246702e-03,  1.75325181e-02,  2.77566239e-02, ...,\n",
       "            3.09552699e-02, -2.46257447e-02, -2.31620260e-02],\n",
       "          [ 4.29919921e-02,  1.13012157e-02,  2.22430453e-01, ...,\n",
       "            1.29934018e-02, -1.24628462e-01, -4.98894714e-02]],\n",
       " \n",
       "         [[-2.01184326e-03,  7.59904757e-02, -5.83389821e-03, ...,\n",
       "           -1.82316508e-02,  4.85840440e-02,  8.26905295e-02],\n",
       "          [-3.98935527e-02,  3.49692479e-02, -1.18773989e-01, ...,\n",
       "           -7.23684654e-02, -3.84846739e-02,  6.93731904e-02],\n",
       "          [ 6.86732233e-02,  6.88054739e-03, -2.88630668e-02, ...,\n",
       "            5.64402714e-02, -1.11063592e-01, -2.57547200e-02],\n",
       "          ...,\n",
       "          [-3.08556613e-02, -8.62917304e-02, -6.64371923e-02, ...,\n",
       "           -6.37193536e-03, -2.92695835e-02, -6.75654262e-02],\n",
       "          [-2.29968261e-02,  4.81729656e-02, -9.27987248e-02, ...,\n",
       "            1.17534295e-01, -5.99852540e-02,  9.70730409e-02],\n",
       "          [ 3.92247103e-02,  4.08579521e-02, -4.39537227e-01, ...,\n",
       "           -1.87486373e-02, -1.62187952e-03, -3.03100999e-02]],\n",
       " \n",
       "         [[ 1.71277691e-02, -1.14356510e-01, -6.62101209e-02, ...,\n",
       "           -7.81089514e-02, -6.41456153e-03, -8.57223943e-02],\n",
       "          [-4.42827269e-02,  4.04025353e-02, -4.33220454e-02, ...,\n",
       "           -2.07457636e-02,  2.91748308e-02,  6.24633804e-02],\n",
       "          [-9.21790227e-02,  6.74687624e-02,  2.43296232e-02, ...,\n",
       "            3.29830050e-02, -3.29433158e-02, -4.54304591e-02],\n",
       "          ...,\n",
       "          [-7.26269558e-02,  8.52026790e-03, -3.67348082e-02, ...,\n",
       "           -1.12099089e-01, -6.35831431e-02, -3.82992462e-03],\n",
       "          [-7.23703280e-02, -3.63748223e-02, -2.27901433e-02, ...,\n",
       "           -8.18969831e-02, -3.56475562e-02, -6.70396071e-03],\n",
       "          [-3.45423631e-03,  4.69017625e-02,  1.95262861e-02, ...,\n",
       "            9.33272205e-03, -3.88559955e-03,  3.04753962e-03]],\n",
       " \n",
       "         [[ 1.21184792e-02,  1.91087425e-02,  1.23261530e-02, ...,\n",
       "           -3.54470238e-02,  5.84636480e-02,  8.33300203e-02],\n",
       "          [ 7.36239776e-02, -1.11674948e-03, -2.56522410e-02, ...,\n",
       "           -7.67483935e-02,  2.94129308e-02,  2.48003788e-02],\n",
       "          [ 1.24246487e-02, -1.55396387e-02,  4.04140092e-02, ...,\n",
       "            6.13801368e-02,  2.27172747e-02,  1.11266607e-02],\n",
       "          ...,\n",
       "          [ 8.26676656e-03, -7.14082718e-02,  9.23436787e-03, ...,\n",
       "           -1.46342367e-02, -6.97728097e-02, -1.61912981e-02],\n",
       "          [-2.02458389e-02,  3.84706482e-02, -1.72780622e-02, ...,\n",
       "           -1.58765481e-03, -3.88409570e-02, -6.19889013e-02],\n",
       "          [-4.00478579e-02, -8.91127530e-03, -7.51551092e-02, ...,\n",
       "            4.02113162e-02,  5.78085221e-02, -1.20265886e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 2.82601099e-02,  9.00550112e-02, -2.40830686e-02, ...,\n",
       "           -3.78280170e-02, -1.81256384e-02,  4.05305624e-02],\n",
       "          [ 3.59638524e-03, -9.31633636e-03, -6.14899546e-02, ...,\n",
       "            2.29894351e-02, -5.99907488e-02,  9.22977831e-03],\n",
       "          [ 5.00584356e-02,  8.13678652e-02, -6.54531419e-02, ...,\n",
       "            1.66437309e-02, -1.31993983e-02,  5.25726145e-03],\n",
       "          ...,\n",
       "          [ 3.07779410e-03, -3.39096524e-02,  6.96581206e-04, ...,\n",
       "           -6.83730170e-02, -7.25378841e-02,  5.33463992e-03],\n",
       "          [-1.06736988e-01,  1.29056528e-01, -1.07924446e-01, ...,\n",
       "           -6.93942234e-02,  1.92037597e-02, -4.32240218e-02],\n",
       "          [-4.85429205e-02, -5.05180843e-03,  6.97569251e-01, ...,\n",
       "           -1.25117796e-02,  1.65959552e-03,  1.63979717e-02]],\n",
       " \n",
       "         [[ 8.86005815e-03,  5.45003414e-02,  8.89266375e-03, ...,\n",
       "           -5.53992465e-02, -6.20348677e-02,  1.47924218e-02],\n",
       "          [-3.71101648e-02, -2.47027334e-02, -8.44425336e-02, ...,\n",
       "           -1.20086610e-04, -3.45721259e-03,  2.96655800e-02],\n",
       "          [-2.94046849e-02, -6.26178235e-02, -9.41019505e-02, ...,\n",
       "           -2.75615640e-02, -3.44054513e-02, -4.92124595e-02],\n",
       "          ...,\n",
       "          [-1.09259821e-01, -4.15843986e-02, -1.35715511e-02, ...,\n",
       "            3.02420952e-03, -4.83066253e-02, -1.42949307e-02],\n",
       "          [-5.23303114e-02,  4.15927917e-02, -9.68277231e-02, ...,\n",
       "           -2.21502185e-02, -4.16095704e-02, -3.12152393e-02],\n",
       "          [ 7.53112286e-02, -3.55335176e-02,  1.75687373e-01, ...,\n",
       "           -5.21175563e-02, -1.23514853e-01, -2.89177746e-02]],\n",
       " \n",
       "         [[ 9.04182866e-02, -1.69667955e-02,  1.01672430e-02, ...,\n",
       "           -3.74411494e-02, -1.14368111e-01,  4.44631241e-02],\n",
       "          [-6.51073009e-02,  3.10552157e-02, -3.90793942e-02, ...,\n",
       "           -8.17269087e-02, -6.69115316e-03,  8.18412099e-03],\n",
       "          [ 6.08789437e-02, -7.71498755e-02,  7.52371028e-02, ...,\n",
       "            9.58538577e-02,  5.49934991e-03,  1.02768794e-01],\n",
       "          ...,\n",
       "          [-2.13252455e-02, -3.34815644e-02, -3.80296670e-02, ...,\n",
       "            2.26356816e-02, -9.57632884e-02,  2.50036512e-02],\n",
       "          [-9.24915150e-02,  3.71086854e-03,  1.70955958e-03, ...,\n",
       "            4.18225117e-02, -6.81865290e-02,  2.04139687e-02],\n",
       "          [-4.99187084e-03, -1.13640353e-02, -2.21029297e-01, ...,\n",
       "            1.96105856e-02,  1.62312850e-01,  5.08104526e-02]],\n",
       " \n",
       "         [[-3.33574787e-02,  5.06810136e-02,  6.43666759e-02, ...,\n",
       "            3.44887972e-02,  7.89459199e-02,  2.44557410e-02],\n",
       "          [-6.30694181e-02, -4.51778360e-02,  4.77522239e-03, ...,\n",
       "           -9.70366597e-03, -6.23298921e-02, -3.41982134e-02],\n",
       "          [ 5.50481193e-02,  3.39267068e-02, -7.81329256e-03, ...,\n",
       "           -1.56189874e-02,  6.35067970e-02,  6.40914217e-02],\n",
       "          ...,\n",
       "          [-5.78756444e-02,  6.60981014e-02, -5.60650229e-02, ...,\n",
       "           -5.89212961e-02,  4.89675514e-02, -1.96871087e-02],\n",
       "          [-7.50878081e-02,  8.20199102e-02, -4.34782207e-02, ...,\n",
       "           -2.18057297e-02, -9.78705063e-02,  8.31924453e-02],\n",
       "          [ 4.28216755e-02, -9.78427753e-02, -2.66155660e-01, ...,\n",
       "           -3.08708437e-02,  2.56086379e-01, -2.48485245e-02]],\n",
       " \n",
       "         [[ 4.33044359e-02, -7.60322809e-02,  5.88290058e-02, ...,\n",
       "           -2.60637607e-02,  7.36651048e-02,  9.91138816e-02],\n",
       "          [ 5.74211851e-02,  1.51876360e-02, -9.16487575e-02, ...,\n",
       "           -8.59394204e-03, -2.82678846e-02,  3.04291621e-02],\n",
       "          [ 3.43041718e-02, -7.46578723e-02,  3.29365805e-02, ...,\n",
       "            3.37891839e-02, -5.88360764e-02, -6.78692684e-02],\n",
       "          ...,\n",
       "          [-1.21315107e-01,  6.05727658e-02,  1.69383660e-02, ...,\n",
       "           -1.34467278e-02, -9.64410380e-02,  5.04696593e-02],\n",
       "          [-4.56095189e-02,  1.46648929e-01, -1.62829570e-02, ...,\n",
       "           -5.57095297e-02, -3.66297886e-02,  1.17024899e-01],\n",
       "          [ 4.94557759e-03,  9.09560472e-02,  1.18220426e-01, ...,\n",
       "            3.41467559e-02, -4.33425494e-02, -4.59288899e-03]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.37591663, -0.1944835 , -0.784241  , -0.17579475, -0.3741356 ,\n",
       "        -0.29633224, -0.11950943, -0.4795825 , -0.28537545, -0.30339187,\n",
       "        -0.32749623, -1.0445943 , -0.2612832 , -0.7010813 , -1.0211535 ,\n",
       "        -0.19826542, -0.3888395 , -0.40019533, -0.56014264, -0.28819236,\n",
       "        -0.422891  , -0.30165917, -0.32629728, -0.39982098, -0.14341004,\n",
       "        -0.4323993 , -0.2586089 , -0.41944188, -0.34315404, -0.28479174,\n",
       "        -1.2347554 , -0.3659859 , -0.21252908, -0.3360767 , -0.29377544,\n",
       "        -0.41866162, -0.24328388, -1.105627  , -0.62848616, -0.5642465 ,\n",
       "        -0.26001722, -0.3396277 , -0.18642619, -0.8507282 , -0.38348687,\n",
       "        -0.56600237, -0.18277755, -0.39419118, -0.31520775, -0.43735436,\n",
       "        -0.06951635, -0.45583287, -0.37528232, -0.8549429 , -0.3399927 ,\n",
       "        -0.25858337, -1.0234792 , -0.2624461 , -0.3804428 , -0.0786055 ,\n",
       "        -0.1561444 , -0.4419156 , -0.5323797 , -0.42190567], dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/dense/kernel:0' shape=(23, 36) dtype=float32, numpy=\n",
       " array([[ 2.2069159e+00, -5.4508467e+00, -1.4496259e-01, -3.0637534e+00,\n",
       "          1.6854624e+00,  1.6651729e-01,  5.3625810e-01, -4.5938773e+00,\n",
       "          9.8321831e-01, -4.7709885e+00, -4.1992021e-01,  2.9152870e+00,\n",
       "          2.9512233e-01, -4.9167209e+00,  6.2890726e-01,  1.8182467e+00,\n",
       "          1.4974047e+00,  4.7858447e-02, -4.7274569e-01,  1.6283827e+00,\n",
       "         -2.7725050e+00,  1.3690319e+00,  1.8688058e+00,  2.1421478e+00,\n",
       "          1.4817735e+00,  2.6537840e+00, -1.2666872e+00,  2.7701383e-02,\n",
       "         -9.8684990e-01, -3.1896746e+00, -3.1191139e+00,  1.8962653e-01,\n",
       "          2.1364841e+00,  1.6140642e+00,  1.2694989e-01,  1.4009520e+00],\n",
       "        [-1.8997453e+00, -7.0635343e-01, -2.7602971e+00,  6.5098023e-01,\n",
       "         -6.4936328e-01,  2.5593609e-01, -8.5231638e-01, -1.2798562e+00,\n",
       "          7.4433517e-01,  6.2405616e-02, -1.1714710e+00,  1.1095190e+00,\n",
       "         -1.1486018e+00, -6.3533449e-01,  1.0529079e+00,  5.8195466e-01,\n",
       "          4.1669479e-01,  1.2172563e+00, -2.7503273e-01, -8.8014132e-01,\n",
       "         -9.2739987e-01,  2.8938320e+00,  5.0840318e-01,  1.6756853e+00,\n",
       "         -1.4672533e+00, -3.0329971e+00,  2.8016365e-01, -1.1295974e+00,\n",
       "          1.0880190e+00, -3.4789890e-01, -5.8990341e-01, -1.5976685e+00,\n",
       "         -8.7909132e-01, -6.0536891e-01,  1.9781919e-01, -1.9903718e+00],\n",
       "        [-8.0113053e-01,  2.0389649e-01,  1.6297401e+00, -9.0563709e-01,\n",
       "         -6.7798518e-02, -2.4683177e+00, -1.4267144e+00,  7.1553266e-01,\n",
       "         -2.8324980e-01,  7.9399645e-01,  1.8801694e+00,  5.0930709e-02,\n",
       "         -7.8409731e-01,  1.0812433e+00, -1.8010370e+00,  3.0674031e-02,\n",
       "         -2.8814590e-01, -2.2774849e+00,  9.9052739e-01, -7.0837247e-01,\n",
       "         -8.3178043e-01,  2.8294122e-01,  4.6732691e-01, -7.0648044e-01,\n",
       "         -5.1842451e-02,  2.1178701e+00,  5.3762019e-01, -4.1793397e-01,\n",
       "          5.8005309e-01,  1.3128568e+00,  1.2065552e+00,  7.5184003e-02,\n",
       "          8.3557002e-02, -1.2721264e+00,  2.4423490e+00,  1.3068947e+00],\n",
       "        [ 5.0957561e-01,  1.9091003e-01, -2.1047899e-01, -1.4542618e+00,\n",
       "          1.7387246e+00, -1.1825180e+00,  7.1935302e-01, -2.7763012e-01,\n",
       "         -9.0177095e-01, -9.5024711e-01, -1.0108083e-01, -2.0686655e+00,\n",
       "          9.5678431e-01,  7.0097393e-01,  6.2342954e-01, -1.0794078e+00,\n",
       "         -7.1791583e-01,  6.5758996e-02, -1.0752428e+00,  1.3185601e+00,\n",
       "         -1.8791244e+00,  1.3243450e+00,  1.6035199e+00, -1.0946788e+00,\n",
       "         -9.0322506e-01, -8.0980164e-01, -2.2502655e-01,  4.9248165e-01,\n",
       "          3.2471347e+00,  8.4458970e-02, -1.0178233e+00,  5.6129140e-01,\n",
       "         -6.4149931e-02,  1.3597116e+00,  4.7336688e+00,  1.7586086e+00],\n",
       "        [ 3.6480451e-01, -5.9308529e-01,  7.2844070e-01,  2.3554870e-01,\n",
       "         -9.0533209e-01, -2.0828788e+00, -5.7364470e-01,  4.7879103e-01,\n",
       "         -9.7162217e-01,  1.8226673e-01,  3.0598762e+00,  2.1014488e+00,\n",
       "         -1.0716501e+00,  1.1971672e+00, -2.2739742e+00, -3.3583349e-01,\n",
       "         -1.0906187e+00, -1.8436294e+00, -6.8623058e-02, -1.4658380e+00,\n",
       "          8.9479440e-01,  2.2986488e+00,  1.0106206e+00, -3.3699915e-01,\n",
       "          9.7191650e-01,  5.8280158e-01, -4.3292400e-01, -3.6549971e-01,\n",
       "          2.7597959e+00,  6.2883925e-01,  8.3815724e-01,  2.9259592e-01,\n",
       "          9.1384751e-01, -8.1695873e-01,  4.4125199e+00,  1.3706715e+00],\n",
       "        [ 4.0452343e-01, -2.1350864e-01, -3.1225348e-01,  4.4948825e-01,\n",
       "          5.9895456e-01,  1.7740719e+00,  1.2520937e+00, -3.5231954e-01,\n",
       "         -3.9391100e-01,  2.0031956e-01,  1.1994744e-01,  3.9081940e-01,\n",
       "         -5.5446696e-01, -5.9065402e-01, -3.0993906e-01, -9.6384937e-01,\n",
       "          3.3968192e-02, -2.8338996e-01, -7.2197264e-01,  6.5847105e-01,\n",
       "          3.5376939e-01,  9.7416443e-01,  1.3180449e+00,  2.0883243e+00,\n",
       "         -5.3580892e-01, -1.2459830e+00, -5.5665213e-01, -4.5558506e-01,\n",
       "          2.6996443e-02, -4.0774202e-01, -5.8551002e-01,  4.7133231e-01,\n",
       "         -7.2651130e-01, -8.2561040e-01, -1.0549593e+00, -6.8716824e-01],\n",
       "        [ 3.0698398e-02,  1.8096989e+00, -9.2837888e-01, -3.1168249e-02,\n",
       "         -1.2066417e+00,  1.9050881e+00, -1.7382053e+00,  2.5442312e+00,\n",
       "         -2.5097257e-01,  2.3932695e+00, -1.3855506e+00, -1.7198411e+00,\n",
       "         -1.6450558e+00,  3.4140706e+00,  5.9617871e-01, -1.5068156e+00,\n",
       "         -1.2362159e+00,  4.2676324e-01, -2.1778560e+00, -8.0010021e-01,\n",
       "         -6.0601300e-01,  6.3021231e-01, -4.0926412e-01, -2.2962611e+00,\n",
       "         -1.5448688e+00, -1.0466028e+00,  1.0366278e+00, -1.3429867e+00,\n",
       "          8.6872831e-02,  2.6924443e+00,  1.3948787e+00, -4.2471287e-01,\n",
       "          1.0931612e+00, -9.9408275e-01, -3.4409532e-01, -1.2210038e+00],\n",
       "        [-3.1542199e+00,  7.1995407e-01,  4.2813554e-01,  1.5846554e+00,\n",
       "         -6.5219885e-01,  6.8744069e-01, -6.9103402e-01,  9.2748797e-01,\n",
       "          9.3084556e-01, -5.7187510e-01,  2.6387022e+00,  1.1746473e+00,\n",
       "          1.3160878e+00,  8.3238661e-02, -1.2898884e+00, -5.0927407e-01,\n",
       "          6.0958403e-01,  1.3160162e+00, -2.0483251e-01, -4.6519342e-01,\n",
       "          1.7396486e+00,  5.7986343e-01,  1.0284219e+00,  8.7395057e-02,\n",
       "          2.1239908e+00, -6.6038835e-01,  1.6053202e+00,  1.4513072e+00,\n",
       "          8.9750934e-01, -1.0624936e+00, -1.8615235e+00,  3.1721208e-02,\n",
       "          2.8711250e-01,  7.9400820e-01,  2.0303702e+00,  2.8131437e-01],\n",
       "        [ 9.7470969e-01,  6.7257404e-01,  3.7770915e-01,  3.9792794e-01,\n",
       "         -1.9784378e-01, -2.6342890e-03, -4.2571235e-03, -3.8283685e-01,\n",
       "          4.2708898e-01,  8.5942495e-01,  7.8127664e-01, -1.1287702e+00,\n",
       "         -2.9312941e-01,  1.0357184e+00, -5.5176479e-01, -9.7823006e-01,\n",
       "          1.4964586e-01, -4.9647009e-01,  4.7523361e-01, -4.2443725e-01,\n",
       "          6.4824766e-01,  8.4003204e-01, -2.2345514e+00, -2.1420550e+00,\n",
       "          1.9221758e+00, -1.3303037e+00,  5.3888434e-01, -7.3678130e-01,\n",
       "          2.0356438e+00, -4.8357180e-01, -4.6314141e-01,  2.3063345e+00,\n",
       "         -9.3900329e-01,  7.6734489e-01,  1.2134970e+00,  2.8538740e+00],\n",
       "        [ 1.4038521e+00,  2.0109987e+00, -1.6391296e+00,  2.1953420e-01,\n",
       "          9.4040239e-01, -7.2185379e-01,  1.5039817e+00,  7.3855048e-01,\n",
       "          7.5778745e-02,  6.7387664e-01, -1.1206133e+00,  1.2812904e+00,\n",
       "         -1.6514055e+00, -6.9198161e-01,  9.2938799e-01, -1.5897329e+00,\n",
       "         -7.1965289e-01,  1.0166786e+00,  6.0354799e-01,  1.6519674e+00,\n",
       "          1.9072297e+00, -3.7013638e-01, -1.0915506e+00,  1.4571456e+00,\n",
       "          2.1672990e-02, -1.0049300e+00,  1.8322267e-01, -2.7134540e+00,\n",
       "         -3.3032659e-01, -9.1332293e-01, -3.4791830e-01,  1.2792357e+00,\n",
       "          1.4259484e+00, -9.0437961e-01, -3.8728637e-01,  7.9249513e-01],\n",
       "        [-5.3162807e-01,  8.7400623e-02, -1.0543973e+00, -3.1787169e-01,\n",
       "          1.9146668e+00,  5.6572467e-01,  5.6325394e-01,  1.8351330e+00,\n",
       "          8.4531879e-01,  1.5503737e+00, -6.0265815e-01, -3.4107499e-02,\n",
       "          6.2525088e-01, -2.1263660e-01,  9.4685249e-02, -7.4051768e-01,\n",
       "          6.1455891e-02,  1.4940709e+00,  1.7575951e+00,  1.9756482e+00,\n",
       "         -8.0021322e-01,  4.8675513e-01,  6.3559264e-01,  5.0873584e-01,\n",
       "         -1.1192101e+00, -2.6285260e+00,  5.1340783e-01,  1.3138821e+00,\n",
       "         -2.2066149e-01,  3.3721469e-02,  2.6940751e+00, -6.2499022e-01,\n",
       "          6.9283813e-01,  1.4025728e-01, -4.0178338e-01, -2.7829533e+00],\n",
       "        [-1.4329911e+00,  1.8097529e+00,  7.5057739e-01,  1.3738281e+00,\n",
       "         -1.0170007e+00, -1.1694167e+00, -2.9288232e-01, -6.7335939e-01,\n",
       "         -6.8479228e-01,  1.1654235e+00, -6.1192828e-01,  6.2119269e-01,\n",
       "          1.2676423e+00, -1.2727717e+00, -2.6393697e+00,  1.1449254e+00,\n",
       "         -6.1588579e-01, -3.2387993e+00,  1.3995254e+00, -7.1987748e-01,\n",
       "          1.5617926e+00, -1.1581751e+00, -3.5913925e+00,  1.1399016e+00,\n",
       "         -7.4736315e-01, -4.1269448e-01, -1.2145700e+00,  1.3861127e+00,\n",
       "          4.8730451e-01, -4.6448955e-01,  9.9285012e-01, -2.2439518e+00,\n",
       "         -3.4649832e+00, -2.5160434e+00,  8.7827086e-01, -1.0874196e-01],\n",
       "        [ 1.3288315e-01, -5.2685849e-02,  1.7642782e+00, -9.5695227e-01,\n",
       "          2.2030802e+00,  1.0157180e-01, -1.3342054e-01, -6.8330765e-01,\n",
       "          1.8075709e+00, -1.2595621e-01,  3.9927319e-01, -1.2738991e+00,\n",
       "          9.1960466e-01,  1.3160603e+00,  1.3431628e+00,  6.5457231e-01,\n",
       "          8.1223989e-01,  1.3836085e+00, -8.8241547e-01,  1.4525595e+00,\n",
       "          2.9298142e-01, -1.9026546e+00,  3.5200283e-01,  1.6188402e-01,\n",
       "         -8.9344221e-01,  2.0582461e+00, -2.7546391e-01, -6.2588423e-01,\n",
       "          3.3802721e-01,  3.8817671e-01, -1.2549539e+00, -3.9182329e-01,\n",
       "          1.0491533e+00,  1.5932623e+00, -1.3834976e+00,  2.1646016e+00],\n",
       "        [-2.3469427e-01, -7.2958402e-02, -3.0302791e-02, -1.1732759e+00,\n",
       "          7.9017174e-01, -2.0598974e+00,  1.3773270e+00, -1.1842006e-01,\n",
       "          5.7695019e-01,  5.9019047e-01,  4.2146727e-01, -1.0396585e+00,\n",
       "          5.1780087e-01, -3.9294729e-01, -1.8272685e+00,  2.5167367e-01,\n",
       "          2.7442691e-01, -2.9280198e+00,  1.5149591e+00,  5.3863585e-01,\n",
       "         -6.0891199e-01, -2.1335420e-01,  2.9281822e-01, -8.6704957e-01,\n",
       "         -1.4279819e+00, -1.6342986e+00,  8.0275482e-01,  7.5717902e-01,\n",
       "          1.1666785e-01,  8.5556835e-01,  3.9462486e-01,  1.0638009e+00,\n",
       "         -1.8371177e+00,  7.7627945e-01,  1.2585767e-01,  4.3989623e-01],\n",
       "        [ 8.9771461e-01, -1.1488178e-01, -1.0694579e+00, -8.4733361e-01,\n",
       "          1.8858559e-01,  8.2321501e-01, -3.1862210e-02,  2.0593241e-01,\n",
       "         -6.6896367e-01, -6.4517570e-01, -8.0314624e-01, -3.7860864e-01,\n",
       "         -2.1598645e-01, -3.7358239e-01,  1.5294185e-01,  9.2111039e-01,\n",
       "         -1.2413460e+00, -2.6236400e-01, -3.9715084e-01,  1.0072372e+00,\n",
       "          1.4839806e-01, -3.3911853e+00,  8.2533062e-01,  1.3649786e+00,\n",
       "         -2.8818591e+00,  4.8966354e-01,  5.0905520e-01,  6.7170590e-02,\n",
       "         -1.2615758e+00,  4.0447605e-01, -6.7382067e-01, -1.2215604e+00,\n",
       "          4.6028244e-01, -1.3048942e+00, -4.0434721e-01, -2.7179546e+00],\n",
       "        [ 1.5860225e+00, -2.8332528e-01, -6.4636874e-01,  5.9133416e-01,\n",
       "          7.7045953e-01,  7.2258544e-01,  1.8384407e-01, -4.1734713e-01,\n",
       "          2.5765163e-01, -5.6863189e-01, -2.4971786e+00, -3.6114483e+00,\n",
       "         -1.2469765e+00,  6.6092485e-01, -1.8427716e+00, -4.8891774e-01,\n",
       "          7.5018957e-02,  1.5457404e-01, -5.0121635e-01,  8.6973006e-01,\n",
       "          7.7171791e-01,  6.3745016e-01, -2.0469794e+00,  2.8802282e-01,\n",
       "          4.4870108e-01, -5.0868958e-01, -6.5690404e-01, -2.0977268e+00,\n",
       "          9.0303379e-01,  3.4996411e-01, -5.1668156e-02,  4.5861197e-01,\n",
       "          5.4581875e-01,  8.5142434e-01,  3.6753559e-01,  6.8805850e-01],\n",
       "        [-5.4383445e-01,  2.3432875e-01,  1.1777872e+00,  5.4202044e-01,\n",
       "          2.7998620e-01,  1.2006582e+00, -3.2972318e-01,  1.0750923e+00,\n",
       "          9.9019939e-01,  9.1273093e-01,  1.8522100e+00,  2.3721220e+00,\n",
       "         -4.7687334e-01, -9.5570976e-01, -1.1140074e+00, -4.9607599e-01,\n",
       "          1.9450814e-01, -1.2513000e+00, -9.2073709e-01, -3.7980574e-01,\n",
       "         -1.1521257e-01, -1.5667624e+00, -1.4191453e+00, -1.6905110e+00,\n",
       "         -1.7059733e-01,  4.7839284e-01,  1.3042343e-01,  3.5377526e-01,\n",
       "         -3.8716357e+00,  9.6674435e-02,  5.7988369e-01, -5.2843136e-01,\n",
       "         -3.1728971e-01,  1.6763318e+00, -4.0421867e+00, -1.0800635e+00],\n",
       "        [ 7.0607412e-01, -1.1396169e-02,  4.5794618e-01,  7.8833562e-01,\n",
       "         -1.0608892e+00,  1.2964380e+00, -9.2558229e-01,  2.6929003e-01,\n",
       "         -5.9694850e-01, -1.7668453e-01, -3.7676874e-01, -4.2342556e-01,\n",
       "          1.1196520e+00,  1.3563229e-01,  2.9029832e+00,  1.0346475e+00,\n",
       "          1.3557838e-01,  8.2416677e-01, -1.1927723e+00, -2.9373753e-01,\n",
       "          1.3940002e+00, -1.4526841e-01,  1.1496123e-02,  6.1571962e-01,\n",
       "          3.4217581e-01, -1.3960269e-01,  6.6848958e-01,  2.0712552e+00,\n",
       "         -3.2122579e-01, -1.9562933e-01,  2.1829721e-01,  1.3769283e+00,\n",
       "          7.0786512e-01,  1.4246001e+00, -5.8833480e-01,  9.1213351e-03],\n",
       "        [ 2.3011352e-01, -1.7452749e-03,  3.9101021e+00, -1.4708852e+00,\n",
       "          3.3485979e-01,  2.2467613e+00,  6.6634125e-01,  3.4198242e-01,\n",
       "          7.5290626e-01,  4.8784506e-01,  2.1763120e+00, -9.8157316e-01,\n",
       "          1.0581408e+00,  1.8623263e+00, -2.3753977e+00,  9.1237736e-01,\n",
       "          2.4051178e+00, -7.6578683e-01, -4.7058356e-01,  1.0428490e-01,\n",
       "          5.4602432e-01,  3.9052796e-01,  1.6330298e+00, -1.2116796e+00,\n",
       "          1.4327792e+00,  3.3446777e-01,  1.4806648e+00,  1.2949736e+00,\n",
       "          3.2695622e+00,  2.4112742e+00,  9.9931413e-01, -1.0291127e+00,\n",
       "          9.8526406e-01, -8.2135588e-02, -5.3172585e-02,  1.4672101e+00],\n",
       "        [ 1.3158575e+00,  4.1014621e-01, -5.9621364e-01, -4.9309891e-02,\n",
       "          5.0185597e-01,  1.4928766e+00, -3.3151749e-01, -1.1609577e+00,\n",
       "          6.1631787e-01,  6.0107768e-01, -7.4179250e-01, -1.4021275e+00,\n",
       "          9.1170415e-02,  1.4406690e-01, -9.9975854e-01,  1.8584046e+00,\n",
       "         -3.7807041e-01, -5.9948915e-01, -4.5794669e-01,  9.9254668e-01,\n",
       "          5.0990176e-01, -2.4638021e+00, -7.4291301e-01, -1.2586491e-01,\n",
       "         -1.5936445e+00, -1.6741070e+00, -4.6136874e-01,  9.1972345e-01,\n",
       "         -1.0289918e-01,  3.6632082e-01,  1.5760477e-01, -5.4794616e-01,\n",
       "         -3.7364170e-02, -1.0086013e+00, -2.6499512e-02, -3.5681483e-01],\n",
       "        [-1.6943584e-01,  1.1408397e+00, -2.1735234e+00, -6.4802873e-01,\n",
       "          1.6767805e+00, -5.0499755e-01, -1.7233859e-01,  2.2027500e+00,\n",
       "          5.0065714e-01,  1.3018788e+00, -3.1888669e+00, -9.5093113e-01,\n",
       "         -9.6698135e-01,  5.9217963e-02,  1.3582978e+00, -6.5883714e-01,\n",
       "          3.7924683e-01,  9.0077561e-01, -6.8998218e-01,  1.8963413e+00,\n",
       "         -7.9197538e-01, -1.2380877e+00, -4.2195243e-01,  1.9151560e+00,\n",
       "         -8.1157315e-01,  8.7988102e-01,  5.5677527e-01, -9.7960547e-02,\n",
       "         -3.4346478e+00, -4.5201153e-01,  1.4419711e+00,  8.1007516e-01,\n",
       "         -8.7981981e-01,  8.4917426e-01, -3.1007314e+00, -9.0424424e-01],\n",
       "        [-3.8327196e-01, -9.7450191e-01, -2.2122960e+00,  1.7292385e+00,\n",
       "         -3.1892285e-01, -7.0936149e-01, -1.0515091e+00, -1.3498361e+00,\n",
       "         -3.7210781e-02, -3.8239896e-01, -3.8796523e-01,  1.6134962e+00,\n",
       "          8.2629728e-01, -5.0856602e-01,  1.7322032e+00,  1.6375557e+00,\n",
       "          4.2584348e-01,  3.9773023e-01,  1.2192118e+00, -1.9018926e-01,\n",
       "          2.1428902e+00,  1.6284239e+00, -1.4166347e+00,  2.8279945e-01,\n",
       "          4.5054853e-01,  1.2791355e+00, -5.2380997e-01,  2.2235371e-01,\n",
       "         -2.1496643e-01, -6.4123529e-01, -5.9150231e-01,  3.3849514e-01,\n",
       "          1.7887838e+00,  1.1055183e+00,  1.1397569e+00, -7.0290297e-02],\n",
       "        [-2.4457470e-01,  6.4254904e-01,  2.7365644e+00, -1.2049848e+00,\n",
       "         -1.5306860e-01, -3.7933019e-01,  2.6500349e+00, -3.1007805e-01,\n",
       "          1.6531172e+00,  2.3728597e+00, -9.7204292e-01,  2.9255971e-01,\n",
       "          2.9131205e+00, -1.4733130e+00, -9.4832069e-01,  2.1476858e+00,\n",
       "          1.7080115e+00, -4.8185511e+00,  4.3525476e+00,  1.3990951e+00,\n",
       "          3.7752512e+00, -5.7534891e-01,  7.4667692e+00,  3.1220860e+00,\n",
       "         -3.8423424e+00, -4.4675908e+00,  2.4761059e+00, -4.4650933e-01,\n",
       "          4.0305247e+00,  2.4825761e+00, -2.1931684e+00, -6.1817449e-01,\n",
       "          3.5372672e+00, -2.5585008e+00,  6.0460512e-02, -5.0926733e+00]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/dense/bias:0' shape=(36,) dtype=float32, numpy=\n",
       " array([-2.530135  , -2.84307   , -3.0209172 ,  0.4277452 , -2.0034385 ,\n",
       "        -5.4352665 , -1.5170107 , -3.7636707 , -3.7164648 , -1.8938545 ,\n",
       "        -1.9662273 , -1.8952056 , -1.5292741 , -1.60981   , -2.7787516 ,\n",
       "        -3.3961556 , -3.2385235 , -1.0786233 , -4.724994  , -0.8084009 ,\n",
       "        -1.0901469 , -0.55848616, -1.4279184 , -2.7447343 ,  0.2008206 ,\n",
       "        -1.0024451 , -2.3246307 , -2.3228526 , -2.5476787 , -2.1515052 ,\n",
       "        -4.362351  ,  0.8268827 , -0.0604331 , -2.5372295 , -4.257223  ,\n",
       "        -1.691162  ], dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/dense_1/kernel:0' shape=(36, 36) dtype=float32, numpy=\n",
       " array([[-0.1415375 , -0.6691847 ,  0.2606615 , ..., -0.3350074 ,\n",
       "         -0.7200519 , -2.8787549 ],\n",
       "        [ 0.4881626 ,  0.32563677,  0.29666635, ...,  0.1864092 ,\n",
       "         -1.0684161 , -0.35135975],\n",
       "        [ 0.1486383 , -0.68479496,  0.16738237, ..., -1.5634161 ,\n",
       "         -0.26719934,  0.79869646],\n",
       "        ...,\n",
       "        [-0.67866695,  0.07237787, -0.19850068, ...,  0.39743707,\n",
       "          0.13185614,  0.91058695],\n",
       "        [ 0.06031871, -0.83894557, -0.22929893, ..., -0.34208283,\n",
       "          0.5523417 ,  0.13326241],\n",
       "        [ 0.5944235 , -0.08590259,  0.5080632 , ...,  0.33424658,\n",
       "         -0.20762978,  0.08065105]], dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/dense_1/bias:0' shape=(36,) dtype=float32, numpy=\n",
       " array([-1.7240517, -2.5380182, -2.193711 , -3.8226109, -0.5866823,\n",
       "        -3.382344 , -2.1264262, -5.624993 , -3.2153   , -2.5020146,\n",
       "        -0.3758571, -2.260947 , -2.6850574, -3.7206511, -1.5467939,\n",
       "        -1.0766503, -2.0373833, -5.5735283, -2.7870686, -3.3491392,\n",
       "        -2.2990158, -3.1626027, -4.9341593, -6.3168745, -2.6081867,\n",
       "        -5.7525215, -2.392663 , -1.4087553, -3.0455163, -3.8923779,\n",
       "        -2.3436677, -6.1080685, -3.1137497, -3.5972366, -5.0074024,\n",
       "        -6.616269 ], dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/dense_2/kernel:0' shape=(33892, 1) dtype=float32, numpy=\n",
       " array([[-0.04766771],\n",
       "        [-0.06411462],\n",
       "        [ 0.64323556],\n",
       "        ...,\n",
       "        [-0.09771827],\n",
       "        [ 0.0713594 ],\n",
       "        [ 0.11568052]], dtype=float32)>,\n",
       " <tf.Variable 'hybrid_model_parallel/dense_2/bias:0' shape=(1,) dtype=float32, numpy=array([0.13796139], dtype=float32)>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the weights objects\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 - Save results and test ids (weights saved within epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Import results from file\\nimported_results = pd.read_csv(modelResPath).to_dict(orient='list')\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save results to file\n",
    "pd.DataFrame.from_dict(results).to_csv(modelResPath, index=False)\n",
    "\n",
    "\"\"\"\n",
    "#Import results from file\n",
    "imported_results = pd.read_csv(modelResPath).to_dict(orient='list')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Import train_ids from file and regenerate test_meta_dict\\ndf = pd.read_csv(test_meta_dict_Path)\\nimported_train_ids = [(df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]) for i in range(len(df))]\\ntest_meta_dict, test_pos_isic_id, test_pos_target = make_meta_dict(metadata, imported_train_ids)\\ndel df\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save test_ids to file\n",
    "pd.DataFrame(test_ids).to_csv(test_ids_Path, index=False)\n",
    "\n",
    "'''\n",
    "#Import train_ids from file and regenerate test_meta_dict\n",
    "df = pd.read_csv(test_meta_dict_Path)\n",
    "imported_train_ids = [(df.iloc[i,0], df.iloc[i,1], df.iloc[i,2]) for i in range(len(df))]\n",
    "test_meta_dict, test_pos_isic_id, test_pos_target = make_meta_dict(metadata, imported_train_ids)\n",
    "del df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimported_weights = model.load_weights(savePath + \"Model_Last_Epoch.weights.h5\", skip_mismatch=False)\\n\\n#Taken from https://machinelearningmastery.com/save-load-keras-deep-learning-models/\\n# load json and create model\\njson_file = open(savePath + \\'model.json\\', \\'r\\')\\nloaded_model_json = json_file.read()\\njson_file.close()\\nloaded_model = tf.keras.models.model_from_json(loaded_model_json)\\n# load weights into new model\\n#loaded_model.load_weights(\"Model_Last_Epoch.weights.h5\")\\n#print(\"Loaded model from disk\")\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try importing hdf5 and json for model\n",
    "\"\"\"\n",
    "imported_weights = model.load_weights(savePath + \"Model_Last_Epoch.weights.h5\", skip_mismatch=False)\n",
    "\n",
    "#Taken from https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
    "# load json and create model\n",
    "json_file = open(savePath + 'model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "#loaded_model.load_weights(\"Model_Last_Epoch.weights.h5\")\n",
    "#print(\"Loaded model from disk\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6 - Plot the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 2.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the training and validation losses\n",
    "\n",
    "#Convert loss results into a dataframe\n",
    "result_preproc = pd.DataFrame({\n",
    "    'Epoch': [i+1 for i in range(len(results[\"loss\"]))], \n",
    "    'Train': results[\"loss\"],\n",
    "    'Validate': results[\"val_loss\"]\n",
    "    })\n",
    "\n",
    "# Convert dataframe from wide to long format\n",
    "df = pd.melt(result_preproc, ['Epoch'])\n",
    "\n",
    "#Make plot\n",
    "g = sns.lineplot(data=df, x='Epoch', y='value', hue='variable')\n",
    "g.set_title(\"Loss Curves\")\n",
    "g.legend_.set_title(\"Loss\")\n",
    "g.set_ylabel('Loss')\n",
    "g.set_ylim(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Predict Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 - Create a function to make reinitalization of test dataset easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple simple function to ititialize the test dataset using global variables\n",
    "def init_test_dataset():\n",
    "    return make_dataset(hdf5_file, test_meta_dict, test_pos_isic_id, test_pos_target, batch_size = test_batch_size, apply_hair_removal=apply_hair_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 - Retrieve y_test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test batches in dataset: 2387\n"
     ]
    }
   ],
   "source": [
    "#Test dataset basic size information: nb of samples and batch size\n",
    "nb_test_batches = int(np.ceil(len(test_meta_dict)/test_batch_size))\n",
    "print(\"Total test batches in dataset:\", nb_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 07:28:53.630741: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "#Retrieve real values for the target in the test dataset\n",
    "y_test = []\n",
    "test_dataset = init_test_dataset()\n",
    "for item in test_dataset.take(nb_test_batches):\n",
    "    img_meta, targ = item\n",
    "    y_test.extend(targ.numpy().flatten())\n",
    "#Convert to numpy array (mathematical operations are faster)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 - Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2387/2387 [==============================] - 687s 288ms/step\n",
      "Shape of prediction data: (76376,)\n"
     ]
    }
   ],
   "source": [
    "#Reinitialize the test dataset (necessary to start at beginning)\n",
    "test_dataset = init_test_dataset()\n",
    "#Retrieve predictions\n",
    "y_prob = model.predict(test_dataset, steps = nb_test_batches)\n",
    "y_prob = y_prob.flatten()\n",
    "#Put predictionsin a numpy array\n",
    "y_pred = np.array([round(i) for i  in y_prob])\n",
    "print(\"Shape of prediction data:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 - Save y_test and y_pred in exported file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Import results from file\\nimported_test_results = pd.read_csv(testResPath)\\ny_test = np.array(imported_test_results[\"y_test\"])\\ny_prob = np.array(imported_test_results[\"y_prob\"])\\ny_pred = np.array(imported_test_results[\"y_pred\"])\\ndel imported_test_results\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save test results to file\n",
    "pd.DataFrame({\"y_test\": y_test, \"y_prob\": y_prob, \"y_pred\": y_pred}).to_csv(testResPath, index=False)\n",
    "\n",
    "\"\"\"\n",
    "#Import results from file\n",
    "imported_test_results = pd.read_csv(testResPath)\n",
    "y_test = np.array(imported_test_results[\"y_test\"])\n",
    "y_prob = np.array(imported_test_results[\"y_prob\"])\n",
    "y_pred = np.array(imported_test_results[\"y_pred\"])\n",
    "del imported_test_results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5 - Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the loss\n",
    "loss = sum(abs(y_test - y_pred))/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine true/false positives and negatives\n",
    "pos_indices = y_test == 1\n",
    "neg_indices = y_test == 0\n",
    "\n",
    "#True positives\n",
    "true_pos = sum(abs(y_test[pos_indices] == y_pred[pos_indices]))\n",
    "\n",
    "#False negatives\n",
    "false_neg = sum(abs(y_test[pos_indices] != y_pred[pos_indices]))\n",
    "\n",
    "#True negatives\n",
    "true_neg = sum(abs(y_test[neg_indices] == y_pred[neg_indices]))\n",
    "\n",
    "#False positives\n",
    "false_pos = sum(abs(y_test[neg_indices] != y_pred[neg_indices]))\n",
    "\n",
    "#Precision\n",
    "try:\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "except:\n",
    "    precision = np.nan\n",
    "\n",
    "#Recall (sensitivity)\n",
    "try:\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "except:\n",
    "    recall = np.nan\n",
    "\n",
    "#Specificity\n",
    "try:\n",
    "    specificity = true_neg / (true_neg + false_pos)\n",
    "except:\n",
    "    specificity = np.nan\n",
    "\n",
    "#F1 Score\n",
    "try:\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "except:\n",
    "    f1_score = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC and partial AUC\n",
    "precision_prob, recall_prob, _ = precision_recall_curve(y_test, y_prob)\n",
    "auc_pr = auc(recall_prob, precision_prob)\n",
    "auc_roc = roc_auc_score(y_test, y_prob)\n",
    "partial_auc_roc = auc_roc - roc_auc_score(y_test, y_prob, max_fpr=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TEST RESULTS---\n",
      "True positives: 45\n",
      "False positives: 3759\n",
      "True negatives: 72548\n",
      "False negatives: 24\n",
      "\n",
      "Sensitivity: 0.6521739130434783\n",
      "Specificity: 0.9507384643610678\n",
      "\n",
      "Precision: 0.011829652996845425\n",
      "Recall: 0.6521739130434783\n",
      "\n",
      "F1 Score: 0.023237800154918664\n",
      "Loss on test data: 0.04953126636639782\n",
      "\n",
      "AUC-ROC Score:  0.8881991376178189\n",
      "Partial AUC-ROC > 0.8:  0.0022859050356528465\n",
      "AUC-PR:  0.02588650231107967\n"
     ]
    }
   ],
   "source": [
    "print(\"---TEST RESULTS---\")\n",
    "print(\"True positives:\", true_pos)\n",
    "print(\"False positives:\", false_pos)\n",
    "print(\"True negatives:\", true_neg)\n",
    "print(\"False negatives:\", false_neg)\n",
    "print()\n",
    "print(\"Sensitivity:\", recall)\n",
    "print(\"Specificity:\", specificity)\n",
    "print()\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print()\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"Loss on test data:\", loss)\n",
    "print()\n",
    "print(\"AUC-ROC Score: \", auc_roc)\n",
    "print(\"Partial AUC-ROC > 0.8: \", partial_auc_roc)\n",
    "print(\"AUC-PR: \", auc_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAHFCAYAAABxS8rQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABczUlEQVR4nO3deVxU5f4H8M+wzLAIE4swjqKiEUpgGhqit1BRSAW0TQ3jShJqmERCer12lRYhl9TSXK+JmYWWaeZCWKaFgguGhdttIcUEIUU2kfX5/eGPUyOoMxwQdT7v+zqv25zzPec8ZxiZL9/nec5RCCEEiIiIiG7BpLUbQERERHcHJg1ERESkFyYNREREpBcmDURERKQXJg1ERESkFyYNREREpBcmDURERKQXJg1ERESkFyYNREREpBcmDTL8+OOPeP755+Hq6goLCwu0adMGDz/8MObNm4dLly616Ll/+OEH+Pn5Qa1WQ6FQYPHixc1+DoVCgfj4+GY/7q0kJSVBoVBAoVBg7969DbYLIXD//fdDoVBgwIABTTrHsmXLkJSUZNA+e/fuvWGbWto333yD3r17w9raGgqFAlu3bm007vfff5feuxv97MaPHy/FNKcBAwY0+efRuXNnhIeH6xVX33aFQoE2bdrAx8cHH374YZPOa6j6z+bvv/8urWvqdSckJDT6c2zNzxnRrZi1dgPuVqtXr0ZUVBTc3d3x6quvwsPDA9XV1Thy5AhWrFiB9PR0bNmypcXOP378eJSXlyM5ORl2dnbo3Llzs58jPT0dHTp0aPbj6svGxgZr1qxp8At53759+PXXX2FjY9PkYy9btgyOjo56fVHVe/jhh5Geng4PD48mn7cphBAYNWoUHnjgAWzbtg3W1tZwd3e/6T42NjZISkrCrFmzYGLy198GZWVl+PTTT2Fra4uSkpKWbnqL6N+/PxYsWAAAOHfuHBYsWIBx48ahvLwcL7744m1vz7Jly5q0X0JCAp5++mmMHDlSZ31rfc6I9MGkoQnS09Px4osvYsiQIdi6dStUKpW0bciQIYiNjUVKSkqLtiE7OxuRkZEYOnRoi52jb9++LXZsfYwePRobNmzA+++/D1tbW2n9mjVr4Ovre9u+9Kqrq6FQKGBra9sq78n58+dx6dIlPPHEE/D399drn9GjR+O///0vvvnmGwwZMkRav3HjRtTW1mLkyJH46KOPWqrJLeq+++7T+TkMHjwYnTp1wsKFC2+YNNTW1qKmpkbn32pzae4v99b6nBHpg90TTZCQkACFQoFVq1Y1+ktIqVQiJCREel1XV4d58+ahW7duUKlUcHJywj//+U+cO3dOZ78BAwbA09MThw8fxqOPPgorKyt06dIFb7/9Nurq6gD8VR6tqanB8uXLdcrM8fHxjZacGyup7tmzBwMGDICDgwMsLS3RsWNHPPXUU7hy5YoU01iJOzs7GyNGjICdnR0sLCzQs2dPrFu3Tiemvrz6ySefYObMmdBqtbC1tcXgwYNx+vRp/d5kAM8++ywA4JNPPpHWFRcXY/PmzRg/fnyj+7z++uvw8fGBvb09bG1t8fDDD2PNmjX4+3PZOnfujOPHj2Pfvn3S+1dfqalv+/r16xEbG4v27dtDpVLhl19+aVA2/vPPP+Hi4oJ+/fqhurpaOv6JEydgbW2NsLCwW15jWloa/P39YWNjAysrK/Tr1w87duyQtsfHx0vVnunTp+u09Wbc3d3Rr18/fPDBBzrrP/jgAzz55JNQq9UN9tH3cyqEwLx589CpUydYWFjg4Ycfxq5duxptR0lJCeLi4uDq6gqlUon27dsjJiYG5eXlt7wGfd13331wd3fHmTNnAPzVRTNv3jy89dZbcHV1hUqlwrfffgsAOHLkCEJCQmBvbw8LCwv06tULmzZtanDcjIwM9O/fHxYWFtBqtZgxY4bOz7leY90TlZWVeOONN9C9e3dYWFjAwcEBAwcOxIEDBwBc+7dVXl6OdevWSZ/B+mPcqHti27Zt8PX1hZWVFWxsbDBkyBCkp6frxNT/Djh+/DieffZZqNVqODs7Y/z48SguLtaJ/fTTT+Hj4wO1Wi39rrnRvysiiSCD1NTUCCsrK+Hj46P3PhMmTBAAxEsvvSRSUlLEihUrRNu2bYWLi4soLCyU4vz8/ISDg4Nwc3MTK1asELt37xZRUVECgFi3bp0QQoiCggKRnp4uAIinn35apKeni/T0dCGEELNnzxaN/UjXrl0rAIicnBwhhBA5OTnCwsJCDBkyRGzdulXs3btXbNiwQYSFhYmioiJpPwBi9uzZ0utTp04JGxsb0bVrV/Hhhx+KHTt2iGeffVYAEHPnzpXivv32WwFAdO7cWYwdO1bs2LFDfPLJJ6Jjx47Czc1N1NTU3PT9qm/v4cOHRVhYmHjkkUekbcuXLxfW1taipKREPPjgg8LPz09n3/DwcLFmzRqxe/dusXv3bvHmm28KS0tL8frrr0sxR48eFV26dBG9evWS3r+jR4/qtL19+/bi6aefFtu2bRPbt28XFy9elLZ9++230rHS0tKEmZmZeOWVV4QQQpSXlwsPDw/RrVs3UVZWdtPr3Lt3rzA3Nxfe3t5i48aNYuvWrSIgIEAoFAqRnJwshBAiNzdXfP755wKAmDJlik5bG5OTkyMAiPnz54s1a9YICwsLcenSJSHEtZ8fALFnzx4xefLkBp8VfT+n9Z+ziIgIsWvXLrFq1SrRvn17odFodH4e5eXlomfPnsLR0VEsXLhQfP311+Ldd98VarVaDBo0SNTV1UmxnTp1EuPGjbvp+1UfN3z4cJ11VVVVwsnJSWi1Wp33oH379mLgwIHis88+E6mpqSInJ0fs2bNHKJVK8eijj4qNGzeKlJQUER4eLgCItWvXSsc8fvy4sLKyEh4eHuKTTz4RX3zxhQgMDBQdO3bU+bckxLV/t3+/7urqajFw4EBhZmYm4uLixM6dO8W2bdvEv//9b/HJJ58IIYRIT08XlpaWYtiwYdJn8Pjx40II0ejnbMOGDQKACAgIEFu3bhUbN24U3t7eQqlUiu+//77Bz8bd3V3MmjVL7N69WyxcuFCoVCrx/PPPS3EHDhwQCoVCjBkzRuzcuVPs2bNHrF27VoSFhd3yZ0DGjUmDgfLz8wUAMWbMGL3iT548KQCIqKgonfUHDx4UAMS///1vaZ2fn58AIA4ePKgT6+HhIQIDA3XWARCTJ0/WWadv0vDZZ58JACIrK+umbb8+aRgzZoxQqVTi7NmzOnFDhw4VVlZW4vLly0KIv37pDRs2TCdu06ZNAoCU5NzI35OG+mNlZ2cLIYTo06ePCA8PF0KIRpOGv6utrRXV1dXijTfeEA4ODjpfUjfat/58jz322A23/f2XuRBCzJ07VwAQW7ZsEePGjROWlpbixx9/vOk1CiFE3759hZOTkygtLZXW1dTUCE9PT9GhQwepvX9PBG7l77GlpaWiTZs2YunSpUIIIV599VXh6uoq6urqGiQN+n5Oi4qKhIWFhXjiiSd04vbv3y8A6LyniYmJwsTERBw+fFgntv7zt3PnTmmdIUnDsGHDRHV1taiurhY5OTli3LhxAoB49dVXdd6Drl27iqqqKp39u3XrJnr16iWqq6t11gcFBYl27dqJ2tpaIYQQo0ePFpaWliI/P1+KqampEd26dbtl0vDhhx8KAGL16tU3vRZra+tGr/n6z1ltba3QarXCy8tLap8QQpSWlgonJyfRr18/aV3974B58+bpHDMqKkpYWFhIn6kFCxYIANK/WSJ9sXuihdWXRK8fcPfII4+ge/fu+Oabb3TWazQaPPLIIzrrevToIZVem0PPnj2hVCoxYcIErFu3Dr/99pte++3Zswf+/v5wcXHRWR8eHo4rV640KJX+vYsGuHYdAAy6Fj8/P3Tt2hUffPABfvrpJxw+fPimJdQ9e/Zg8ODBUKvVMDU1hbm5OWbNmoWLFy+ioKBA7/M+9dRTese++uqrGD58OJ599lmsW7cOS5YsgZeX1033KS8vx8GDB/H000+jTZs20npTU1OEhYXh3LlzBnXlNKZNmzZ45pln8MEHH6CmpgYffvghnn/++Ua7sPT9nKanp+Pq1asYO3asTly/fv3QqVMnnXXbt2+Hp6cnevbsiZqaGmkJDAyUNTtg586dMDc3h7m5OVxdXbFp0yZMmTIFb731lk5cSEgIzM3Npde//PILTp06JbX9720aNmwY8vLypPf822+/hb+/P5ydnaX9TU1NMXr06Fu2b9euXbCwsGi2Uv/p06dx/vx5hIWF6QxqbdOmDZ566ilkZGTodCsCjf/bu3r1qvRvoE+fPgCAUaNGYdOmTfjjjz+apa1072PSYCBHR0dYWVkhJydHr/iLFy8CANq1a9dgm1arlbbXc3BwaBCnUqlQUVHRhNY2rmvXrvj666/h5OSEyZMno2vXrujatSvefffdm+538eLFG15H/fa/u/5a6sd/GHItCoUCzz//PD766COsWLECDzzwAB599NFGYw8dOoSAgAAA12a37N+/H4cPH8bMmTMNPm9j13mzNoaHh+Pq1avQaDR6jWUoKiqCEMKg97MpIiIicPToUcyZMweFhYU3nC2i7+e0/v81Gk2DuOvXXbhwAT/++KP0BV+/2NjYQAiBP//8s0nX9I9//AOHDx/GkSNHcOLECVy+fBnvvfcelEqlTtz113LhwgUAQFxcXIM2RUVFAYDUposXL+p1jY0pLCyEVqvV+YKX41Y/m7q6OhQVFemsv9W/vcceewxbt25FTU0N/vnPf6JDhw7w9PTUGT9E1BjOnjCQqakp/P39sWvXLpw7d+6WUxLr//Hm5eU1iD1//jwcHR2brW0WFhYArg3C+vsAzcZ+OT/66KN49NFHUVtbiyNHjmDJkiWIiYmBs7MzxowZ0+jxHRwckJeX12D9+fPnAaBZr+XvwsPDMWvWLKxYsQJz5sy5YVxycjLMzc2xfft26b0AcMN7GtyMIfcwyMvLw+TJk9GzZ08cP34ccXFxeO+99266j52dHUxMTFr8/ezfvz/c3d3xxhtvYMiQIQ2qRPX0/ZzWx+Xn5zc4Rn5+vs4gTUdHR1haWjYYjPn37U2hVqvRu3fvW8Zd/zOsP9+MGTPw5JNPNrpP/VRWBweHG17jrbRt2xZpaWmoq6trlsTh7z+b650/fx4mJiaws7Mz+LgjRozAiBEjUFlZiYyMDCQmJiI0NBSdO3eGr6+v7HbTvYmVhiaYMWMGhBCIjIxEVVVVg+3V1dX48ssvAQCDBg0CgAbT2w4fPoyTJ0/qPYVOH/W/sH/88Ued9fVtaYypqSl8fHzw/vvvAwCOHj16w1h/f3/s2bNH+lKr9+GHH8LKyqrFpom1b98er776KoKDgzFu3LgbxikUCpiZmcHU1FRaV1FRgfXr1zeIba7qTW1tLZ599lkoFArs2rULiYmJWLJkCT7//POb7mdtbQ0fHx98/vnnOu2oq6vDRx99hA4dOuCBBx6Q3T4AeO211xAcHIzY2Ngbxuj7Oe3bty8sLCywYcMGnbgDBw406HYKCgrCr7/+CgcHB/Tu3bvB0hL3FrkZd3d3uLm54dixY422p3fv3tK9PwYOHIhvvvlGqk4A137WGzduvOV5hg4diqtXr97y5mH6fgbd3d3Rvn17fPzxxzqzgMrLy7F582ZpRkVTqVQq+Pn5Ye7cuQCu3TiO6EZYaWgCX19fLF++HFFRUfD29saLL76IBx98ENXV1fjhhx+watUqeHp6Ijg4GO7u7pgwYQKWLFkCExMTDB06FL///jv+85//wMXFBa+88kqztWvYsGGwt7dHREQE3njjDZiZmSEpKQm5ubk6cStWrMCePXswfPhwdOzYEVevXpX+Ghw8ePANjz979mxs374dAwcOxKxZs2Bvb48NGzZgx44dmDdvXqPT+JrL22+/fcuY4cOHY+HChQgNDcWECRNw8eJFLFiwoNFpsV5eXkhOTsbGjRvRpUsXWFhY3HIcQmNmz56N77//HqmpqdBoNIiNjcW+ffsQERGBXr16wdXV9Yb7JiYmYsiQIRg4cCDi4uKgVCqxbNkyZGdn45NPPmm2OzY+99xzeO65524ao+/n1M7ODnFxcXjrrbfwwgsv4JlnnkFubi7i4+MblO5jYmKwefNmPPbYY3jllVfQo0cP1NXV4ezZs0hNTUVsbCx8fHya5Rr1tXLlSgwdOhSBgYEIDw9H+/btcenSJZw8eRJHjx7Fp59+CuBaorVt2zYMGjQIs2bNgpWVFd5//329poo+++yzWLt2LSZNmoTTp09j4MCBqKurw8GDB9G9e3epkufl5YW9e/fiyy+/RLt27WBjY9PoTbtMTEwwb948jB07FkFBQZg4cSIqKysxf/58XL58Wa9/G9ebNWsWzp07B39/f3To0AGXL1/Gu+++C3Nzc/j5+Rl8PDIirTsO8+6WlZUlxo0bJzp27CiUSqWwtrYWvXr1ErNmzRIFBQVSXG1trZg7d6544IEHhLm5uXB0dBTPPfecyM3N1Tmen5+fePDBBxucZ9y4caJTp04669DI7AkhhDh06JDo16+fsLa2Fu3btxezZ88W//3vf3VGfKenp4snnnhCdOrUSahUKuHg4CD8/PzEtm3bGpzj77MnhBDip59+EsHBwUKtVgulUikeeughnalqQvw1+vvTTz/VWV8/qv36+Ov9ffbEzTQ2A+KDDz4Q7u7uQqVSiS5duojExESxZs2aBiPef//9dxEQECBsbGwEAOn9vVHb/76tflR7amqqMDExafAeXbx4UXTs2FH06dNHVFZW3vQavv/+ezFo0CBhbW0tLC0tRd++fcWXX36pE9PU2RM309iUS30/p3V1dSIxMVG4uLgIpVIpevToIb788ssGswiEEKKsrEy89tprwt3dXSiVSqFWq4WXl5d45ZVXdGYmyJlyaeh7cOzYMTFq1Cjh5OQkzM3NhUajEYMGDRIrVqzQidu/f7/o27evUKlUQqPRiFdffVWsWrXqlrMnhBCioqJCzJo1S7i5uQmlUikcHBzEoEGDxIEDB6SYrKws0b9/f2FlZaUz8+RGs3S2bt0qfHx8hIWFhbC2thb+/v5i//79OjH1syf+PkVWiIYzqLZv3y6GDh0q2rdvL5RKpXBychLDhg3Tmb5J1BiFEH+rdxERERHdAMc0EBERkV6YNBAREZFemDQQERGRXpg0EBERkV6YNBAREZFemDQQERGRXu7qmzvV1dXh/PnzsLGxabYb4RAR0e0jhEBpaWmzPq+jMVevXm30Dr6GUiqVOrepNzZ3ddJw/vz5G95Ln4iI7h65ubm3fJZPU129ehWWNg5AzZVbB9+CRqNBTk6O0SYOd3XSUH+feKXHOChMlbeIJro7nfrK8NsEE90tSktL0MPdVfp93hKqqqqAmitQeYwD5HxX1FYh/8Q6VFVVMWm4G9V3SShMlUwa6J5lY2vb2k0ganG3pYvZzELWd4VQcBjgXZ00EBER6U0BQE5ywqFzTBqIiMhIKEyuLXL2N3J8B4iIiEgvrDQQEZFxUChkdk+wf4JJAxERGQd2T8jGd4CIiIj0wqSBiIiMQ333hJzFAJ07d4ZCoWiwTJ48GcC1u2HGx8dDq9XC0tISAwYMwPHjx3WOUVlZiSlTpsDR0RHW1tYICQnBuXPndGKKiooQFhYGtVoNtVqNsLAwXL58WSfm7NmzCA4OhrW1NRwdHREdHd2kO2QyaSAiIiNh8lcXRVMWA78yDx8+jLy8PGnZvXs3AOCZZ54BAMybNw8LFy7E0qVLcfjwYWg0GgwZMgSlpaXSMWJiYrBlyxYkJycjLS0NZWVlCAoKQm1trRQTGhqKrKwspKSkICUlBVlZWQgLC5O219bWYvjw4SgvL0daWhqSk5OxefNmxMbGGvwOKoQQwuC97hAlJSVQq9VQeUXy5k50zzqXtri1m0DUYkpLSuCqdUBxcTFsW+hGZtJ3hffLUJipmnwcUVOJysx3m9zWmJgYbN++HT///DMAQKvVIiYmBtOnTwdwrarg7OyMuXPnYuLEiSguLkbbtm2xfv16jB49GsBfj0/YuXMnAgMDcfLkSXh4eCAjIwM+Pj4AgIyMDPj6+uLUqVNwd3fHrl27EBQUhNzcXGi1WgBAcnIywsPDUVBQYNC1sNJARETGoZm6J0pKSnSWysrKW566qqoKH330EcaPHw+FQoGcnBzk5+cjICBAilGpVPDz88OBAwcAAJmZmaiurtaJ0Wq18PT0lGLS09OhVqulhAEA+vbtC7VarRPj6ekpJQwAEBgYiMrKSmRmZhr0FjJpICIi4yCna+JvMy9cXFyk8QNqtRqJiYm3PPXWrVtx+fJlhIeHAwDy8/MBAM7Ozjpxzs7O0rb8/HwolUrY2dndNMbJyanB+ZycnHRirj+PnZ0dlEqlFKMvTrkkIiIyQG5urk5JX6W6dZfHmjVrMHToUJ2/9oGGz9wQQtzyORzXxzQW35QYfbDSQERExqGZuidsbW11llslDWfOnMHXX3+NF154QVqn0WgAoMFf+gUFBVJVQKPRoKqqCkVFRTeNuXDhQoNzFhYW6sRcf56ioiJUV1c3qEDcCpMGIiIyDs3UPWGotWvXwsnJCcOHD5fWubq6QqPRSDMqgGvjHvbt24d+/foBALy9vWFubq4Tk5eXh+zsbCnG19cXxcXFOHTokBRz8OBBFBcX68RkZ2cjLy9PiklNTYVKpYK3t7dB18LuCSIiMg6tcBvpuro6rF27FuPGjYOZ2V9fuQqFAjExMUhISICbmxvc3NyQkJAAKysrhIaGAgDUajUiIiIQGxsLBwcH2NvbIy4uDl5eXhg8eDAAoHv37nj88ccRGRmJlStXAgAmTJiAoKAguLu7AwACAgLg4eGBsLAwzJ8/H5cuXUJcXBwiIyMNngXCpIGIiKiFfP311zh79izGjx/fYNu0adNQUVGBqKgoFBUVwcfHB6mpqbCxsZFiFi1aBDMzM4waNQoVFRXw9/dHUlISTE1NpZgNGzYgOjpammUREhKCpUuXSttNTU2xY8cOREVFoX///rC0tERoaCgWLFhg8PXwPg1Edzjep4HuZbf1Pg2+/5J/n4b0t1u0rXc6VhqIiMg4KBQyH1jFp1xyICQRERHphZUGIiIyDiaKa4uc/Y0ckwYiIjIOMqZNSvsbOb4DREREpBdWGoiIyDi0wn0a7jVMGoiIyDiwe0I2vgNERESkF1YaiIjIOLB7QjYmDUREZBzYPSEbkwYiIjIOrDTIxrSJiIiI9MJKAxERGQd2T8jGpIGIiIwDuydkY9pEREREemGlgYiIjITM7gn+nc2kgYiIjAS7J2Rj2kRERER6YaWBiIiMg0Ihc/YEKw1MGoiIyDhwyqVsfAeIiIhIL6w0EBGRceBASNmYNBARkXFg94RsTBqIiMg4sNIgG9MmIiIi0gsrDUREZBzYPSEbkwYiIjIO7J6QjWkTERER6YWVBiIiMgoKhQIKVhpkYdJARERGgUmDfOyeICIiIr2w0kBERMZB8f+LnP2NHJMGIiIyCuyekI/dE0RERKQXVhqIiMgosNIgH5MGIiIyCkwa5GPSQERERoFJg3wc00BERER6YaWBiIiMA6dcysakgYiIjAK7J+Rj9wQREVEL+eOPP/Dcc8/BwcEBVlZW6NmzJzIzM6XtQgjEx8dDq9XC0tISAwYMwPHjx3WOUVlZiSlTpsDR0RHW1tYICQnBuXPndGKKiooQFhYGtVoNtVqNsLAwXL58WSfm7NmzCA4OhrW1NRwdHREdHY2qqiqDrodJAxERGYVrT8ZWyFgMO19RURH69+8Pc3Nz7Nq1CydOnMA777yD++67T4qZN28eFi5ciKVLl+Lw4cPQaDQYMmQISktLpZiYmBhs2bIFycnJSEtLQ1lZGYKCglBbWyvFhIaGIisrCykpKUhJSUFWVhbCwsKk7bW1tRg+fDjKy8uRlpaG5ORkbN68GbGxsYa9h0IIYdjbcOcoKSmBWq2GyisSClNlazeHqEWcS1vc2k0gajGlJSVw1TqguLgYtra2LXKO+u+K+0athkJp1eTjiKoruLwpUu+2/utf/8L+/fvx/fffN348IaDVahETE4Pp06cDuFZVcHZ2xty5czFx4kQUFxejbdu2WL9+PUaPHg0AOH/+PFxcXLBz504EBgbi5MmT8PDwQEZGBnx8fAAAGRkZ8PX1xalTp+Du7o5du3YhKCgIubm50Gq1AIDk5GSEh4ejoKBA7/eelQYiIiIDlJSU6CyVlZWNxm3btg29e/fGM888AycnJ/Tq1QurV6+Wtufk5CA/Px8BAQHSOpVKBT8/Pxw4cAAAkJmZierqap0YrVYLT09PKSY9PR1qtVpKGACgb9++UKvVOjGenp5SwgAAgYGBqKys1OkuuRUmDUREZBTkdU38NYjSxcVFGjugVquRmJjY6Pl+++03LF++HG5ubvjqq68wadIkREdH48MPPwQA5OfnAwCcnZ119nN2dpa25efnQ6lUws7O7qYxTk5ODc7v5OSkE3P9eezs7KBUKqUYfXD2BBERGYdmmnKZm5urU85XqVSNhtfV1aF3795ISEgAAPTq1QvHjx/H8uXL8c9//vOvw143WEIIcctZHtfHNBbflJhbYaWBiIjIALa2tjrLjZKGdu3awcPDQ2dd9+7dcfbsWQCARqMBgAZ/6RcUFEhVAY1Gg6qqKhQVFd005sKFCw3OX1hYqBNz/XmKiopQXV3doAJxM0waiIjIOMjtmjBw+kT//v1x+vRpnXX/+9//0KlTJwCAq6srNBoNdu/eLW2vqqrCvn370K9fPwCAt7c3zM3NdWLy8vKQnZ0txfj6+qK4uBiHDh2SYg4ePIji4mKdmOzsbOTl5UkxqampUKlU8Pb21vua2D1BRERGQe7NnQzd95VXXkG/fv2QkJCAUaNG4dChQ1i1ahVWrVolHS8mJgYJCQlwc3ODm5sbEhISYGVlhdDQUACAWq1GREQEYmNj4eDgAHt7e8TFxcHLywuDBw8GcK168fjjjyMyMhIrV64EAEyYMAFBQUFwd3cHAAQEBMDDwwNhYWGYP38+Ll26hLi4OERGRho0a4VJAxERGYXbnTT06dMHW7ZswYwZM/DGG2/A1dUVixcvxtixY6WYadOmoaKiAlFRUSgqKoKPjw9SU1NhY2MjxSxatAhmZmYYNWoUKioq4O/vj6SkJJiamkoxGzZsQHR0tDTLIiQkBEuXLpW2m5qaYseOHYiKikL//v1haWmJ0NBQLFiwwLD3gPdpILqz8T4NdC+7nfdpcBi7FiYy7tNQV3UFFzc836JtvdOx0kBERMaBD6ySjUkDEREZhdvdPXEv4uwJIiIi0gsrDUREZBRYaZCPSQMRERkFJg3ysXuCiIiI9MJKAxERGQVWGuRj0kBERMaBUy5lY/cEERER6YWVBiIiMgrsnpCPSQMRERkFJg3yMWkgIiKjwKRBPo5pICIiIr2w0kBERMaBsydkY9JARERGgd0T8rF7goiIiPTCSsM97NgXr6Oj1qHB+v9++h1mvPMZXnsxGEP6P4hO7R1QUnYV+w6dwutLtyH/z2Ip9ssVL+Mf3m46+3+emomImWsbHFdpboavk+Lg9UAHPDo2Edn/+0Pa1sujI2a/NAI9u7lACODoiTOYvWSrTgxRc/hwSxo+3Lof5/IuAQAecNUgJjwQg3w9AAAd/hHT6H4zo0LwYuggAMDTLy1BRtavOttD/Hth2evjpNc/nc5FwvIvcezUWZiYmGCY30OYPWUkrK1ULXBV1BxYaZCv1ZOGZcuWYf78+cjLy8ODDz6IxYsX49FHH23tZt0TBo2bD1PTvz7k3btqsfX9Kdj69Q+wslCiRzcXzF+zC9k//4H7bKyQMPUpfPzORAwaN0/nOElb9iNx5Xbp9dWr1Y2e7/XoEcgvLIbXAx101rexUmHze5Ox87ufEDd3I8xMTfCvCcOx+b3JeHD4a6iprWvGqyZj167tfZgxKRiu7R0BAJ/uOoyIGWuQ8kEc3Lu0w9Ev3tCJ/zbjJOLeTsYwvx4660ODfRH3wlDptYXKXPrv/D+LMSZmOUL8e+KtqU+htLwS8e9twSsJH2PVW8+34NWRHArITBo4qKF1k4aNGzciJiYGy5YtQ//+/bFy5UoMHToUJ06cQMeOHVuzafeEi5fLdF7HjPPEb7mF2H/0ZwDAky8t1dk+fcGn2LNuGjo42+HchSJpfcXVKhRcLL3puQb388BAn+4YN/2/GNL/QZ1t93dyhp3aGokrt+OPC5cBAPNW78L+5H+jg8Yev//xZ1MvkaiBIf/w1Hk9feJwfLh1P46eOAP3Lu3g5GCrsz017Sf0e/h+dPr/JKOepYV5g9h6X+8/DnMzE8yZ+jRMTK718s6Z+hQCn1+AnHOFcO3QthmviOjO0apjGhYuXIiIiAi88MIL6N69OxYvXgwXFxcsX768NZt1TzI3M8WooX2wYVv6DWNs21iirq4OxWUVOuufebw3ftn9Ng5snIk3Xn4Cba4rv7a1t8Hifz+LSbM/xJWrVQ2O+8uZC/izqBTPhfSDuZkpLFTmeG6EL07+eh65+Zea5wKJGlFbW4cvvj6KiquV8H6wc4PthZdK8c2BExgzvG+DbVt2Z8Jr+EwMeu5tvLn0C5RduSptq6qugbm5mZQwAH9VIg7/+FvzXwg1i/ruCTmLsWu1SkNVVRUyMzPxr3/9S2d9QEAADhw40EqtuncNH9AD6jaW+Hj7wUa3q5RmmD15BD776ghKy//65fhpymGcOX8RBRdL0L2LFrMmB8PTrb1OlWLZ7Oew9vM0ZJ08C5d29g2OXXalEsGT3sWGBRPxasTjAIBfzhbg6Snvo5ZdE9QCTv56HiMmLUZlVQ2sLZVYnRCBB1w1DeI+3XUI1lYWGHpd18QTAb3RsZ092jrY4vRveXh75Xac+OUPfLI4CgDQ/2E3vLFkK5Z/vAcRzzyGKxVVeHvlDgBAwcWSlr9AahpOuZSt1ZKGP//8E7W1tXB2dtZZ7+zsjPz8/Eb3qaysRGVlpfS6pIT/OPX1XEg/fJ1+QmeQYz0zUxOsmfM8TEwUiJu7SWfbh1v/SuBO/pqHX3MLsHf9dPRw74AfT5/DhNF+sLG2wKKk1Bue20JljiX/eQ4Hj/2GF15bC1MTE7z0nD82vfsiBo2bj6uVjY+RIGqqrh2d8NXaV1FSVoGde4/hlTkb8NmSKQ0Sh407DuKJAG+d8QoAMDbEV/rvbl3awbVDWwx74R38dDoXXu4ucO/SDotmjsUbS7fi7ZXbYWqiwPNPP4a29jY61Qeie02rD4S8vtwjhLhhCSgxMRGvv/767WjWPcVFY4cBj7gjbNrqBtvMTE2wNjECnbQOCIlaolNlaMyxU7moqq5B145O+PH0OTzW+wH09nTFhf2LdeK+XTcNn6YcQdTr6/F04LW/2gLGvwMhBAAg8rUk5OyZh2GP9cDnuzOb7VqJgGszeerHFTzUrSOOnczFmk/3Ye600VLMwWO/4tezBVj+txkRN+Ll3gHmZqbIOVcIL3cXAMATAd54IsAbhZdKYWWhhEIBrN64Fx3bNZyxRHcGzp6Qr9WSBkdHR5iamjaoKhQUFDSoPtSbMWMGpk6dKr0uKSmBi4tLi7bzXhAa7IvColKk7j+us74+YejasS2CJ72HouLyWx6re9d2UJqb4cL/Vyz+teAzzFnx18wKjaMany99CeP/vRaZx38HAFhaKFEnhJQwAPj/14CJCf8RUssTEKiqrtFZl7w9Az3cXeDh1v6W+5/OyUd1TS2cHNQNtrW1t5GOp1Ka49E+DzRPo6nZMWmQr9WSBqVSCW9vb+zevRtPPPGEtH737t0YMWJEo/uoVCqoVJwDbQiFQoGxwX2RvOOgzvgBU1MTrJv7Ah7q5oIxr6yAqakCTg7XfvkVFV9BdU0tOrd3xDNDe2P3/hO4eLkM3Vw1eDPmSRw7lYuMY9cGe527UARc+Ot8ZVeudR/l/FGI8wWXAQB7D57CG9EjsWD6KKzauA8mJgrEjAtAbW0tvj/yv9vzRpDReHvldgzs2x1ap/tQdqUS277+Aek//IKP3pkkxZSWX8X2b49h1ksNf9f8/sef2JJ6BIN8PWCvtsb/fr+AN5duhecDHdDHy1WKW7v5e/T27AxrSxW+O3waby3bhhmTgqC2sbot10mGUyiuLXL2N3at2j0xdepUhIWFoXfv3vD19cWqVatw9uxZTJo06dY7k14GPOIOl3b2+Ghbhs56rdN90rz07z+eobMtaOK72H/0Z1TX1MCvjzsmjR4Iaysl/rhwGan7szF39S7U1Qno6+czF/Ds1JWYHjkUqR/Eoq5O4Mf/ncPT0ctwgYPGqJkVXirFy29+hIKLJbCxtkT3rlp89M4kPNbHXYr54uujEEJgxOCHG+yvNDNFWubPWPPpd7hSUYl2Tnbw9/XAK+MDYWr613iFrBNn8M6aXbhSUYmuHZ3x9quj8PTjfW7LNRK1FoX4e824FSxbtgzz5s1DXl4ePD09sWjRIjz22GN67VtSUgK1Wg2VVyQUpsoWbilR6ziXtri1m0DUYkpLSuCqdUBxcTFsbRu/L4Zc9d8VXaZ8BhOVdZOPU1dZjt+WPN2ibb3TtfpAyKioKERFRbV2M4iI6F4ns3uCUy75wCoiIiLSU6tXGoiIiG4Hzp6Qj0kDEREZBc6ekI/dE0RERKQXVhqIiMgomJgoZN1QTvBmdEwaiIjIOLB7Qj52TxAREZFeWGkgIiKjwNkT8jFpICIio8DuCfmYNBARkVFgpUE+jmkgIiIivbDSQERERoGVBvlYaSAiIqNQP6ZBzmKI+Ph4KVGpXzQajbRdCIH4+HhotVpYWlpiwIABOH78uM4xKisrMWXKFDg6OsLa2hohISE4d+6cTkxRURHCwsKgVquhVqsRFhaGy5cv68ScPXsWwcHBsLa2hqOjI6Kjo1FVVWXYBYFJAxERUYt58MEHkZeXJy0//fSTtG3evHlYuHAhli5disOHD0Oj0WDIkCEoLS2VYmJiYrBlyxYkJycjLS0NZWVlCAoKQm1trRQTGhqKrKwspKSkICUlBVlZWQgLC5O219bWYvjw4SgvL0daWhqSk5OxefNmxMbGGnw97J4gIiKjoIDM7okmPBvbzMxMp7pQTwiBxYsXY+bMmXjyyScBAOvWrYOzszM+/vhjTJw4EcXFxVizZg3Wr1+PwYMHAwA++ugjuLi44Ouvv0ZgYCBOnjyJlJQUZGRkwMfHBwCwevVq+Pr64vTp03B3d0dqaipOnDiB3NxcaLVaAMA777yD8PBwzJkzB7a2tnpfDysNRERkFJqre6KkpERnqaysvOE5f/75Z2i1Wri6umLMmDH47bffAAA5OTnIz89HQECAFKtSqeDn54cDBw4AADIzM1FdXa0To9Vq4enpKcWkp6dDrVZLCQMA9O3bF2q1WifG09NTShgAIDAwEJWVlcjMzDToPWTSQEREZAAXFxdp/IBarUZiYmKjcT4+Pvjwww/x1VdfYfXq1cjPz0e/fv1w8eJF5OfnAwCcnZ119nF2dpa25efnQ6lUws7O7qYxTk5ODc7t5OSkE3P9eezs7KBUKqUYfbF7goiIjEJzzZ7Izc3VKemrVKpG44cOHSr9t5eXF3x9fdG1a1esW7cOffv21TlmPSHELdt4fUxj8U2J0QcrDUREZBSaq3vC1tZWZ7lR0nA9a2treHl54eeff5bGOVz/l35BQYFUFdBoNKiqqkJRUdFNYy5cuNDgXIWFhTox15+nqKgI1dXVDSoQt8KkgYiI6DaorKzEyZMn0a5dO7i6ukKj0WD37t3S9qqqKuzbtw/9+vUDAHh7e8Pc3FwnJi8vD9nZ2VKMr68viouLcejQISnm4MGDKC4u1onJzs5GXl6eFJOamgqVSgVvb2+DroHdE0REZBRu982d4uLiEBwcjI4dO6KgoABvvfUWSkpKMG7cOCgUCsTExCAhIQFubm5wc3NDQkICrKysEBoaCgBQq9WIiIhAbGwsHBwcYG9vj7i4OHh5eUmzKbp3747HH38ckZGRWLlyJQBgwoQJCAoKgru7OwAgICAAHh4eCAsLw/z583Hp0iXExcUhMjLSoJkTAJMGIiIyErf7gVXnzp3Ds88+iz///BNt27ZF3759kZGRgU6dOgEApk2bhoqKCkRFRaGoqAg+Pj5ITU2FjY2NdIxFixbBzMwMo0aNQkVFBfz9/ZGUlARTU1MpZsOGDYiOjpZmWYSEhGDp0qXSdlNTU+zYsQNRUVHo378/LC0tERoaigULFhj+HgghhMF73SFKSkqgVquh8oqEwlTZ2s0hahHn0ha3dhOIWkxpSQlctQ4oLi42+K9efdV/V3jP2gFTC+smH6f2ajky3xjeom2903FMAxEREemF3RNERGQcZHZPNOGGkPccJg1ERGQU+JRL+dg9QURERHphpYGIiIzC7Z49cS9i0kBEREaB3RPysXuCiIiI9MJKAxERGQV2T8jHpIGIiIwCuyfkY/cEERER6YWVBiIiMgqsNMjHpIGIiIwCxzTIx6SBiIiMAisN8nFMAxEREemFlQYiIjIK7J6Qj0kDEREZBXZPyMfuCSIiItILKw1ERGQUFJDZPdFsLbl7MWkgIiKjYKJQwERG1iBn33sFuyeIiIhIL6w0EBGRUeDsCfmYNBARkVHg7An5mDQQEZFRMFFcW+Tsb+w4poGIiIj0wkoDEREZB4XMLgZWGpg0EBGRceBASPnYPUFERER6YaWBiIiMguL//ydnf2PHpIGIiIwCZ0/Ix+4JIiIi0gsrDUREZBR4cyf59Eoa3nvvPb0PGB0d3eTGEBERtRTOnpBPr6Rh0aJFeh1MoVAwaSAiIrpH6ZU05OTktHQ7iIiIWhQfjS1fkwdCVlVV4fTp06ipqWnO9hAREbWI+u4JOYuxMzhpuHLlCiIiImBlZYUHH3wQZ8+eBXBtLMPbb7/d7A0kIiJqDvUDIeUsxs7gpGHGjBk4duwY9u7dCwsLC2n94MGDsXHjxmZtHBEREd05DJ5yuXXrVmzcuBF9+/bVybo8PDzw66+/NmvjiIiImgtnT8hncNJQWFgIJyenBuvLy8tZuiEiojsWB0LKZ3D3RJ8+fbBjxw7pdX2isHr1avj6+jZfy4iIiOiOYnDSkJiYiJkzZ+LFF19ETU0N3n33XQwZMgRJSUmYM2dOS7SRiIhINkUzLE2VmJgIhUKBmJgYaZ0QAvHx8dBqtbC0tMSAAQNw/Phxnf0qKysxZcoUODo6wtraGiEhITh37pxOTFFREcLCwqBWq6FWqxEWFobLly/rxJw9exbBwcGwtraGo6MjoqOjUVVVZfB1GJw09OvXD/v378eVK1fQtWtXpKamwtnZGenp6fD29ja4AURERLdDa82eOHz4MFatWoUePXrorJ83bx4WLlyIpUuX4vDhw9BoNBgyZAhKS0ulmJiYGGzZsgXJyclIS0tDWVkZgoKCUFtbK8WEhoYiKysLKSkpSElJQVZWFsLCwqTttbW1GD58OMrLy5GWlobk5GRs3rwZsbGxBl9Lk5494eXlhXXr1jVlVyIiIqNRVlaGsWPHYvXq1Xjrrbek9UIILF68GDNnzsSTTz4JAFi3bh2cnZ3x8ccfY+LEiSguLsaaNWuwfv16DB48GADw0UcfwcXFBV9//TUCAwNx8uRJpKSkICMjAz4+PgD+Gi5w+vRpuLu7IzU1FSdOnEBubi60Wi0A4J133kF4eDjmzJkDW1tbva+nSTd3qq2txWeffYY333wTb731FjZv3sybPBER0R2t/tHYchYAKCkp0VkqKytveM7Jkydj+PDh0pd+vZycHOTn5yMgIEBap1Kp4OfnhwMHDgAAMjMzUV1drROj1Wrh6ekpxaSnp0OtVksJAwD07dsXarVaJ8bT01NKGAAgMDAQlZWVyMzMNOg9NLjSkJ2djREjRiA/Px/u7u4AgP/9739o27Yttm3bBi8vL0MPSURE1OKa6ymXLi4uOutnz56N+Pj4BvHJyck4evQoDh8+3GBbfn4+AMDZ2VlnvbOzM86cOSPFKJVK2NnZNYip3z8/P7/RGY1OTk46Mdefx87ODkqlUorRl8FJwwsvvIAHH3wQR44ckS6kqKgI4eHhmDBhAtLT0w09JBER0V0jNzdXp6SvUqkajXn55ZeRmpqqcyPE612fxAghbpnYXB/TWHxTYvRhcPfEsWPHkJiYqJP52NnZYc6cOcjKyjL0cERERLdNczx3wtbWVmdpLGnIzMxEQUEBvL29YWZmBjMzM+zbtw/vvfcezMzMpL/8r/9Lv6CgQNqm0WhQVVWFoqKim8ZcuHChwfkLCwt1Yq4/T1FREaqrqxtUIG7F4KTB3d290QYWFBTg/vvvN/RwREREt8XtnD3h7++Pn376CVlZWdLSu3dvjB07FllZWejSpQs0Gg12794t7VNVVYV9+/ahX79+AABvb2+Ym5vrxOTl5SE7O1uK8fX1RXFxMQ4dOiTFHDx4EMXFxTox2dnZyMvLk2JSU1OhUqkMnvWoV/dESUmJ9N8JCQmIjo5GfHw8+vbtCwDIyMjAG2+8gblz5xp0ciIiotvl74MZm7q/vmxsbODp6amzztraGg4ODtL6mJgYJCQkwM3NDW5ubkhISICVlRVCQ0MBAGq1GhEREYiNjYWDgwPs7e0RFxcHLy8vaWBl9+7d8fjjjyMyMhIrV64EAEyYMAFBQUHSuMOAgAB4eHggLCwM8+fPx6VLlxAXF4fIyEiDZk4AeiYN9913n06GJYTAqFGjpHVCCABAcHCwztxRIiIiaty0adNQUVGBqKgoFBUVwcfHB6mpqbCxsZFiFi1aBDMzM4waNQoVFRXw9/dHUlISTE1NpZgNGzYgOjpammUREhKCpUuXSttNTU2xY8cOREVFoX///rC0tERoaCgWLFhgcJsVov4b/yb27dun9wH9/PwMbkRTlZSUQK1WQ+UVCYWp8radl+h2Ope2uLWbQNRiSktK4Kp1QHFxscF/9eqr/rsidM0BKK3aNPk4VVfK8HFEvxZt651Or0rD7UwEiIiIWoLcW0HzcVVNvCMkAFy5cgVnz55tcO/q62+TSURERPeGJj0a+/nnn8euXbsa3c4xDUREdCfio7HlM3jKZUxMDIqKipCRkQFLS0ukpKRg3bp1cHNzw7Zt21qijURERLLJuUfD9fdqMFYGVxr27NmDL774An369IGJiQk6deqEIUOGwNbWFomJiRg+fHhLtJOIiIhamcGVhvLycuk+1/b29igsLARw7cmXR48ebd7WERERNZPWejT2vaRJd4Q8ffo0AKBnz55YuXIl/vjjD6xYsQLt2rVr9gYSERE1B3ZPyGdw90RMTIx0K8rZs2cjMDAQGzZsgFKpRFJSUnO3j4iIiO4QBicNY8eOlf67V69e+P3333Hq1Cl07NgRjo6Ozdo4IiKi5sLZE/I1+T4N9aysrPDwww83R1uIiIhajNwuBuYMeiYNU6dO1fuACxcubHJjiIiIWorcwYwcCKln0vDDDz/odTC+oURERPcuvZKGb7/9tqXbIcvZvQuM9uEhRER3s1qV7F5yvZmgCVMGr9vf2N2+nxYREVErYveEfEyciIiISC+sNBARkVFQKAATzp6QhUkDEREZBROZSYOcfe8V7J4gIiIivTQpaVi/fj369+8PrVaLM2fOAAAWL16ML774olkbR0RE1Fz4wCr5DE4ali9fjqlTp2LYsGG4fPkyamtrAQD33XcfFi9e3NztIyIiahb13RNyFmNncNKwZMkSrF69GjNnzoSpqam0vnfv3vjpp5+atXFERER05zB4IGROTg569erVYL1KpUJ5eXmzNIqIiKi58dkT8hlcaXB1dUVWVlaD9bt27YKHh0dztImIiKjZ1T/lUs5i7AyuNLz66quYPHkyrl69CiEEDh06hE8++QSJiYn473//2xJtJCIiko23kZbP4KTh+eefR01NDaZNm4YrV64gNDQU7du3x7vvvosxY8a0RBuJiIjoDtCkmztFRkYiMjISf/75J+rq6uDk5NTc7SIiImpWHNMgn6w7Qjo6OjZXO4iIiFqUCeSNSzABswaDkwZXV9eb3uDit99+k9UgIiIiujMZnDTExMTovK6ursYPP/yAlJQUvPrqq83VLiIiombF7gn5DE4aXn755UbXv//++zhy5IjsBhEREbUEPrBKvmabQTJ06FBs3ry5uQ5HREREd5hmezT2Z599Bnt7++Y6HBERUbNSKCBrICS7J5qQNPTq1UtnIKQQAvn5+SgsLMSyZcuatXFERETNhWMa5DM4aRg5cqTOaxMTE7Rt2xYDBgxAt27dmqtdREREdIcxKGmoqalB586dERgYCI1G01JtIiIianYcCCmfQQMhzczM8OKLL6KysrKl2kNERNQiFM3wP2Nn8OwJHx8f/PDDDy3RFiIiohZTX2mQsxg7g8c0REVFITY2FufOnYO3tzesra11tvfo0aPZGkdERER3Dr2ThvHjx2Px4sUYPXo0ACA6OlraplAoIISAQqFAbW1t87eSiIhIJo5pkE/vpGHdunV4++23kZOT05LtISIiahEKheKmz07SZ39jp/eYBiEEAKBTp043XYiIiAhYvnw5evToAVtbW9ja2sLX1xe7du2StgshEB8fD61WC0tLSwwYMADHjx/XOUZlZSWmTJkCR0dHWFtbIyQkBOfOndOJKSoqQlhYGNRqNdRqNcLCwnD58mWdmLNnzyI4OBjW1tZwdHREdHQ0qqqqDL4mgwZCMssiIqK71e0eCNmhQwe8/fbbOHLkCI4cOYJBgwZhxIgRUmIwb948LFy4EEuXLsXhw4eh0WgwZMgQlJaWSseIiYnBli1bkJycjLS0NJSVlSEoKEhnKEBoaCiysrKQkpKClJQUZGVlISwsTNpeW1uL4cOHo7y8HGlpaUhOTsbmzZsRGxtr8HuoEPUlhFswMTGBWq2+ZeJw6dIlgxvRVCUlJVCr1bhwsRi2tra37bxERNQ8SkpK4OygRnFxy/0er/+umLMzCxbWNk0+ztXyUswc1lNWW+3t7TF//nyMHz8eWq0WMTExmD59OoBrVQVnZ2fMnTsXEydORHFxMdq2bYv169dL4wnPnz8PFxcX7Ny5E4GBgTh58iQ8PDyQkZEBHx8fAEBGRgZ8fX1x6tQpuLu7Y9euXQgKCkJubi60Wi0AIDk5GeHh4SgoKDDoWgyaPfH6669DrVYbsgsREdE9paSkROe1SqWCSqW66T61tbX49NNPUV5eDl9fX+Tk5CA/Px8BAQE6x/Hz88OBAwcwceJEZGZmorq6WidGq9XC09MTBw4cQGBgINLT06FWq6WEAQD69u0LtVqNAwcOwN3dHenp6fD09JQSBgAIDAxEZWUlMjMzMXDgQL2v3aCkYcyYMXBycjJkFyIiojuCiUIh64FV9fu6uLjorJ89ezbi4+Mb3eenn36Cr68vrl69ijZt2mDLli3w8PDAgQMHAADOzs468c7Ozjhz5gwAID8/H0qlEnZ2dg1i8vPzpZjGvpednJx0Yq4/j52dHZRKpRSjL72TBo5nICKiu1lzTbnMzc3VKenfrMrg7u6OrKwsXL58GZs3b8a4ceOwb98+afv13631ty+4metjGotvSow+DJ49QUREZMzqZ0PULzdLGpRKJe6//3707t0biYmJeOihh/Duu+9Kz2+6/i/9goICqSqg0WhQVVWFoqKim8ZcuHChwXkLCwt1Yq4/T1FREaqrqxtUIG5F76Shrq6OXRNERHT3Uvz1eOymLM3x6AkhBCorK+Hq6gqNRoPdu3dL26qqqrBv3z7069cPAODt7Q1zc3OdmLy8PGRnZ0sxvr6+KC4uxqFDh6SYgwcPori4WCcmOzsbeXl5UkxqaipUKhW8vb0Nar/Bt5EmIiK6G5lAARMZ3/yG7vvvf/8bQ4cOhYuLC0pLS5GcnIy9e/ciJSUFCoUCMTExSEhIgJubG9zc3JCQkAArKyuEhoYCANRqNSIiIhAbGwsHBwfY29sjLi4OXl5eGDx4MACge/fuePzxxxEZGYmVK1cCACZMmICgoCC4u7sDAAICAuDh4YGwsDDMnz8fly5dQlxcHCIjIw2eBcKkgYiIjIJUMZCxvyEuXLiAsLAw5OXlQa1Wo0ePHkhJScGQIUMAANOmTUNFRQWioqJQVFQEHx8fpKamwsbmr2mhixYtgpmZGUaNGoWKigr4+/sjKSkJpqamUsyGDRsQHR0tzbIICQnB0qVLpe2mpqbYsWMHoqKi0L9/f1haWiI0NBQLFiww/D3Q9z4NdyLep4GI6O52O+/TsCD1R1jKuE9DRXkp4gJ6tGhb73SsNBARkVHgA6vkY9JARERGobnu02DMDHr2BBERERkvVhqIiMgo3O6BkPciJg1ERGQUTCCze6I5btRwl2P3BBEREemFlQYiIjIK7J6Qj0kDEREZBRPIK6+zNM/3gIiIiPTESgMRERkFhUJh8KOgr9/f2DFpICIioyD3QZVMGZg0EBGRkeAdIeXjmAYiIiLSCysNRERkNFgrkIdJAxERGQXep0E+dk8QERGRXlhpICIio8Apl/IxaSAiIqPAO0LKx/eAiIiI9MJKAxERGQV2T8jHpIGIiIwC7wgpH7sniIiISC+sNBARkVFg94R8TBqIiMgocPaEfEwaiIjIKLDSIB8TJyIiItILKw1ERGQUOHtCPiYNRERkFPjAKvnYPUFERER6YaWBiIiMggkUMJHRySBn33sFkwYiIjIK7J6Qj90TREREpBdWGoiIyCgo/v9/cvY3dkwaiIjIKLB7Qj52TxAREZFeWGkgIiKjoJA5e4LdE0waiIjISLB7Qj4mDUREZBSYNMjHMQ1ERESkF1YaiIjIKHDKpXysNBARkVEwUchfDJGYmIg+ffrAxsYGTk5OGDlyJE6fPq0TI4RAfHw8tFotLC0tMWDAABw/flwnprKyElOmTIGjoyOsra0REhKCc+fO6cQUFRUhLCwMarUaarUaYWFhuHz5sk7M2bNnERwcDGtrazg6OiI6OhpVVVUGXROTBiIiohawb98+TJ48GRkZGdi9ezdqamoQEBCA8vJyKWbevHlYuHAhli5disOHD0Oj0WDIkCEoLS2VYmJiYrBlyxYkJycjLS0NZWVlCAoKQm1trRQTGhqKrKwspKSkICUlBVlZWQgLC5O219bWYvjw4SgvL0daWhqSk5OxefNmxMbGGnRNCiGEkPGetKqSkhKo1WpcuFgMW1vb1m4OEREZqKSkBM4OahQXt9zv8frvim2Hc2DdxqbJxykvK0VIH9cmt7WwsBBOTk7Yt28fHnvsMQghoNVqERMTg+nTpwO4VlVwdnbG3LlzMXHiRBQXF6Nt27ZYv349Ro8eDQA4f/48XFxcsHPnTgQGBuLkyZPw8PBARkYGfHx8AAAZGRnw9fXFqVOn4O7ujl27diEoKAi5ubnQarUAgOTkZISHh6OgoEDv62GlgYiIjEL97Ak5C3AtCfn7UllZqdf5i4uLAQD29vYAgJycHOTn5yMgIECKUalU8PPzw4EDBwAAmZmZqK6u1onRarXw9PSUYtLT06FWq6WEAQD69u0LtVqtE+Pp6SklDAAQGBiIyspKZGZm6v0eMmkgIiIygIuLizR2QK1WIzEx8Zb7CCEwdepU/OMf/4CnpycAID8/HwDg7OysE+vs7Cxty8/Ph1KphJ2d3U1jnJycGpzTyclJJ+b689jZ2UGpVEox+uDsCSIiMgoKyJsBUb9nbm6uTjlfpVLdct+XXnoJP/74I9LS0hoe97obQAghGqy73vUxjcU3JeZWWGkgIiKj0FyzJ2xtbXWWWyUNU6ZMwbZt2/Dtt9+iQ4cO0nqNRgMADf7SLygokKoCGo0GVVVVKCoqumnMhQsXGpy3sLBQJ+b68xQVFaG6urpBBeJmmDQQERG1ACEEXnrpJXz++efYs2cPXF1ddba7urpCo9Fg9+7d0rqqqirs27cP/fr1AwB4e3vD3NxcJyYvLw/Z2dlSjK+vL4qLi3Ho0CEp5uDBgyguLtaJyc7ORl5enhSTmpoKlUoFb29vva+J3RPUwMK1X2H7t8fw85kLsFCZ45EeXRD/0gi4dW48G41J+ATrtuxHwitP4cXQgbe5tUTyLFz7Fd5c9iUmjRmAxNinAQBR8evxyY6DOnG9PTtj99q41mgiNZPbfXOnyZMn4+OPP8YXX3wBGxsb6S99tVoNS0tLKBQKxMTEICEhAW5ubnBzc0NCQgKsrKwQGhoqxUZERCA2NhYODg6wt7dHXFwcvLy8MHjwYABA9+7d8fjjjyMyMhIrV64EAEyYMAFBQUFwd3cHAAQEBMDDwwNhYWGYP38+Ll26hLi4OERGRho0E6RVk4bvvvsO8+fPR2ZmJvLy8rBlyxaMHDmyNZtEAA4c/QUvPPMYenl0Qk1tLd5a/iWenLIUGZteg7Wlbhlux95jyMz+He3aqluptURNd/T4GazbegAPurVvsM3f1wPvz3pOeq00N72dTaMWcLufPbF8+XIAwIABA3TWr127FuHh4QCAadOmoaKiAlFRUSgqKoKPjw9SU1NhY/PX1NBFixbBzMwMo0aNQkVFBfz9/ZGUlART078+kxs2bEB0dLQ0yyIkJARLly6VtpuammLHjh2IiopC//79YWlpidDQUCxYsMCga2rVpKG8vBwPPfQQnn/+eTz11FOt2RT6m8+WTNZ5/f6s5+AWMANZJ3PR/+H7pfXnCy5j2vxP8dl7kzH6leW3u5lEspRdqcSEWUl499/PYsEHKQ22q5RmcHbk/V/uJQpA1o2gDd1Xn9sgKRQKxMfHIz4+/oYxFhYWWLJkCZYsWXLDGHt7e3z00Uc3PVfHjh2xffv2W7bpZlo1aRg6dCiGDh3amk0gPZSUXQUA2NlaSevq6uowafaHmPKcP7p3bddaTSNqslfnbURAf08M8OnWaNKQlvkz3AL+BbWNJfr3csNrUcFoa9/0GwMR3QvuqjENlZWVOjfRKCkpacXWGAchBGYu2oy+PbvC4/6/bgqyeN1umJmaYOKYAa3XOKIm2px6BMdO5WLPummNbh/czwMjBveCi8YeZ85fRMKK7Qh58T3sXT8NKqX5bW4tNRcTKGAio3/ChA+suruShsTERLz++uut3Qyj8uq8TTj+y3nsWv2KtC7r5FmsTN6LvR9NN2h+L9Gd4Fx+EWa8sxmbl0yGharxBODJgL9Gk3vcr0Uvj47oETwLqWnHETyo521qKTW32909cS+6q5KGGTNmYOrUqdLrkpISuLi4tGKL7m3T5m/Cru9+ws5VMWjv/NfdyNJ/+BWFRWXwCp4lrautrcNr736O5cnf4sdtb7RGc4n0cuzUWRReKsXAf86T1tXW1uHAD79i9aff4cL+xTA11Z2NrnFUw6WdPX7NLbzdzSW6o9xVSYNKpdLrzlskjxAC0+Z/ih17j+HLFS+jU3tHne2jh/WB3yPuOuuejn4fo4Y+grHBfW9nU4kM9lgfd+z/5N8661564yO4dXbGy/8c0iBhAIBLl8vwx4UiaDgw8u7GUoNsd1XSQLdH3NxN+OyrI/h4wQS0sbLAhT+vjR2xbWMBSwsl7O9rA/v72ujsY2ZmCmcH2xvey4HoTmFjbaEzPgcArCyVsFdbw+N+LcquVGLuqh0IHtQTGkc1zuZdxBvvfwmH+9pg+ICHWqnV1Bxu930a7kWtmjSUlZXhl19+kV7n5OQgKysL9vb26NixYyu2zLh9sPl7AEDQpHd11r8/6zmEspJA9zhTEwVO/HoeyTsPobi0As6OtnjU+wF8kDAeNtYWrd08olalEPpMJG0he/fuxcCBDe8gOG7cOCQlJd1y//pnpF+42HLPYSciopZTUlICZwc1iotb7vd4/XfFN1ln0cam6ecoKy2Bf8+OLdrWO12rVhoGDBig180viIiI5OKQBvn4wCoiIiLSCwdCEhGRcWCpQTYmDUREZBQ4e0I+Jg1ERGQUbvdTLu9FHNNAREREemGlgYiIjAKHNMjHpIGIiIwDswbZ2D1BREREemGlgYiIjAJnT8jHpIGIiIwCZ0/Ix+4JIiIi0gsrDUREZBQ4DlI+Jg1ERGQcmDXIxu4JIiIi0gsrDUREZBQ4e0I+Jg1ERGQUOHtCPiYNRERkFDikQT6OaSAiIiK9sNJARETGgaUG2Zg0EBGRUeBASPnYPUFERER6YaWBiIiMAmdPyMekgYiIjAKHNMjH7gkiIiLSCysNRERkHFhqkI1JAxERGQXOnpCP3RNERESkF1YaiIjIKHD2hHxMGoiIyChwSIN8TBqIiMg4MGuQjWMaiIiISC9MGoiIyCgomuF/hvjuu+8QHBwMrVYLhUKBrVu36mwXQiA+Ph5arRaWlpYYMGAAjh8/rhNTWVmJKVOmwNHREdbW1ggJCcG5c+d0YoqKihAWFga1Wg21Wo2wsDBcvnxZJ+bs2bMIDg6GtbU1HB0dER0djaqqKoOuB2DSQERExkLx12DIpiyGdk+Ul5fjoYcewtKlSxvdPm/ePCxcuBBLly7F4cOHodFoMGTIEJSWlkoxMTEx2LJlC5KTk5GWloaysjIEBQWhtrZWigkNDUVWVhZSUlKQkpKCrKwshIWFSdtra2sxfPhwlJeXIy0tDcnJydi8eTNiY2MNuyAACiGEMHivO0RJSQnUajUuXCyGra1tazeHiIgMVFJSAmcHNYqLW+73eP13xdFf8mFj0/RzlJaW4OH7NU1qq0KhwJYtWzBy5EgA16oMWq0WMTExmD59OoBrVQVnZ2fMnTsXEydORHFxMdq2bYv169dj9OjRAIDz58/DxcUFO3fuRGBgIE6ePAkPDw9kZGTAx8cHAJCRkQFfX1+cOnUK7u7u2LVrF4KCgpCbmwutVgsASE5ORnh4OAoKCgy6FlYaiIjIKCiaYQGuJSF/XyorKw1uS05ODvLz8xEQECCtU6lU8PPzw4EDBwAAmZmZqK6u1onRarXw9PSUYtLT06FWq6WEAQD69u0LtVqtE+Pp6SklDAAQGBiIyspKZGZmGtRuJg1ERGQcmilrcHFxkcYPqNVqJCYmGtyU/Px8AICzs7POemdnZ2lbfn4+lEol7Ozsbhrj5OTU4PhOTk46Mdefx87ODkqlUorRF6dcEhERGSA3N1enpK9SqZp8LMV1d4wSQjRYd73rYxqLb0qMPlhpICIio9BcsydsbW11lqYkDRqNBgAa/KVfUFAgVQU0Gg2qqqpQVFR005gLFy40OH5hYaFOzPXnKSoqQnV1dYMKxK0waSAiIqMgZ+aE3FtQX8/V1RUajQa7d++W1lVVVWHfvn3o168fAMDb2xvm5uY6MXl5ecjOzpZifH19UVxcjEOHDkkxBw8eRHFxsU5MdnY28vLypJjU1FSoVCp4e3sb1G52TxAREbWAsrIy/PLLL9LrnJwcZGVlwd7eHh07dkRMTAwSEhLg5uYGNzc3JCQkwMrKCqGhoQAAtVqNiIgIxMbGwsHBAfb29oiLi4OXlxcGDx4MAOjevTsef/xxREZGYuXKlQCACRMmICgoCO7u7gCAgIAAeHh4ICwsDPPnz8elS5cQFxeHyMhIg2eBMGkgIiKjcLvvIn3kyBEMHDhQej116lQAwLhx45CUlIRp06ahoqICUVFRKCoqgo+PD1JTU2FjYyPts2jRIpiZmWHUqFGoqKiAv78/kpKSYGpqKsVs2LAB0dHR0iyLkJAQnXtDmJqaYseOHYiKikL//v1haWmJ0NBQLFiwwPD3gPdpICKi1nI779PwY84F2fdp6OHq3KJtvdOx0kBEREahKbeCvn5/Y8eBkERERKQXVhqIiMgoKCBvBgTrDEwaiIjISNzugZD3InZPEBERkV5YaSAiIqMg9wZNzXlzp7sVkwYiIjIS7KCQi90TREREpBdWGoiIyCiwe0I+Jg1ERGQU2DkhH7sniIiISC+sNBARkVFg94R8TBqIiMgo8NkT8jFpICIi48BBDbJxTAMRERHphZUGIiIyCiw0yMekgYiIjAIHQsrH7gkiIiLSCysNRERkFDh7Qj4mDUREZBw4qEE2dk8QERGRXlhpICIio8BCg3xMGoiIyChw9oR87J4gIiIivbDSQERERkLe7Al2UDBpICIiI8HuCfnYPUFERER6YdJAREREemH3BBERGQV2T8jHpIGIiIwCbyMtH7sniIiISC+sNBARkVFg94R8TBqIiMgo8DbS8rF7goiIiPTCSgMRERkHlhpkY9JARERGgbMn5GP3BBEREemFlQYiIjIKnD0hH5MGIiIyChzSIB+TBiIiMg7MGmTjmAYiIiLSCysNRERkFDh7Qj4mDUREZBQ4EFK+uzppEEIAAEpLSlq5JURE1BT1v7/rf5+3pBKZ3xVy978X3NVJQ2lpKQDgfleXVm4JERHJUVpaCrVa3SLHViqV0Gg0cGuG7wqNRgOlUtkMrbo7KcTtSO9aSF1dHc6fPw8bGxsoWDe6LUpKSuDi4oLc3FzY2tq2dnOImhU/37efEAKlpaXQarUwMWm5sflXr15FVVWV7OMolUpYWFg0Q4vuTnd1pcHExAQdOnRo7WYYJVtbW/5SpXsWP9+3V0tVGP7OwsLCqL/smwunXBIREZFemDQQERGRXpg0kEFUKhVmz54NlUrV2k0hanb8fBPd3F09EJKIiIhuH1YaiIiISC9MGoiIiEgvTBqIiIhIL0waiIiISC9MGkhvy5Ytg6urKywsLODt7Y3vv/++tZtE1Cy+++47BAcHQ6vVQqFQYOvWra3dJKI7EpMG0svGjRsRExODmTNn4ocffsCjjz6KoUOH4uzZs63dNCLZysvL8dBDD2Hp0qWt3RSiOxqnXJJefHx88PDDD2P58uXSuu7du2PkyJFITExsxZYRNS+FQoEtW7Zg5MiRrd0UojsOKw10S1VVVcjMzERAQIDO+oCAABw4cKCVWkVERLcbkwa6pT///BO1tbVwdnbWWe/s7Iz8/PxWahUREd1uTBpIb9c/flwIwUeSExEZESYNdEuOjo4wNTVtUFUoKChoUH0gIqJ7F5MGuiWlUglvb2/s3r1bZ/3u3bvRr1+/VmoVERHdbmat3QC6O0ydOhVhYWHo3bs3fH19sWrVKpw9exaTJk1q7aYRyVZWVoZffvlFep2Tk4OsrCzY29ujY8eOrdgyojsLp1yS3pYtW4Z58+YhLy8Pnp6eWLRoER577LHWbhaRbHv37sXAgQMbrB83bhySkpJuf4OI7lBMGoiIiEgvHNNAREREemHSQERERHph0kBERER6YdJAREREemHSQERERHph0kBERER6YdJAREREemHSQCRTfHw8evbsKb0ODw/HyJEjb3s7fv/9dygUCmRlZd0wpnPnzli8eLHex0xKSsJ9990nu20KhQJbt26VfRwial1MGuieFB4eDoVCAYVCAXNzc3Tp0gVxcXEoLy9v8XO/++67et9FUJ8veiKiOwWfPUH3rMcffxxr165FdXU1vv/+e7zwwgsoLy/H8uXLG8RWV1fD3Ny8Wc6rVqub5ThERHcaVhronqVSqaDRaODi4oLQ0FCMHTtWKpHXdyl88MEH6NKlC1QqFYQQKC4uxoQJE+Dk5ARbW1sMGjQIx44d0znu22+/DWdnZ9jY2CAiIgJXr17V2X5990RdXR3mzp2L+++/HyqVCh07dsScOXMAAK6urgCAXr16QaFQYMCAAdJ+a9euRffu3WFhYYFu3bph2bJlOuc5dOgQevXqBQsLC/Tu3Rs//PCDwe/RwoUL4eXlBWtra7i4uCAqKgplZWUN4rZu3YoHHngAFhYWGDJkCHJzc3W2f/nll/D29oaFhQW6dOmC119/HTU1NQa3h4jubEwayGhYWlqiurpaev3LL79g06ZN2Lx5s9Q9MHz4cOTn52Pnzp3IzMzEww8/DH9/f1y6dAkAsGnTJsyePRtz5szBkSNH0K5duwZf5tebMWMG5s6di//85z84ceIEPv74Yzg7OwO49sUPAF9//TXy8vLw+eefAwBWr16NmTNnYs6cOTh58iQSEhLwn//8B+vWrQMAlJeXIygoCO7u7sjMzER8fDzi4uIMfk9MTEzw3nvvITs7G+vWrcOePXswbdo0nZgrV65gzpw5WLduHfbv34+SkhKMGTNG2v7VV1/hueeeQ3R0NE6cOIGVK1ciKSlJSoyI6B4iiO5B48aNEyNGjJBeHzx4UDg4OIhRo0YJIYSYPXu2MDc3FwUFBVLMN998I2xtbcXVq1d1jtW1a1excuVKIYQQvr6+YtKkSTrbfXx8xEMPPdTouUtKSoRKpRKrV69utJ05OTkCgPjhhx901ru4uIiPP/5YZ92bb74pfH19hRBCrFy5Utjb24vy8nJp+/Llyxs91t916tRJLFq06IbbN23aJBwcHKTXa9euFQBERkaGtO7kyZMCgDh48KAQQohHH31UJCQk6Bxn/fr1ol27dtJrAGLLli03PC8R3R04poHuWdu3b0ebNm1QU1OD6upqjBgxAkuWLJG2d+rUCW3btpVeZ2ZmoqysDA4ODjrHqaiowK+//goAOHnyJCZNmqSz3dfXF99++22jbTh58iQqKyvh7++vd7sLCwuRm5uLiIgIREZGSutramqk8RInT57EQw89BCsrK512GOrbb79FQkICTpw4gZKSEtTU1ODq1asoLy+HtbU1AMDMzAy9e/eW9unWrRvuu+8+nDx5Eo888ggyMzNx+PBhncpCbW0trl69iitXrui0kYjubkwa6J41cOBALF++HObm5tBqtQ0GOtZ/Kdarq6tDu3btsHfv3gbHauq0Q0tLS4P3qaurA3Cti8LHx0dnm6mpKQBANMMT7c+cOYNhw4Zh0qRJePPNN2Fvb4+0tDRERETodOMA16ZMXq9+XV1dHV5//XU8+eSTDWIsLCxkt5OI7hxMGuieZW1tjfvvv1/v+Icffhj5+fkwMzND586dG43p3r07MjIy8M9//lNal5GRccNjurm5wdLSEt988w1eeOGFBtuVSiWAa3+Z13N2dkb79u3x22+/YezYsY0e18PDA+vXr0dFRYWUmNysHY05cuQIampq8M4778DE5Nrwpk2bNjWIq6mpwZEjR/DII48AAE6fPo3Lly+jW7duAK69b6dPnzbovSaiuxOTBqL/N3jwYPj6+mLkyJGYO3cu3N3dcf78eezcuRMjR45E79698fLLL2PcuHHo3bs3/vGPf2DDhg04fvw4unTp0ugxLSwsMH36dEybNg1KpRL9+/dHYWEhjh8/joiICDg5OcHS0hIpKSno0KEDLCwsoFarER8fj+joaNja2mLo0KGorKzEkSNHUFRUhKlTpyI0NBQzZ85EREQEXnvtNfz+++9YsGCBQdfbtWtX1NTUYMmSJQgODsb+/fuxYsWKBnHm5uaYMmUK3nvvPZibm+Oll15C3759pSRi1qxZCAoKgouLC5555hmYmJjgxx9/xE8//YS33nrL8B8EEd2xOHuC6P8pFArs3LkTjz32GMaPH48HHngAY8aMwe+//y7Ndhg9ejRmzZqF6dOnw9vbG2fOnMGLL7540+P+5z//QWxsLGbNmoXu3btj9OjRKCgoAHBtvMB7772HlStXQqvVYsSIEQCAF154Af/973+RlJQELy8v+Pn5ISkpSZqi2aZNG3z55Zc4ceIEevXqhZkzZ2Lu3LkGXW/Pnj2xcOFCzJ07F56entiwYQMSExMbxFlZWWH69OkIDQ2Fr68vLC0tkZycLG0PDAzE9u3bsXv3bvTp0wd9+/bFwoUL0alTJ4PaQ0R3PoVojs5RIiIiuuex0kBERER6YdJAREREemHSQERERHph0kBERER6YdJAREREemHSQERERHph0kBERER6YdJAREREemHSQERERHph0kBERER6YdJAREREemHSQERERHr5P9zKJCYxXjh+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix of Model Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

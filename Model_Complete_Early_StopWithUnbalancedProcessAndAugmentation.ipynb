{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import gc\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_cv\n",
    "#import tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Declare file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "#metaPath = dataPath + \"train-metadata.csv\"\n",
    "metaPath = dataPath + \"sample-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "#hdf5_file = dataPath + \"train-image.hdf5\"\n",
    "hdf5_file = dataPath + \"sample-image.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\admin\\\\Documents\\\\DSTI\\\\DeepLearning\\\\Project/isic-2024-challenge/sample-metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#base_path = \"C:/Users/admin/Documents/DSTI/DeepLearning/Project/Computer_Vision/isic-2024-challenge\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(metaPath, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\admin\\\\Documents\\\\DSTI\\\\DeepLearning\\\\Project/isic-2024-challenge/sample-metadata.csv'"
     ]
    }
   ],
   "source": [
    "#base_path = \"C:/Users/admin/Documents/DSTI/DeepLearning/Project/Computer_Vision/isic-2024-challenge\"\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "#hdf5_file = os.path.join(base_path, \"sampleclaire-image.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_4364\\208283826.py:4: DtypeWarning: Columns (48,49,50,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(os.path.join(base_path, \"sampleclaire50000-metadata.csv\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "\n",
    "base_path = \"C:/Users/admin/Documents/DSTI/DeepLearning/Project/Computer_Vision/isic-2024-challenge2\"\n",
    "metadata = pd.read_csv(os.path.join(base_path, \"sampleclaire50000-metadata.csv\"))\n",
    "hdf5_file = os.path.join(base_path, \"sampleclaire50000-image.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Load metadata from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                          0\n",
      "age_approx                     319\n",
      "target                           0\n",
      "clin_size_long_diam_mm           0\n",
      "tbp_lv_areaMM2                   0\n",
      "tbp_lv_area_perim_ratio          0\n",
      "tbp_lv_eccentricity              0\n",
      "tbp_lv_minorAxisMM               0\n",
      "tbp_lv_color_std_mean            0\n",
      "tbp_lv_deltaLBnorm               0\n",
      "tbp_lv_radial_color_std_max      0\n",
      "tbp_lv_location                  0\n",
      "dtype: int64\n",
      "Number of unknown for tbp_lv_location 749\n"
     ]
    }
   ],
   "source": [
    "#METADATA: color and size features having no NAs\n",
    "metadata = metadata[[\"isic_id\",\n",
    "                     \"age_approx\",\n",
    "                     \"target\",\n",
    "                     \"clin_size_long_diam_mm\",\n",
    "                     \"tbp_lv_areaMM2\",\n",
    "                     \"tbp_lv_area_perim_ratio\",\n",
    "                     \"tbp_lv_eccentricity\",\n",
    "                     \"tbp_lv_minorAxisMM\",\n",
    "                     \"tbp_lv_color_std_mean\",\n",
    "                     \"tbp_lv_deltaLBnorm\",\n",
    "                     \"tbp_lv_radial_color_std_max\",\n",
    "                     \"tbp_lv_location\"]]\n",
    "\n",
    "\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())\n",
    "\n",
    "#Check number of Unknoxn for tbp_lv_location\n",
    "loc_unknown=metadata[metadata[\"tbp_lv_location\"]==\"Unknown\"]\n",
    "print(\"Number of unknown for tbp_lv_location\", len(loc_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activate for debugging of the predict function\n",
    "#metadata[\"target_cheat\"] = metadata[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown for tbp_lv_location 0\n"
     ]
    }
   ],
   "source": [
    "metadata=metadata[metadata[\"tbp_lv_location\"]!=\"Unknown\"]\n",
    "\n",
    "loc_unknown2=metadata[metadata[\"tbp_lv_location\"]==\"Unknown\"]\n",
    "print(\"Number of unknown for tbp_lv_location\", len(loc_unknown2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['isic_id', 'age_approx', 'target', 'clin_size_long_diam_mm',\n",
      "       'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_eccentricity',\n",
      "       'tbp_lv_minorAxisMM', 'tbp_lv_color_std_mean', 'tbp_lv_deltaLBnorm',\n",
      "       'tbp_lv_radial_color_std_max', 'category_Head & Neck',\n",
      "       'category_Left Arm', 'category_Left Arm - Lower',\n",
      "       'category_Left Arm - Upper', 'category_Left Leg',\n",
      "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
      "       'category_Right Arm', 'category_Right Arm - Lower',\n",
      "       'category_Right Arm - Upper', 'category_Right Leg',\n",
      "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
      "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
      "       'category_Torso Back Top Third', 'category_Torso Front',\n",
      "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Apply One-hot encoding for location\n",
    "location=pd.get_dummies(metadata[\"tbp_lv_location\"],prefix='category')\n",
    "location = location.astype(int)\n",
    "metadata = pd.concat([metadata, location], axis=1)\n",
    "metadata=metadata.drop(\"tbp_lv_location\",axis=1)\n",
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                             0\n",
      "age_approx                          0\n",
      "target                              0\n",
      "clin_size_long_diam_mm              0\n",
      "tbp_lv_areaMM2                      0\n",
      "tbp_lv_area_perim_ratio             0\n",
      "tbp_lv_eccentricity                 0\n",
      "tbp_lv_minorAxisMM                  0\n",
      "tbp_lv_color_std_mean               0\n",
      "tbp_lv_deltaLBnorm                  0\n",
      "tbp_lv_radial_color_std_max         0\n",
      "category_Head & Neck                0\n",
      "category_Left Arm                   0\n",
      "category_Left Arm - Lower           0\n",
      "category_Left Arm - Upper           0\n",
      "category_Left Leg                   0\n",
      "category_Left Leg - Lower           0\n",
      "category_Left Leg - Upper           0\n",
      "category_Right Arm                  0\n",
      "category_Right Arm - Lower          0\n",
      "category_Right Arm - Upper          0\n",
      "category_Right Leg                  0\n",
      "category_Right Leg - Lower          0\n",
      "category_Right Leg - Upper          0\n",
      "category_Torso Back Bottom Third    0\n",
      "category_Torso Back Middle Third    0\n",
      "category_Torso Back Top Third       0\n",
      "category_Torso Front                0\n",
      "category_Torso Front Bottom Half    0\n",
      "category_Torso Front Top Half       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of age_approx for each target group\n",
    "mean_age_malign = metadata.loc[metadata[\"target\"] == 1, \"age_approx\"].mean()\n",
    "mean_age_benign = metadata.loc[metadata[\"target\"] == 0, \"age_approx\"].mean()\n",
    "\n",
    "# Define a function to fill NA based on the target value\n",
    "def fill_na_by_target(row):\n",
    "    if pd.isna(row['age_approx']):\n",
    "        if row['target'] == 1:\n",
    "            return mean_age_malign\n",
    "        elif row['target'] == 0:\n",
    "            return mean_age_benign\n",
    "    return row['age_approx']\n",
    "\n",
    "# Apply the function to the age_approx column\n",
    "metadata['age_approx'] = metadata.apply(fill_na_by_target, axis=1)\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#from sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import MinMaxScaler\\n#Normalization\\n#Select the column\\nfeature=metadata.drop(columns=['isic_id','target'])\\n\\n#scaler=StandardScaler() for standardization\\nscaler = MinMaxScaler()\\nfeature_standardized=scaler.fit_transform(feature)\\nfeature_standardized_df = pd.DataFrame(feature_standardized, columns=feature.columns)\\n\\nmetadata=pd.concat([metadata[['isic_id','target']].reset_index(drop=True), feature_standardized_df] , axis=1)\\nprint(len(metadata.columns))\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Normalization\n",
    "#Select the column\n",
    "feature=metadata.drop(columns=['isic_id','target'])\n",
    "\n",
    "#scaler=StandardScaler() for standardization\n",
    "scaler = MinMaxScaler()\n",
    "feature_standardized=scaler.fit_transform(feature)\n",
    "feature_standardized_df = pd.DataFrame(feature_standardized, columns=feature.columns)\n",
    "\n",
    "metadata=pd.concat([metadata[['isic_id','target']].reset_index(drop=True), feature_standardized_df] , axis=1)\n",
    "print(len(metadata.columns))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nmetadata=pd.concat([metadata[['isic_id','target', 'category_Head & Neck',\\n       'category_Left Arm', 'category_Left Arm - Lower',\\n       'category_Left Arm - Upper', 'category_Left Leg',\\n       'category_Left Leg - Lower', 'category_Left Leg - Upper',\\n       'category_Right Arm', 'category_Right Arm - Lower',\\n       'category_Right Arm - Upper', 'category_Right Leg',\\n       'category_Right Leg - Lower', 'category_Right Leg - Upper',\\n       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\\n       'category_Torso Back Top Third',\\n       'category_Torso Front Bottom Half', 'category_Torso Front Top Half']].reset_index(drop=True), feature_standardized_df] , axis=1)\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Normalization\n",
    "#Select the column\n",
    "\n",
    "feature=metadata.drop(columns=['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third','category_Torso Front',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half'])\n",
    "'''\n",
    "#Select the column\n",
    "feature=metadata.drop(columns=['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half'])\n",
    "'''\n",
    "\n",
    "#scaler=StandardScaler() for standardization\n",
    "scaler = MinMaxScaler()\n",
    "feature_standardized=scaler.fit_transform(feature)\n",
    "feature_standardized_df = pd.DataFrame(feature_standardized, columns=feature.columns)\n",
    "\n",
    "\n",
    "metadata=pd.concat([metadata[['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third', 'category_Torso Front',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half']].reset_index(drop=True), feature_standardized_df] , axis=1)\n",
    "'''\n",
    "\n",
    "metadata=pd.concat([metadata[['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half']].reset_index(drop=True), feature_standardized_df] , axis=1)\n",
    "'''\n",
    "#print(len(metadata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4a - Train, Validate, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_if_needed(obj):\n",
    "    if isinstance(obj, pd.Series):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "#Function to perform train-validate or train-test-validate split on a list of isic_ids\n",
    "def ttv_split(isic_ids, test_frac=0.2, validate_frac=0.2, random_state=88, shuffle=True, stratify=None):\n",
    "    if test_frac < 0 or validate_frac < 0:\n",
    "        print(\"ERROR: Test of validate fraction is negative\")\n",
    "        return None\n",
    "    if test_frac > 1 or validate_frac > 1:\n",
    "        print(\"ERROR: Test of validate fraction is above 0\")\n",
    "        return None\n",
    "    if test_frac + validate_frac >= 1:\n",
    "        print(\"ERROR: Test and validate fractions sum to 1 or more.\")\n",
    "        return None\n",
    "\n",
    "    #Split training from the rest\n",
    "    test_size = test_frac + validate_frac\n",
    "    train, temp = train_test_split(isic_ids, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "    #Split test and validate\n",
    "    if test_frac == 0 or validate_frac == 0:\n",
    "       # return train.tolist(), temp.tolist()\n",
    "        return list_if_needed(train), list_if_needed(temp)\n",
    "    else:\n",
    "        test_size = test_frac / (test_frac + validate_frac)\n",
    "        test, validate = train_test_split(temp, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "        #return train.tolist(), test.tolist(), validate.tolist()\n",
    "        return list_if_needed(train), list_if_needed(test), list_if_needed(validate)\n",
    "\n",
    "#Generate the splits of the isic_ids\n",
    "#train_ids, test_ids, val_ids = ttv_split(metadata[\"isic_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep 10% of isic_Id of target=1 without duplication\n",
    "isic_id_val_target_1 = metadata[metadata['target'] == 1]['isic_id'].tolist()\n",
    "n=int(0.1*len(isic_id_val_target_1))\n",
    "isic_ids_keep_val = np.random.choice(isic_id_val_target_1, n , replace=False)\n",
    "\n",
    "#isic_ids_keep_train = list(set(isic_id_val_target_1) - set(isic_ids_keep_val))\n",
    "\n",
    "\n",
    "# Split to isolate the test set\n",
    "isic_ids = metadata.loc[~metadata[\"isic_id\"].isin(isic_ids_keep_val), 'isic_id']\n",
    "train_val_ids, test_ids= ttv_split(isic_ids, test_frac=0.2, validate_frac=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49301\n"
     ]
    }
   ],
   "source": [
    "print(len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9860\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49296\n"
     ]
    }
   ],
   "source": [
    "print(len(isic_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4b - Data augmentation\n",
    "- Augment only the malignant data in the training set\n",
    "- Reformat all lists (train_ids, test_ids, val_ids) to be compatible: list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "test_tar1=metadata.loc[(metadata[\"target\"] == 1) & (metadata[\"isic_id\"].isin( test_ids)),'isic_id']\n",
    "print(len(test_tar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make list of ids compatible with data augmentations\n",
    "#Base data takes a value of 0, meaning it should not be modified\n",
    "train_val_ids_mods = [(id, 0) for id in train_val_ids]\n",
    "test_ids_mods = [(id, 0) for id in test_ids]\n",
    "#train_ids_mods = [(id, 0) for id in train_ids]\n",
    "#val_ids_mods = [(id, 0) for id in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives in training and validation data: 35\n"
     ]
    }
   ],
   "source": [
    "#Identify the malignant cases in the training data\n",
    "#all_pos = metadata[metadata[\"target\"]==1][\"isic_id\"]\n",
    "all_pos = metadata.loc[(metadata[\"target\"] == 1) & (~metadata[\"isic_id\"].isin(list(isic_ids_keep_val) + test_ids)),'isic_id']\n",
    "pos_in_train_val = all_pos[all_pos.isin(train_val_ids)]\n",
    "print(\"Number of positives in training and validation data:\", len(pos_in_train_val))\n",
    "#pos_in_train = all_pos[all_pos.isin(train_ids)]\n",
    "#print(\"Number of positives in training data:\", len(pos_in_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49301\n"
     ]
    }
   ],
   "source": [
    "print(len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39436\n"
     ]
    }
   ],
   "source": [
    "print(len(train_val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42936\n"
     ]
    }
   ],
   "source": [
    "# Apply augmentations only to training and validation sets before splitting them\n",
    "#Duplicates of ids will each have a different number, indicating a specific augmentation to be used\n",
    "nb_of_augments = 100 \n",
    "\n",
    "rng = np.random.default_rng()\n",
    "for i in range(nb_of_augments):\n",
    "    rand_nb = rng.random()\n",
    "    #Option 1: use random float between 0 and 1\n",
    "    #train_ids_mods += [(id, rand_nb) for id in pos_in_train_val]\n",
    "    #Option 2: use integer\n",
    "    train_val_ids_mods += [(id, i + 1) for id in pos_in_train_val]\n",
    "\n",
    "#Shuffle the list\n",
    "np.random.shuffle(train_val_ids_mods)\n",
    "print(len(train_val_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids_mods, val_ids_mods= ttv_split(train_val_ids_mods, test_frac=0.0, validate_frac=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28767\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2346\n"
     ]
    }
   ],
   "source": [
    "train_ids_mods_tar1 = [(id_mod, i) for (id_mod, i) in train_ids_mods if id_mod in pos_in_train_val_set]\n",
    "print(len(train_ids_mods_tar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14169\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "#apply duplication on reserved validation data (target 1) \n",
    "nb_of_augments = 15 \n",
    "\n",
    "rng = np.random.default_rng()\n",
    "isic_ids_keep_val_mods=[]\n",
    "for i in range(nb_of_augments):\n",
    "    rand_nb = rng.random()\n",
    "    #Option 1: use random float between 0 and 1\n",
    "    #train_ids_mods += [(id, rand_nb) for id in pos_in_train_val]\n",
    "    #Option 2: use integer\n",
    "    isic_ids_keep_val_mods += [(id, i + 1) for id in isic_ids_keep_val]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(isic_ids_keep_val_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction of the target =0 on validation data set\n",
    "# Split id by target\n",
    "pos_in_train_val_set = set(pos_in_train_val)\n",
    "val_ids_mods_tar1 = [(id_mod, i) for (id_mod, i) in val_ids_mods if id_mod in pos_in_train_val_set]\n",
    "\n",
    "val_ids_mods_tar0 = [(id_mod, i) for (id_mod, i) in val_ids_mods if id_mod not in pos_in_train_val_set]\n",
    "# Reduction on target = 0\n",
    "val_red = int(0.2 * len(val_ids_mods_tar0))\n",
    "val_ids_mods_tar0_red = random.sample(val_ids_mods_tar0, val_red)    \n",
    "\n",
    "# concatenation of data target = 1 + target = 0 after reduction\n",
    "val_ids_mods_red = val_ids_mods_tar1 + val_ids_mods_tar0_red\n",
    "val_ids_mods=isic_ids_keep_val_mods + val_ids_mods_red \n",
    "\n",
    "\n",
    "#Shuffle the list\n",
    "np.random.shuffle(val_ids_mods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12980\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods_tar0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2596\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods_tar0_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1189\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods_tar1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3785\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods_red))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3860\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Load images and create hybrid tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hair_removal(image, crop_pixels=10):\n",
    "    height_pixels = len(image)  # Image rows\n",
    "    width_pixels = len(image[0])  # Image columns\n",
    "\n",
    "    # Image cropping\n",
    "    height = [crop_pixels, height_pixels - crop_pixels]\n",
    "    width = [crop_pixels, width_pixels - crop_pixels]\n",
    "    img = image[height[0]:height[1], width[0]:width[1]]\n",
    "\n",
    "    # Gray scale\n",
    "    grayScale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Black hat filter\n",
    "    kernel = cv2.getStructuringElement(1, (9, 9))\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "    # Gaussian filter\n",
    "    bhg = cv2.GaussianBlur(blackhat, (3, 3), cv2.BORDER_DEFAULT)\n",
    "    # Binary thresholding (MASK)\n",
    "    ret, mask = cv2.threshold(bhg, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Replace pixels of the mask\n",
    "    dst = cv2.inpaint(img, mask, 6, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return dst\n",
    "\n",
    "#def resize_image(image, target_size=(100, 100)):\n",
    "#    resized_image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "#    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation function\n",
    "def augment_image(image):\n",
    "    \"\"\"\n",
    "    Apply a series of augmentations to create diverse variations of the input image.\n",
    "    Includes random flips, rotations, brightness adjustments, and other transformations.\n",
    "    \"\"\"\n",
    "    # Apply various augmentations\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    '''\n",
    "\n",
    "    # RandomCutout initialization\n",
    "    cutout_layer = keras_cv.layers.RandomCutout(height_factor=(0.02, 0.06), width_factor=(0.02, 0.06))\n",
    "    \n",
    "    # List of augmentations\n",
    "    augmentations = [\n",
    "        tf.image.random_flip_left_right,  \n",
    "        tf.image.random_flip_up_down,   \n",
    "        lambda img: tf.image.rot90(img, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)), \n",
    "        tf.image.random_brightness,      \n",
    "        tf.image.random_contrast,         \n",
    "        tf.image.random_saturation,       \n",
    "        lambda img: cutout_layer(img)    \n",
    "    ]\n",
    "    \n",
    "    # Shuffle and pick one augmentation\n",
    "    augmentation = augmentations[tf.random.uniform(shape=[], minval=0, maxval=len(augmentations), dtype=tf.int32)]\n",
    "    \n",
    "    # Apply augmentation with 99% probability\n",
    "    if tf.random.uniform([]) < 0.95:\n",
    "        # Apply augmentation \n",
    "        if augmentation in [tf.image.random_flip_left_right, tf.image.random_flip_up_down]:\n",
    "            image = augmentation(image) \n",
    "        elif augmentation == tf.image.random_brightness:\n",
    "            image = augmentation(image, max_delta=0.25)  \n",
    "        elif augmentation == tf.image.random_contrast:\n",
    "            image = augmentation(image, lower=0.7, upper=1.8)  \n",
    "        elif augmentation == tf.image.random_saturation:\n",
    "            image = augmentation(image, lower=0.7, upper=1.8)  \n",
    "        else:\n",
    "            image = augmentation(image)  \n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(metadata, img_names):\n",
    "    # Initialize counters for target=0 and target=1\n",
    "    target_0_count = 0\n",
    "    target_1_count = 0\n",
    "\n",
    "    # Loop through each tuple in img_names (img_name, transformation)\n",
    "    for img_name, mod in img_names:\n",
    "        # Filter metadata to find the corresponding isic_id\n",
    "        metadata_filtered = metadata[metadata[\"isic_id\"] == img_name]\n",
    "\n",
    "        if not metadata_filtered.empty:\n",
    "            # Retrieve the target value for the corresponding isic_id\n",
    "            target = metadata_filtered[\"target\"].values[0]\n",
    "\n",
    "            # Increment the counter based on the target value\n",
    "            if target == 0:\n",
    "                target_0_count += 1\n",
    "            elif target == 1:\n",
    "                target_1_count += 1\n",
    "\n",
    "    # Calculate total number of images\n",
    "    total = target_0_count + target_1_count\n",
    "\n",
    "    # Calculate class weights based on the counts, avoid division by zero\n",
    "    if target_0_count > 0:\n",
    "        weight_for_0 = total / (2 * target_0_count)\n",
    "    else:\n",
    "        weight_for_0 = 1\n",
    "\n",
    "    if target_1_count > 0:\n",
    "        weight_for_1 = total / (2 * target_1_count)\n",
    "    else:\n",
    "        weight_for_1 = 1\n",
    "\n",
    "    return weight_for_0, weight_for_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATOR FOR HDF5 AND METADATA\n",
    "\"\"\"\n",
    "file = filepath to the hdf5 file containing the image data\n",
    "metadata = the full metadata dataframe (col1 = \"isic_id\", col2 = \"target\")\n",
    "img_names = list of tuples, each containing the isic_id followed by a number, signifying:\n",
    "            * 0 when original data is to be used\n",
    "            * random number - data augmentation is to be applied\n",
    "imgSize = images are to be adjusted to this size (square) in pixels\n",
    "\"\"\"\n",
    "class hdf5_generator:\n",
    "    def __init__(self, file, metadata, img_names, imgSize,is_training=False):\n",
    "        self.file = file\n",
    "        self.metadata = metadata\n",
    "        self.img_names = img_names\n",
    "        self.imgSize = imgSize\n",
    "        self.is_training=is_training\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as h5file:\n",
    "            for img_name_tuple in self.img_names:\n",
    "                img_name, mod = img_name_tuple\n",
    "                try:\n",
    "                    # Load image data from HDF5\n",
    "                    img = np.array(Image.open(io.BytesIO(h5file[img_name][()])))\n",
    "                    \n",
    "                    # Clean image\n",
    "                    img = hair_removal(img)\n",
    "\n",
    "                    \n",
    "                    #if mod != 0:\n",
    "                    if self.is_training==True:\n",
    "                        # Data Augmentation \n",
    "                        img= augment_image(img)\n",
    "                    else:\n",
    "                        img = tf.image.random_flip_left_right(img)\n",
    "                        img = tf.image.random_flip_up_down(img)\n",
    "                        img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "                        img = tf.image.random_contrast(img, lower=0.85, upper=1.15)\n",
    "                        img = tf.image.random_saturation(img, lower=0.85, upper=1.15)\n",
    "                      \n",
    "                        \n",
    "                    # Resize the image\n",
    "                    img = tf.image.resize(img, [self.imgSize, self.imgSize])\n",
    "\n",
    "                    # Standardize and return as TensorFlow constant\n",
    "                    img = tf.constant(img / 255, dtype=tf.float32)  # Standardize here\n",
    "\n",
    "                    #Retrieve corresponding metadata\n",
    "                    meta = self.metadata[self.metadata[\"isic_id\"] == img_name].iloc[:,2:]\n",
    "\n",
    "                    #Retrieve corresponding target\n",
    "                    target = self.metadata[self.metadata[\"isic_id\"] == img_name][\"target\"]\n",
    "                    target = np.reshape(target, (1, 1))\n",
    "                    \n",
    "                    yield (img, meta), target\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_name}: {e}\")\n",
    "                    # log the error to a file for later analysis\n",
    "                    with open('image_errors.log', 'a') as f:\n",
    "                        f.write(f\"Error loading image {img_name}: {e}\\n\")\n",
    "                    continue\n",
    "\n",
    "#Generate the dataset with batch size and prefetching\n",
    "def make_dataset(hdf5_file, metadata, img_names, imgSize=100, batch_size=32, shuffle=True, is_training=False, weight_calc=False):\n",
    "    if weight_calc:\n",
    "        #Get number of picture for each target\n",
    "        weight_for_0, weight_for_1 = compute_class_weights(metadata, img_names)\n",
    "        #print(f\"Class weight for target=0: {weight_for_0}\")\n",
    "        #print(f\"Class weight for target=1: {weight_for_1}\")\n",
    "    else:\n",
    "        weight_for_0, weight_for_1 = None, None\n",
    "        \n",
    "    # Get the number of metadata features (isic_id and target are present, so subtract)\n",
    "    num_features = metadata.shape[-1] - 2\n",
    "    \n",
    "    # Generate image dataset\n",
    "    element_spec = ((tf.TensorSpec(shape=(imgSize, imgSize, 3), dtype=tf.float32),\n",
    "                 tf.TensorSpec(shape=(1, num_features), dtype=tf.float32)),\n",
    "                tf.TensorSpec(shape=(1, 1), dtype=tf.int32))\n",
    "    \n",
    "    img_dataset = tf.data.Dataset.from_generator(\n",
    "        hdf5_generator(hdf5_file, metadata, img_names, imgSize, is_training),\n",
    "        output_signature=element_spec\n",
    "    )\n",
    "\n",
    "    # Add shuffling, batching, and prefetching\n",
    "    dataset = img_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset, (weight_for_0, weight_for_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'leaky_relu', img_size = 100, img_channels=3):\n",
    "        #Run the constructor of the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "        \n",
    "        #Image size declaration\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "        #Layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(img_size, img_size, img_channels),\n",
    "                                            kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image, x_meta = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Metadata Neural Network\n",
    "class Meta_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        #Run the constructor of the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "        #Layers\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        x_all = tf.reshape(x_meta, (tf.shape(x_meta)[0], x_meta.shape[-1]))\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        x_all = self.dense2(x_all)\n",
    "        if training:\n",
    "            x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'leaky_relu', img_size = 100, img_channels = 3):\n",
    "        #Run the constructor of the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "        #Image size declaration\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "        #Layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(img_size, img_size, img_channels),\n",
    "                                            kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 5, activation='relu', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.10)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.10)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.concatenate = keras.layers.Concatenate(axis=1)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x = self.conv1(x_image)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x = self.flatten(x)\n",
    "        # Reshape metadata to match dimensions\n",
    "        x_meta = tf.reshape(x_meta, (tf.shape(x_meta)[0], x_meta.shape[-1]))\n",
    "        x_all = self.concatenate([x, x_meta])\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        if training:\n",
    "            x_all = self.dropout1(x_all, training=training)\n",
    "        x_all = self.dense2(x_all)\n",
    "        if training:\n",
    "            x_all = self.dropout2(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "#model = CNN_model(neurons=8, activ='tanh')\n",
    "model = Hybrid_model(neurons=36, activ='leaky_relu')\n",
    "#model = Meta_model(neurons=18, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Take 1 batch from the dataset and check its content\\nfor batch in train_dataset.take(1):\\n    (img_batch, meta_batch), target_batch = batch\\n    \\n    # Print the shapes of the individual components\\n    print(f\"Image batch shape: {img_batch.shape}\")\\n    print(f\"Metadata batch shape: {meta_batch.shape}\")\\n    print(f\"Target batch shape: {target_batch.shape}\")\\n\\n# To count the total number of batches\\nbatch_count = 0\\nfor _ in train_dataset:\\n    batch_count += 1\\n\\nprint(f\"Total number of batches in the dataset: {batch_count}\")\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Take 1 batch from the dataset and check its content\n",
    "for batch in train_dataset.take(1):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the individual components\n",
    "    print(f\"Image batch shape: {img_batch.shape}\")\n",
    "    print(f\"Metadata batch shape: {meta_batch.shape}\")\n",
    "    print(f\"Target batch shape: {target_batch.shape}\")\n",
    "\n",
    "# To count the total number of batches\n",
    "batch_count = 0\n",
    "for _ in train_dataset:\n",
    "    batch_count += 1\n",
    "\n",
    "print(f\"Total number of batches in the dataset: {batch_count}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear the memory leak in Keras\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "    #print(f\"Epoch {epoch+1} finished. Validation loss: {logs['val_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training batches in dataset: 903\n",
      "Total validate batches in dataset: 2922\n",
      "Total test batches in dataset: 9860\n"
     ]
    }
   ],
   "source": [
    "#Set batch sizes\n",
    "train_batch_size = 32\n",
    "val_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "#Determine the number of batches\n",
    "nb_training_batches = int(len(train_ids_mods)//train_batch_size)\n",
    "nb_validate_batches = int(len(val_ids_mods)//val_batch_size)\n",
    "nb_test_batches = int(len(test_ids_mods)//test_batch_size)\n",
    "\n",
    "#Print results\n",
    "print(\"Total training batches in dataset:\", nb_training_batches)\n",
    "print(\"Total validate batches in dataset:\", nb_validate_batches)\n",
    "print(\"Total test batches in dataset:\", nb_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets and get weights\n",
    "train_dataset, class_weights = make_dataset(hdf5_file, metadata, train_ids_mods, batch_size=train_batch_size, is_training=True, weight_calc=True)\n",
    "weight_for_0, weight_for_1 = class_weights\n",
    "validate_dataset, class_weights = make_dataset(hdf5_file, metadata, val_ids_mods, batch_size = val_batch_size, is_training=False, weight_calc=True)\n",
    "test_dataset, _ = make_dataset(hdf5_file, metadata, test_ids_mods, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "First training ID: ISIC_0392891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\numpy\\core\\getlimits.py:549: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  setattr(self, word, getattr(machar, word).flat[0])\n",
      "C:\\Users\\admin\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\numpy\\core\\getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.\n",
      "  return self._float_to_str(self.smallest_subnormal)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1188s\u001b[0m 1s/step - binary_accuracy: 0.6301 - false_negatives: 271.0199 - false_positives: 3820.7578 - loss: 0.6040 - true_negatives: 9387.5801 - true_positives: 1000.6073 - val_binary_accuracy: 0.8888 - val_false_negatives: 93.0000 - val_false_positives: 232.0000 - val_loss: 0.4581 - val_true_negatives: 2374.0000 - val_true_positives: 223.0000\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\anaconda3\\envs\\env_DL_python3119\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "EPOCH 2\n",
      "First training ID: ISIC_1993761\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1767s\u001b[0m 2s/step - binary_accuracy: 0.8762 - false_negatives: 108.8628 - false_positives: 1627.6814 - loss: 0.2699 - true_negatives: 11570.3652 - true_positives: 1173.0553 - val_binary_accuracy: 0.8279 - val_false_negatives: 60.0000 - val_false_positives: 443.0000 - val_loss: 0.6394 - val_true_negatives: 2163.0000 - val_true_positives: 256.0000\n",
      "EPOCH 3\n",
      "First training ID: ISIC_7836717\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2104s\u001b[0m 2s/step - binary_accuracy: 0.8970 - false_negatives: 69.7699 - false_positives: 1403.3507 - loss: 0.2101 - true_negatives: 11824.7656 - true_positives: 1182.0785 - val_binary_accuracy: 0.9196 - val_false_negatives: 60.0000 - val_false_positives: 175.0000 - val_loss: 0.6050 - val_true_negatives: 2431.0000 - val_true_positives: 256.0000\n",
      "EPOCH 4\n",
      "First training ID: ISIC_0519649\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1939s\u001b[0m 2s/step - binary_accuracy: 0.9138 - false_negatives: 47.2102 - false_positives: 1193.9613 - loss: 0.1717 - true_negatives: 12035.7227 - true_positives: 1203.0708 - val_binary_accuracy: 0.9381 - val_false_negatives: 60.0000 - val_false_positives: 121.0000 - val_loss: 0.7208 - val_true_negatives: 2485.0000 - val_true_positives: 256.0000\n",
      "EPOCH 5\n",
      "First training ID: ISIC_5293329\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1910s\u001b[0m 2s/step - binary_accuracy: 0.9264 - false_negatives: 36.9436 - false_positives: 1011.3407 - loss: 0.1524 - true_negatives: 12210.6826 - true_positives: 1220.9978 - val_binary_accuracy: 0.9220 - val_false_negatives: 45.0000 - val_false_positives: 183.0000 - val_loss: 0.8383 - val_true_negatives: 2423.0000 - val_true_positives: 271.0000\n",
      "EPOCH 6\n",
      "First training ID: ISIC_6541270\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1968s\u001b[0m 2s/step - binary_accuracy: 0.9274 - false_negatives: 37.6394 - false_positives: 981.2876 - loss: 0.1597 - true_negatives: 12247.8848 - true_positives: 1213.1527 - val_binary_accuracy: 0.9398 - val_false_negatives: 60.0000 - val_false_positives: 116.0000 - val_loss: 0.8393 - val_true_negatives: 2490.0000 - val_true_positives: 256.0000\n",
      "EPOCH 7\n",
      "First training ID: ISIC_7705015\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32018s\u001b[0m 35s/step - binary_accuracy: 0.9345 - false_negatives: 31.7367 - false_positives: 913.4901 - loss: 0.1405 - true_negatives: 12285.3271 - true_positives: 1249.4104 - val_binary_accuracy: 0.9322 - val_false_negatives: 60.0000 - val_false_positives: 138.0000 - val_loss: 0.8896 - val_true_negatives: 2468.0000 - val_true_positives: 256.0000\n",
      "EPOCH 8\n",
      "First training ID: ISIC_1229208\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1663s\u001b[0m 2s/step - binary_accuracy: 0.9451 - false_negatives: 27.5199 - false_positives: 742.9635 - loss: 0.1160 - true_negatives: 12472.9414 - true_positives: 1236.5398 - val_binary_accuracy: 0.9333 - val_false_negatives: 45.0000 - val_false_positives: 150.0000 - val_loss: 0.9463 - val_true_negatives: 2456.0000 - val_true_positives: 271.0000\n",
      "EPOCH 9\n",
      "First training ID: ISIC_6424871\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2264s\u001b[0m 3s/step - binary_accuracy: 0.9491 - false_negatives: 24.1095 - false_positives: 707.0078 - loss: 0.1102 - true_negatives: 12532.3174 - true_positives: 1216.5299 - val_binary_accuracy: 0.9322 - val_false_negatives: 75.0000 - val_false_positives: 123.0000 - val_loss: 1.0808 - val_true_negatives: 2483.0000 - val_true_positives: 241.0000\n",
      "EPOCH 10\n",
      "First training ID: ISIC_9268701\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1771s\u001b[0m 2s/step - binary_accuracy: 0.9525 - false_negatives: 21.1759 - false_positives: 668.9314 - loss: 0.1032 - true_negatives: 12554.7012 - true_positives: 1235.1560 - val_binary_accuracy: 0.9322 - val_false_negatives: 75.0000 - val_false_positives: 123.0000 - val_loss: 1.1288 - val_true_negatives: 2483.0000 - val_true_positives: 241.0000\n",
      "EPOCH 11\n",
      "First training ID: ISIC_3892634\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1600s\u001b[0m 2s/step - binary_accuracy: 0.9587 - false_negatives: 17.3296 - false_positives: 601.0266 - loss: 0.0913 - true_negatives: 12612.8535 - true_positives: 1248.7544 - val_binary_accuracy: 0.9398 - val_false_negatives: 75.0000 - val_false_positives: 101.0000 - val_loss: 1.1233 - val_true_negatives: 2505.0000 - val_true_positives: 241.0000\n",
      "EPOCH 12\n",
      "First training ID: ISIC_0601026\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1589s\u001b[0m 2s/step - binary_accuracy: 0.9580 - false_negatives: 25.7212 - false_positives: 597.4016 - loss: 0.0988 - true_negatives: 12631.7549 - true_positives: 1225.0874 - val_binary_accuracy: 0.9415 - val_false_negatives: 75.0000 - val_false_positives: 96.0000 - val_loss: 1.1394 - val_true_negatives: 2510.0000 - val_true_positives: 241.0000\n",
      "EPOCH 13\n",
      "First training ID: ISIC_9336671\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1458s\u001b[0m 2s/step - binary_accuracy: 0.9611 - false_negatives: 19.5066 - false_positives: 549.2411 - loss: 0.0864 - true_negatives: 12674.8848 - true_positives: 1236.3319 - val_binary_accuracy: 0.9466 - val_false_negatives: 60.0000 - val_false_positives: 96.0000 - val_loss: 1.2111 - val_true_negatives: 2510.0000 - val_true_positives: 256.0000\n",
      "EPOCH 14\n",
      "First training ID: ISIC_7420584\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1470s\u001b[0m 2s/step - binary_accuracy: 0.9618 - false_negatives: 13.1858 - false_positives: 532.5255 - loss: 0.0854 - true_negatives: 12704.4365 - true_positives: 1229.8164 - val_binary_accuracy: 0.9470 - val_false_negatives: 60.0000 - val_false_positives: 95.0000 - val_loss: 1.3393 - val_true_negatives: 2511.0000 - val_true_positives: 256.0000\n",
      "EPOCH 15\n",
      "First training ID: ISIC_0551805\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1641s\u001b[0m 2s/step - binary_accuracy: 0.9640 - false_negatives: 18.3119 - false_positives: 520.6759 - loss: 0.0839 - true_negatives: 12720.6182 - true_positives: 1220.3584 - val_binary_accuracy: 0.9473 - val_false_negatives: 60.0000 - val_false_positives: 94.0000 - val_loss: 1.2684 - val_true_negatives: 2512.0000 - val_true_positives: 256.0000\n",
      "EPOCH 16\n",
      "First training ID: ISIC_8122351\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 2s/step - binary_accuracy: 0.9665 - false_negatives: 15.7157 - false_positives: 472.6726 - loss: 0.0808 - true_negatives: 12752.8174 - true_positives: 1238.7588 - val_binary_accuracy: 0.9459 - val_false_negatives: 75.0000 - val_false_positives: 83.0000 - val_loss: 1.3467 - val_true_negatives: 2523.0000 - val_true_positives: 241.0000\n",
      "EPOCH 17\n",
      "First training ID: ISIC_3113644\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1309s\u001b[0m 1s/step - binary_accuracy: 0.9675 - false_negatives: 17.0310 - false_positives: 466.3109 - loss: 0.0937 - true_negatives: 12772.7168 - true_positives: 1223.9060 - val_binary_accuracy: 0.9449 - val_false_negatives: 75.0000 - val_false_positives: 86.0000 - val_loss: 0.8844 - val_true_negatives: 2520.0000 - val_true_positives: 241.0000\n",
      "EPOCH 18\n",
      "First training ID: ISIC_7724515\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1298s\u001b[0m 1s/step - binary_accuracy: 0.9612 - false_negatives: 18.9779 - false_positives: 534.7202 - loss: 0.0888 - true_negatives: 12703.0557 - true_positives: 1223.2113 - val_binary_accuracy: 0.9507 - val_false_negatives: 60.0000 - val_false_positives: 84.0000 - val_loss: 1.1074 - val_true_negatives: 2522.0000 - val_true_positives: 256.0000\n",
      "EPOCH 19\n",
      "First training ID: ISIC_3407047\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1273s\u001b[0m 1s/step - binary_accuracy: 0.9709 - false_negatives: 10.7965 - false_positives: 410.9701 - loss: 0.0660 - true_negatives: 12805.3770 - true_positives: 1252.8208 - val_binary_accuracy: 0.9507 - val_false_negatives: 60.0000 - val_false_positives: 84.0000 - val_loss: 1.2165 - val_true_negatives: 2522.0000 - val_true_positives: 256.0000\n",
      "EPOCH 20\n",
      "First training ID: ISIC_2586193\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1294s\u001b[0m 1s/step - binary_accuracy: 0.9671 - false_negatives: 14.5509 - false_positives: 442.9016 - loss: 0.0795 - true_negatives: 12779.8926 - true_positives: 1242.6195 - val_binary_accuracy: 0.9463 - val_false_negatives: 60.0000 - val_false_positives: 97.0000 - val_loss: 1.1842 - val_true_negatives: 2509.0000 - val_true_positives: 256.0000\n",
      "EPOCH 21\n",
      "First training ID: ISIC_5455209\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1266s\u001b[0m 1s/step - binary_accuracy: 0.9719 - false_negatives: 9.1051 - false_positives: 384.8971 - loss: 0.0634 - true_negatives: 12840.4883 - true_positives: 1245.4746 - val_binary_accuracy: 0.9452 - val_false_negatives: 75.0000 - val_false_positives: 85.0000 - val_loss: 1.3169 - val_true_negatives: 2521.0000 - val_true_positives: 241.0000\n",
      "EPOCH 22\n",
      "First training ID: ISIC_8527032\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1363s\u001b[0m 2s/step - binary_accuracy: 0.9705 - false_negatives: 19.1095 - false_positives: 405.7743 - loss: 0.0723 - true_negatives: 12831.7510 - true_positives: 1223.3296 - val_binary_accuracy: 0.9521 - val_false_negatives: 75.0000 - val_false_positives: 65.0000 - val_loss: 1.2136 - val_true_negatives: 2541.0000 - val_true_positives: 241.0000\n",
      "EPOCH 23\n",
      "First training ID: ISIC_1380537\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1309s\u001b[0m 1s/step - binary_accuracy: 0.9656 - false_negatives: 15.6869 - false_positives: 431.5299 - loss: 0.0797 - true_negatives: 12773.7158 - true_positives: 1259.0321 - val_binary_accuracy: 0.9524 - val_false_negatives: 75.0000 - val_false_positives: 64.0000 - val_loss: 1.4072 - val_true_negatives: 2542.0000 - val_true_positives: 241.0000\n",
      "EPOCH 24\n",
      "First training ID: ISIC_2730614\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1301s\u001b[0m 1s/step - binary_accuracy: 0.9754 - false_negatives: 12.6504 - false_positives: 365.8883 - loss: 0.0597 - true_negatives: 12873.9316 - true_positives: 1227.4945 - val_binary_accuracy: 0.9538 - val_false_negatives: 75.0000 - val_false_positives: 60.0000 - val_loss: 1.3638 - val_true_negatives: 2546.0000 - val_true_positives: 241.0000\n",
      "EPOCH 25\n",
      "First training ID: ISIC_8103201\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1486s\u001b[0m 2s/step - binary_accuracy: 0.9686 - false_negatives: 16.8064 - false_positives: 432.6891 - loss: 0.0749 - true_negatives: 12810.0059 - true_positives: 1220.4635 - val_binary_accuracy: 0.9600 - val_false_negatives: 60.0000 - val_false_positives: 57.0000 - val_loss: 1.3415 - val_true_negatives: 2549.0000 - val_true_positives: 256.0000\n"
     ]
    }
   ],
   "source": [
    "#Run the model through epochs\n",
    "nb_epochs = 25\n",
    "early_break = True #End early in case of increasing validation loss\n",
    "\n",
    "for epoch in range(1, nb_epochs + 1):\n",
    "    #Make datasets\n",
    "    np.random.shuffle(train_ids_mods)\n",
    "    np.random.shuffle(val_ids_mods)\n",
    "    print(\"EPOCH\", epoch)\n",
    "    print(\"First training ID:\", train_ids_mods[0][0])\n",
    "    train_dataset, _ = make_dataset(hdf5_file, metadata, train_ids_mods, batch_size=train_batch_size, is_training=True)\n",
    "    validate_dataset, _ = make_dataset(hdf5_file, metadata, val_ids_mods, batch_size = val_batch_size, is_training=False)\n",
    "\n",
    "    mod = model.fit(train_dataset, epochs=1, steps_per_epoch = nb_training_batches, validation_data = validate_dataset, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\n",
    "                    class_weight={0: weight_for_0, 1: weight_for_1})\n",
    "    \n",
    "    #Save results\n",
    "    if epoch == 1:\n",
    "        results = mod.history\n",
    "    else:\n",
    "        for key in mod.history:   \n",
    "            results[key] += mod.history[key]\n",
    "\n",
    "    #Clean memory after use\n",
    "    del mod\n",
    "    del train_dataset\n",
    "    del validate_dataset\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    #Early termination (check after 15 epochs)\n",
    "    if epoch >= 15 and early_break == True:\n",
    "        #Calculate previous three changes, if positive, then loss is increasing\n",
    "        change1 = results[\"val_loss\"][-1] - results[\"val_loss\"][-2]\n",
    "        change2 = results[\"val_loss\"][-2] - results[\"val_loss\"][-3]\n",
    "        change3 = results[\"val_loss\"][-3] - results[\"val_loss\"][-4]\n",
    "\n",
    "        #Three consecutive increases in validation loss will stop the model\n",
    "        if change1 > 0 and change2 > 0 and change3 > 0:\n",
    "            break\n",
    "\n",
    "    #Save occasionally\n",
    "    #if (epoch % 25 == 0):\n",
    "    #    model.save(f\"XXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(5, 5, 3, 32), dtype=float32, path=hybrid_model/conv2d/kernel>,\n",
       " <KerasVariable shape=(32,), dtype=float32, path=hybrid_model/conv2d/bias>,\n",
       " <KerasVariable shape=(5, 5, 32, 64), dtype=float32, path=hybrid_model/conv2d_1/kernel>,\n",
       " <KerasVariable shape=(64,), dtype=float32, path=hybrid_model/conv2d_1/bias>,\n",
       " <KerasVariable shape=(33884, 36), dtype=float32, path=hybrid_model/dense/kernel>,\n",
       " <KerasVariable shape=(36,), dtype=float32, path=hybrid_model/dense/bias>,\n",
       " <KerasVariable shape=(36, 36), dtype=float32, path=hybrid_model/dense_1/kernel>,\n",
       " <KerasVariable shape=(36,), dtype=float32, path=hybrid_model/dense_1/bias>,\n",
       " <KerasVariable shape=(36, 1), dtype=float32, path=hybrid_model/dense_2/kernel>,\n",
       " <KerasVariable shape=(1,), dtype=float32, path=hybrid_model/dense_2/bias>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the training and validation losses\n",
    "\n",
    "#Convert loss results into a datafram\n",
    "result_preproc = pd.DataFrame({\n",
    "    'Epoch': [i+1 for i in range(len(results[\"loss\"]))], \n",
    "    'Train': results[\"loss\"],\n",
    "    'Validate': results[\"val_loss\"]\n",
    "    })\n",
    "\n",
    "# Convert dataframe from wide to long format\n",
    "df = pd.melt(result_preproc, ['Epoch'])\n",
    "\n",
    "#Make plot\n",
    "g = sns.lineplot(data=df, x='Epoch', y='value', hue='variable')\n",
    "g.set_title(\"Loss Curves\")\n",
    "g.legend_.set_title(\"Loss\")\n",
    "g.set_ylabel('Loss')\n",
    "g.set_ylim(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BATCHES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Iterate through all batches in the dataset and print their shapes\\nfor i, batch in enumerate(train_dataset):\\n    (img_batch, meta_batch), target_batch = batch\\n    \\n    # Print the shapes of the current batch\\n    print(f\"Batch {i+1}:\")\\n    print(\"  Image Batch Shape:\", img_batch.shape)\\n    print(\"  Metadata Batch Shape:\", meta_batch.shape)\\n    print(\"  Target Batch Shape:\", target_batch.shape)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Iterate through all batches in the dataset and print their shapes\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the current batch\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"  Image Batch Shape:\", img_batch.shape)\n",
    "    print(\"  Metadata Batch Shape:\", meta_batch.shape)\n",
    "    print(\"  Target Batch Shape:\", target_batch.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9860/9860\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 65ms/step\n",
      "Shape of prediction data: (9860, 1)\n"
     ]
    }
   ],
   "source": [
    "#Retrieve test predictions and real test values\n",
    "predictions = model.predict(test_dataset, steps = nb_test_batches)\n",
    "y_pred = np.array([round(i) for i  in predictions.flatten()])\n",
    "y_test = np.concatenate([y for x, y in test_dataset], axis=0).flatten()\n",
    "print(\"Shape of prediction data:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the loss\n",
    "loss = sum(abs(y_test - y_pred))/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine true/false positives and negatives\n",
    "pos_indices = y_test == 1\n",
    "neg_indices = y_test == 0\n",
    "\n",
    "#True positives\n",
    "true_pos = sum(abs(y_test[pos_indices] == y_pred[pos_indices]))\n",
    "\n",
    "#False negatives\n",
    "false_neg = sum(abs(y_test[pos_indices] != y_pred[pos_indices]))\n",
    "\n",
    "#True negatives\n",
    "true_neg = sum(abs(y_test[neg_indices] == y_pred[neg_indices]))\n",
    "\n",
    "#False positives\n",
    "false_pos = sum(abs(y_test[neg_indices] != y_pred[neg_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---TEST RESULTS---\n",
      "Loss on test data: 0.01612576064908722\n",
      "True positives: 0\n",
      "False positives: 151\n",
      "True negatives: 9701\n",
      "False negatives: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"---TEST RESULTS---\")\n",
    "print(\"Loss on test data:\", loss)\n",
    "print(\"True positives:\", true_pos)\n",
    "print(\"False positives:\", false_pos)\n",
    "print(\"True negatives:\", true_neg)\n",
    "print(\"False negatives:\", false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

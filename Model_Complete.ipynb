{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 20:02:50.066977: I tensorflow/core/platform/cpu_feature_guard.cc:181] Beginning TensorFlow 2.15, this package will be updated to install stock TensorFlow 2.15 alongside Intel's TensorFlow CPU extension plugin, which provides all the optimizations available in the package and more. If a compatible version of stock TensorFlow is present, only the extension will get installed. No changes to code or installation setup is needed as a result of this change.\n",
      "More information on Intel's optimizations for TensorFlow, delivered as TensorFlow extension plugin can be viewed at https://github.com/intel/intel-extension-for-tensorflow.\n",
      "2024-09-23 20:02:50.067028: I tensorflow/core/platform/cpu_feature_guard.cc:192] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import gc\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Declare file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "#metaPath = dataPath + \"train-metadata.csv\"\n",
    "metaPath = dataPath + \"sample-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "#hdf5_file = dataPath + \"train-image.hdf5\"\n",
    "hdf5_file = dataPath + \"sample-image.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_path = \"C:/Users/admin/Documents/DSTI/DeepLearning/Project/Computer_Vision/isic-2024-challenge\"\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "#hdf5_file = os.path.join(base_path, \"sampleclaire-image.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Load metadata from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                         0\n",
      "age_approx                     34\n",
      "target                          0\n",
      "clin_size_long_diam_mm          0\n",
      "tbp_lv_areaMM2                  0\n",
      "tbp_lv_area_perim_ratio         0\n",
      "tbp_lv_eccentricity             0\n",
      "tbp_lv_minorAxisMM              0\n",
      "tbp_lv_color_std_mean           0\n",
      "tbp_lv_deltaLBnorm              0\n",
      "tbp_lv_radial_color_std_max     0\n",
      "tbp_lv_location                 0\n",
      "dtype: int64\n",
      "Number of unknown for tbp_lv_location 77\n"
     ]
    }
   ],
   "source": [
    "#METADATA: color and size features having no NAs\n",
    "metadata = metadata[[\"isic_id\",\n",
    "                     \"age_approx\",\n",
    "                     \"target\",\n",
    "                     \"clin_size_long_diam_mm\",\n",
    "                     \"tbp_lv_areaMM2\",\n",
    "                     \"tbp_lv_area_perim_ratio\",\n",
    "                     \"tbp_lv_eccentricity\",\n",
    "                     \"tbp_lv_minorAxisMM\",\n",
    "                     \"tbp_lv_color_std_mean\",\n",
    "                     \"tbp_lv_deltaLBnorm\",\n",
    "                     \"tbp_lv_radial_color_std_max\",\n",
    "                     \"tbp_lv_location\"]]\n",
    "\n",
    "\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())\n",
    "\n",
    "#Check number of Unknoxn for tbp_lv_location\n",
    "loc_unknown=metadata[metadata[\"tbp_lv_location\"]==\"Unknown\"]\n",
    "print(\"Number of unknown for tbp_lv_location\", len(loc_unknown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Activate for debugging of the predict function\n",
    "#metadata[\"target_cheat\"] = metadata[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown for tbp_lv_location 0\n"
     ]
    }
   ],
   "source": [
    "metadata=metadata[metadata[\"tbp_lv_location\"]!=\"Unknown\"]\n",
    "\n",
    "loc_unknown2=metadata[metadata[\"tbp_lv_location\"]==\"Unknown\"]\n",
    "print(\"Number of unknown for tbp_lv_location\", len(loc_unknown2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['isic_id', 'age_approx', 'target', 'clin_size_long_diam_mm',\n",
      "       'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_eccentricity',\n",
      "       'tbp_lv_minorAxisMM', 'tbp_lv_color_std_mean', 'tbp_lv_deltaLBnorm',\n",
      "       'tbp_lv_radial_color_std_max', 'category_Head & Neck',\n",
      "       'category_Left Arm', 'category_Left Arm - Lower',\n",
      "       'category_Left Arm - Upper', 'category_Left Leg',\n",
      "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
      "       'category_Right Arm', 'category_Right Arm - Lower',\n",
      "       'category_Right Arm - Upper', 'category_Right Leg',\n",
      "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
      "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
      "       'category_Torso Back Top Third', 'category_Torso Front Bottom Half',\n",
      "       'category_Torso Front Top Half'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Apply One-hot encoding for location\n",
    "location=pd.get_dummies(metadata[\"tbp_lv_location\"],prefix='category')\n",
    "location = location.astype(int)\n",
    "metadata = pd.concat([metadata, location], axis=1)\n",
    "metadata=metadata.drop(\"tbp_lv_location\",axis=1)\n",
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                             0\n",
      "age_approx                          0\n",
      "target                              0\n",
      "clin_size_long_diam_mm              0\n",
      "tbp_lv_areaMM2                      0\n",
      "tbp_lv_area_perim_ratio             0\n",
      "tbp_lv_eccentricity                 0\n",
      "tbp_lv_minorAxisMM                  0\n",
      "tbp_lv_color_std_mean               0\n",
      "tbp_lv_deltaLBnorm                  0\n",
      "tbp_lv_radial_color_std_max         0\n",
      "category_Head & Neck                0\n",
      "category_Left Arm                   0\n",
      "category_Left Arm - Lower           0\n",
      "category_Left Arm - Upper           0\n",
      "category_Left Leg                   0\n",
      "category_Left Leg - Lower           0\n",
      "category_Left Leg - Upper           0\n",
      "category_Right Arm                  0\n",
      "category_Right Arm - Lower          0\n",
      "category_Right Arm - Upper          0\n",
      "category_Right Leg                  0\n",
      "category_Right Leg - Lower          0\n",
      "category_Right Leg - Upper          0\n",
      "category_Torso Back Bottom Third    0\n",
      "category_Torso Back Middle Third    0\n",
      "category_Torso Back Top Third       0\n",
      "category_Torso Front Bottom Half    0\n",
      "category_Torso Front Top Half       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of age_approx for each target group\n",
    "mean_age_malign = metadata.loc[metadata[\"target\"] == 1, \"age_approx\"].mean()\n",
    "mean_age_benign = metadata.loc[metadata[\"target\"] == 0, \"age_approx\"].mean()\n",
    "\n",
    "# Define a function to fill NA based on the target value\n",
    "def fill_na_by_target(row):\n",
    "    if pd.isna(row['age_approx']):\n",
    "        if row['target'] == 1:\n",
    "            return mean_age_malign\n",
    "        elif row['target'] == 0:\n",
    "            return mean_age_benign\n",
    "    return row['age_approx']\n",
    "\n",
    "# Apply the function to the age_approx column\n",
    "metadata['age_approx'] = metadata.apply(fill_na_by_target, axis=1)\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#from sklearn.preprocessing import StandardScaler\\nfrom sklearn.preprocessing import MinMaxScaler\\n#Normalization\\n#Select the column\\nfeature=metadata.drop(columns=['isic_id','target'])\\n\\n#scaler=StandardScaler() for standardization\\nscaler = MinMaxScaler()\\nfeature_standardized=scaler.fit_transform(feature)\\nfeature_standardized_df = pd.DataFrame(feature_standardized, columns=feature.columns)\\n\\nmetadata=pd.concat([metadata[['isic_id','target']].reset_index(drop=True), feature_standardized_df] , axis=1)\\nprint(len(metadata.columns))\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Normalization\n",
    "#Select the column\n",
    "feature=metadata.drop(columns=['isic_id','target'])\n",
    "\n",
    "#scaler=StandardScaler() for standardization\n",
    "scaler = MinMaxScaler()\n",
    "feature_standardized=scaler.fit_transform(feature)\n",
    "feature_standardized_df = pd.DataFrame(feature_standardized, columns=feature.columns)\n",
    "\n",
    "metadata=pd.concat([metadata[['isic_id','target']].reset_index(drop=True), feature_standardized_df] , axis=1)\n",
    "print(len(metadata.columns))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Normalization\n",
    "#Select the column\n",
    "'''\n",
    "feature=metadata.drop(columns=['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third','category_Torso Front',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half'])\n",
    "'''\n",
    "#Select the column\n",
    "feature=metadata.drop(columns=['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half'])\n",
    "#scaler=StandardScaler() for standardization\n",
    "scaler = MinMaxScaler()\n",
    "feature_standardized=scaler.fit_transform(feature)\n",
    "feature_standardized_df = pd.DataFrame(feature_standardized, columns=feature.columns)\n",
    "\n",
    "'''\n",
    "metadata=pd.concat([metadata[['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third', 'category_Torso Front',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half']].reset_index(drop=True), feature_standardized_df] , axis=1)\n",
    "'''\n",
    "\n",
    "metadata=pd.concat([metadata[['isic_id','target', 'category_Head & Neck',\n",
    "       'category_Left Arm', 'category_Left Arm - Lower',\n",
    "       'category_Left Arm - Upper', 'category_Left Leg',\n",
    "       'category_Left Leg - Lower', 'category_Left Leg - Upper',\n",
    "       'category_Right Arm', 'category_Right Arm - Lower',\n",
    "       'category_Right Arm - Upper', 'category_Right Leg',\n",
    "       'category_Right Leg - Lower', 'category_Right Leg - Upper',\n",
    "       'category_Torso Back Bottom Third', 'category_Torso Back Middle Third',\n",
    "       'category_Torso Back Top Third',\n",
    "       'category_Torso Front Bottom Half', 'category_Torso Front Top Half']].reset_index(drop=True), feature_standardized_df] , axis=1)\n",
    "print(len(metadata.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4a - Train, Validate, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_if_needed(obj):\n",
    "    if isinstance(obj, pd.Series):\n",
    "        return obj.tolist()\n",
    "    return obj\n",
    "\n",
    "#Function to perform train-validate or train-test-validate split on a list of isic_ids\n",
    "def ttv_split(isic_ids, test_frac=0.2, validate_frac=0.2, random_state=88, shuffle=True, stratify=None):\n",
    "    if test_frac < 0 or validate_frac < 0:\n",
    "        print(\"ERROR: Test of validate fraction is negative\")\n",
    "        return None\n",
    "    if test_frac > 1 or validate_frac > 1:\n",
    "        print(\"ERROR: Test of validate fraction is above 0\")\n",
    "        return None\n",
    "    if test_frac + validate_frac >= 1:\n",
    "        print(\"ERROR: Test and validate fractions sum to 1 or more.\")\n",
    "        return None\n",
    "\n",
    "    #Split training from the rest\n",
    "    test_size = test_frac + validate_frac\n",
    "    train, temp = train_test_split(isic_ids, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "    #Split test and validate\n",
    "    if test_frac == 0 or validate_frac == 0:\n",
    "       # return train.tolist(), temp.tolist()\n",
    "        return list_if_needed(train), list_if_needed(temp)\n",
    "    else:\n",
    "        test_size = test_frac / (test_frac + validate_frac)\n",
    "        test, validate = train_test_split(temp, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "        #return train.tolist(), test.tolist(), validate.tolist()\n",
    "        return list_if_needed(train), list_if_needed(test), list_if_needed(validate)\n",
    "\n",
    "#Generate the splits of the isic_ids\n",
    "#train_ids, test_ids, val_ids = ttv_split(metadata[\"isic_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep 10% of isic_Id of target=1 without duplication\n",
    "isic_id_val_target_1 = metadata[metadata['target'] == 1]['isic_id'].tolist()\n",
    "n=int(0.1*len(isic_id_val_target_1))\n",
    "isic_ids_keep_train = np.random.choice(isic_id_val_target_1, n , replace=False)\n",
    "\n",
    "\n",
    "# Split to isolate the test set\n",
    "isic_ids = metadata.loc[~metadata[\"isic_id\"].isin(isic_ids_keep_train), 'isic_id']\n",
    "train_val_ids, test_ids= ttv_split(isic_ids, test_frac=0.2, validate_frac=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1039\n"
     ]
    }
   ],
   "source": [
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4b - Data augmentation\n",
    "- Augment only the malignant data in the training set\n",
    "- Reformat all lists (train_ids, test_ids, val_ids) to be compatible: list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make list of ids compatible with data augmentations\n",
    "#Base data takes a value of 0, meaning it should not be modified\n",
    "train_val_ids_mods = [(id, 0) for id in train_val_ids]\n",
    "test_ids_mods = [(id, 0) for id in test_ids]\n",
    "#train_ids_mods = [(id, 0) for id in train_ids]\n",
    "#val_ids_mods = [(id, 0) for id in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives in training data: 209\n"
     ]
    }
   ],
   "source": [
    "#Identify the malignant cases in the training data\n",
    "#all_pos = metadata[metadata[\"target\"]==1][\"isic_id\"]\n",
    "all_pos = metadata.loc[(metadata[\"target\"] == 1) & (~metadata[\"isic_id\"].isin(isic_ids_keep_train)), 'isic_id']\n",
    "pos_in_train_val = all_pos[all_pos.isin(train_val_ids)]\n",
    "print(\"Number of positives in training data:\", len(pos_in_train_val))\n",
    "#pos_in_train = all_pos[all_pos.isin(train_ids)]\n",
    "#print(\"Number of positives in training data:\", len(pos_in_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5223\n"
     ]
    }
   ],
   "source": [
    "print(len(metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4154\n"
     ]
    }
   ],
   "source": [
    "print(len(train_val_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4154\n"
     ]
    }
   ],
   "source": [
    "print(len(train_val_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8334\n"
     ]
    }
   ],
   "source": [
    "# Apply augmentations only to training and validation sets before splitting them\n",
    "#Duplicates of ids will each have a different number, indicating a specific augmentation to be used\n",
    "nb_of_augments = 50 #apply 500 with the all dataset\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "for i in range(nb_of_augments):\n",
    "    rand_nb = rng.random()\n",
    "    #Option 1: use random float between 0 and 1\n",
    "    #train_ids_mods += [(id, rand_nb) for id in pos_in_train_val]\n",
    "    #Option 2: use integer\n",
    "    train_val_ids_mods += [(id, i + 1) for id in pos_in_train_val]\n",
    "\n",
    "#Shuffle the list\n",
    "np.random.shuffle(train_val_ids_mods)\n",
    "print(len(train_val_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids_mods, val_ids_mods= ttv_split(train_val_ids_mods, test_frac=0.0, validate_frac=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5583\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2751\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply duplication on reserved validation data (target 1) \n",
    "\n",
    "nb_of_augments = 25 #apply 25 with the all dataset\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "isic_ids_keep_train_mods=[]\n",
    "for i in range(nb_of_augments):\n",
    "    rand_nb = rng.random()\n",
    "    #Option 1: use random float between 0 and 1\n",
    "    #train_ids_mods += [(id, rand_nb) for id in pos_in_train_val]\n",
    "    #Option 2: use integer\n",
    "    isic_ids_keep_train_mods += [(id, i + 1) for id in isic_ids_keep_train]\n",
    "\n",
    "\n",
    "\n",
    "#val_size = int(0.5 * len(val_ids_mods))\n",
    "#random_sample = random.sample(val_ids_mods, val_size)\n",
    "\n",
    "#Shuffle the list\n",
    "val_ids_mods=isic_ids_keep_train_mods + val_ids_mods\n",
    "np.random.shuffle(val_ids_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3501\n"
     ]
    }
   ],
   "source": [
    "print(len(val_ids_mods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Load images and create hybrid tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hair_removal(image, crop_pixels=10):\n",
    "    height_pixels = len(image)  # Image rows\n",
    "    width_pixels = len(image[0])  # Image columns\n",
    "\n",
    "    # Image cropping\n",
    "    height = [crop_pixels, height_pixels - crop_pixels]\n",
    "    width = [crop_pixels, width_pixels - crop_pixels]\n",
    "    img = image[height[0]:height[1], width[0]:width[1]]\n",
    "\n",
    "    # Gray scale\n",
    "    grayScale = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Black hat filter\n",
    "    kernel = cv2.getStructuringElement(1, (9, 9))\n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "    # Gaussian filter\n",
    "    bhg = cv2.GaussianBlur(blackhat, (3, 3), cv2.BORDER_DEFAULT)\n",
    "    # Binary thresholding (MASK)\n",
    "    ret, mask = cv2.threshold(bhg, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Replace pixels of the mask\n",
    "    dst = cv2.inpaint(img, mask, 6, cv2.INPAINT_TELEA)\n",
    "\n",
    "    return dst\n",
    "\n",
    "#def resize_image(image, target_size=(100, 100)):\n",
    "#    resized_image = cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "#    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentation function\n",
    "def augment_image(image):\n",
    "    \"\"\"\n",
    "    Apply a series of augmentations to create diverse variations of the input image.\n",
    "    Includes random flips, rotations, brightness adjustments, and other transformations.\n",
    "    \"\"\"\n",
    "    # Apply various augmentations\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.rot90(image, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(metadata, img_names):\n",
    "    # Initialize counters for target=0 and target=1\n",
    "    target_0_count = 0\n",
    "    target_1_count = 0\n",
    "\n",
    "    # Loop through each tuple in img_names (img_name, transformation)\n",
    "    for img_name, mod in img_names:\n",
    "        # Filter metadata to find the corresponding isic_id\n",
    "        metadata_filtered = metadata[metadata[\"isic_id\"] == img_name]\n",
    "\n",
    "        if not metadata_filtered.empty:\n",
    "            # Retrieve the target value for the corresponding isic_id\n",
    "            target = metadata_filtered[\"target\"].values[0]\n",
    "\n",
    "            # Increment the counter based on the target value\n",
    "            if target == 0:\n",
    "                target_0_count += 1\n",
    "            elif target == 1:\n",
    "                target_1_count += 1\n",
    "\n",
    "    # Calculate total number of images\n",
    "    total = target_0_count + target_1_count\n",
    "\n",
    "    # Calculate class weights based on the counts, avoid division by zero\n",
    "    if target_0_count > 0:\n",
    "        weight_for_0 = total / (2 * target_0_count)\n",
    "    else:\n",
    "        weight_for_0 = 1\n",
    "\n",
    "    if target_1_count > 0:\n",
    "        weight_for_1 = total / (2 * target_1_count)\n",
    "    else:\n",
    "        weight_for_1 = 1\n",
    "\n",
    "    return weight_for_0, weight_for_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATOR FOR HDF5 AND METADATA\n",
    "\"\"\"\n",
    "file = filepath to the hdf5 file containing the image data\n",
    "metadata = the full metadata dataframe (col1 = \"isic_id\", col2 = \"target\")\n",
    "img_names = list of tuples, each containing the isic_id followed by a number, signifying:\n",
    "            * 0 when original data is to be used\n",
    "            * random number - data augmentation is to be applied\n",
    "imgSize = images are to be adjusted to this size (square) in pixels\n",
    "\"\"\"\n",
    "class hdf5_generator:\n",
    "    def __init__(self, file, metadata, img_names, imgSize,is_training=False):\n",
    "        self.file = file\n",
    "        self.metadata = metadata\n",
    "        self.img_names = img_names\n",
    "        self.imgSize = imgSize\n",
    "        self.is_training=is_training\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as h5file:\n",
    "            for img_name_tuple in self.img_names:\n",
    "                img_name, mod = img_name_tuple\n",
    "                try:\n",
    "                    # Load image data from HDF5\n",
    "                    img = np.array(Image.open(io.BytesIO(h5file[img_name][()])))\n",
    "                    \n",
    "                    # Clean image\n",
    "                    img = hair_removal(img)\n",
    "\n",
    "                    \n",
    "                    #if mod != 0:\n",
    "                    if self.is_training==True:\n",
    "                        # Data Augmentation \n",
    "                        img= augment_image(img)\n",
    "                    else:\n",
    "                        img=img\n",
    "                        \n",
    "                    # Resize the image\n",
    "                    img = tf.image.resize(img, [self.imgSize, self.imgSize])\n",
    "\n",
    "                    # Standardize and return as TensorFlow constant\n",
    "                    img = tf.constant(img / 255, dtype=tf.float32)  # Standardize here\n",
    "\n",
    "                    #Retrieve corresponding metadata\n",
    "                    meta = self.metadata[self.metadata[\"isic_id\"] == img_name].iloc[:,2:]\n",
    "\n",
    "                    #Retrieve corresponding target\n",
    "                    target = self.metadata[self.metadata[\"isic_id\"] == img_name][\"target\"]\n",
    "                    target = np.reshape(target, (1, 1))\n",
    "                    \n",
    "                    yield (img, meta), target\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_name}: {e}\")\n",
    "                    # log the error to a file for later analysis\n",
    "                    with open('image_errors.log', 'a') as f:\n",
    "                        f.write(f\"Error loading image {img_name}: {e}\\n\")\n",
    "                    continue\n",
    "\n",
    "#Generate the dataset with batch size and prefetching\n",
    "def make_dataset(hdf5_file, metadata, img_names, imgSize=100, batch_size=32, shuffle=True, is_training=False):\n",
    "    if is_training:\n",
    "        #Get number of picture for each target\n",
    "        weight_for_0, weight_for_1 = compute_class_weights(metadata, img_names)\n",
    "        #print(f\"Class weight for target=0: {weight_for_0}\")\n",
    "        #print(f\"Class weight for target=1: {weight_for_1}\")\n",
    "    else:\n",
    "        weight_for_0, weight_for_1 = None, None\n",
    "        \n",
    "    # Get the number of metadata features (isic_id and target are present, so subtract)\n",
    "    num_features = metadata.shape[-1] - 2\n",
    "    \n",
    "    # Generate image dataset\n",
    "    element_spec = ((tf.TensorSpec(shape=(imgSize, imgSize, 3), dtype=tf.float32),\n",
    "                 tf.TensorSpec(shape=(1, num_features), dtype=tf.float32)),\n",
    "                tf.TensorSpec(shape=(1, 1), dtype=tf.int32))\n",
    "    \n",
    "    img_dataset = tf.data.Dataset.from_generator(\n",
    "        hdf5_generator(hdf5_file, metadata, img_names, imgSize, is_training),\n",
    "        output_signature=element_spec\n",
    "    )\n",
    "\n",
    "    # Add shuffling, batching, and prefetching\n",
    "    dataset = img_dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset, (weight_for_0, weight_for_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'leaky_relu', img_size = 100, img_channels=3):\n",
    "        #Run the constructor of the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "        \n",
    "        #Image size declaration\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "        #Layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(img_size, img_size, img_channels),\n",
    "                                            kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image, x_meta = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Metadata Neural Network\n",
    "class Meta_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        #Run the constructor of the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "        #Layers\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dropout = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        x_all = tf.reshape(x_meta, (tf.shape(x_meta)[0], x_meta.shape[-1]))\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        x_all = self.dense2(x_all)\n",
    "        if training:\n",
    "            x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'leaky_relu', img_size = 100, img_channels = 3):\n",
    "        #Run the constructor of the parent class\n",
    "        super().__init__()\n",
    "\n",
    "        #Weight and bias initializers\n",
    "        kernel_initializer = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "        bias_initializer = tf.keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "\n",
    "        #Image size declaration\n",
    "        self.img_size = img_size\n",
    "        self.img_channels = img_channels\n",
    "\n",
    "        #Layers\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(img_size, img_size, img_channels),\n",
    "                                            kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 5, activation='relu', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.10)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.10)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=kernel_initializer, bias_initializer=bias_initializer)\n",
    "        self.concatenate = keras.layers.Concatenate(axis=1)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x = self.conv1(x_image)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x = self.flatten(x)\n",
    "        # Reshape metadata to match dimensions\n",
    "        x_meta = tf.reshape(x_meta, (tf.shape(x_meta)[0], x_meta.shape[-1]))\n",
    "        x_all = self.concatenate([x, x_meta])\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        if training:\n",
    "            x_all = self.dropout1(x_all, training=training)\n",
    "        x_all = self.dense2(x_all)\n",
    "        if training:\n",
    "            x_all = self.dropout2(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 20:02:52.290631: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "#model = CNN_model(neurons=8, activ='tanh')\n",
    "model = Hybrid_model(neurons=36, activ='leaky_relu')\n",
    "#model = Meta_model(neurons=18, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Take 1 batch from the dataset and check its content\\nfor batch in train_dataset.take(1):\\n    (img_batch, meta_batch), target_batch = batch\\n    \\n    # Print the shapes of the individual components\\n    print(f\"Image batch shape: {img_batch.shape}\")\\n    print(f\"Metadata batch shape: {meta_batch.shape}\")\\n    print(f\"Target batch shape: {target_batch.shape}\")\\n\\n# To count the total number of batches\\nbatch_count = 0\\nfor _ in train_dataset:\\n    batch_count += 1\\n\\nprint(f\"Total number of batches in the dataset: {batch_count}\")\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Take 1 batch from the dataset and check its content\n",
    "for batch in train_dataset.take(1):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the individual components\n",
    "    print(f\"Image batch shape: {img_batch.shape}\")\n",
    "    print(f\"Metadata batch shape: {meta_batch.shape}\")\n",
    "    print(f\"Target batch shape: {target_batch.shape}\")\n",
    "\n",
    "# To count the total number of batches\n",
    "batch_count = 0\n",
    "for _ in train_dataset:\n",
    "    batch_count += 1\n",
    "\n",
    "print(f\"Total number of batches in the dataset: {batch_count}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clear the memory leak in Keras\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "    #print(f\"Epoch {epoch+1} finished. Validation loss: {logs['val_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training batches in dataset: 174\n",
      "Total validate batches in dataset: 3501\n",
      "Total test batches in dataset: 3501\n"
     ]
    }
   ],
   "source": [
    "#Set batch sizes\n",
    "train_batch_size = 32\n",
    "val_batch_size = 1\n",
    "test_batch_size = 1\n",
    "\n",
    "#Determine the number of batches\n",
    "nb_training_batches = int(len(train_ids_mods)//train_batch_size)\n",
    "nb_validate_batches = int(len(val_ids_mods)//val_batch_size)\n",
    "nb_test_batches = int(len(val_ids_mods)//test_batch_size)\n",
    "\n",
    "#Print results\n",
    "print(\"Total training batches in dataset:\", nb_training_batches)\n",
    "print(\"Total validate batches in dataset:\", nb_validate_batches)\n",
    "print(\"Total test batches in dataset:\", nb_test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Create datasets and get weights\n",
    "train_dataset, class_weights = make_dataset(hdf5_file, metadata, train_ids_mods, batch_size=train_batch_size, is_training=True)\n",
    "weight_for_0, weight_for_1 = class_weights\n",
    "validate_dataset, _ = make_dataset(hdf5_file, metadata, val_ids_mods, batch_size = val_batch_size, is_training=False)\n",
    "test_dataset, _ = make_dataset(hdf5_file, metadata, test_ids_mods, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training ID: ISIC_5506776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n",
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174/174 [==============================] - 342s 2s/step - loss: 0.7019 - binary_accuracy: 0.6252 - false_negatives: 1239.0000 - false_positives: 848.0000 - true_negatives: 1777.0000 - true_positives: 1704.0000 - val_loss: 0.5623 - val_binary_accuracy: 0.7107 - val_false_negatives: 704.0000 - val_false_positives: 309.0000 - val_true_negatives: 1007.0000 - val_true_positives: 1481.0000\n",
      "First training ID: ISIC_8215425\n",
      "174/174 [==============================] - 345s 2s/step - loss: 0.5446 - binary_accuracy: 0.7292 - false_negatives: 1029.0000 - false_positives: 479.0000 - true_negatives: 2142.0000 - true_positives: 1918.0000 - val_loss: 0.5111 - val_binary_accuracy: 0.7286 - val_false_negatives: 746.0000 - val_false_positives: 204.0000 - val_true_negatives: 1112.0000 - val_true_positives: 1439.0000\n",
      "First training ID: ISIC_9709310\n",
      "174/174 [==============================] - 394s 2s/step - loss: 0.4778 - binary_accuracy: 0.7870 - false_negatives: 689.0000 - false_positives: 497.0000 - true_negatives: 2122.0000 - true_positives: 2260.0000 - val_loss: 0.4318 - val_binary_accuracy: 0.8189 - val_false_negatives: 390.0000 - val_false_positives: 244.0000 - val_true_negatives: 1072.0000 - val_true_positives: 1795.0000\n",
      "First training ID: ISIC_4692259\n",
      "174/174 [==============================] - 382s 2s/step - loss: 0.4334 - binary_accuracy: 0.8105 - false_negatives: 576.0000 - false_positives: 479.0000 - true_negatives: 2143.0000 - true_positives: 2370.0000 - val_loss: 0.4227 - val_binary_accuracy: 0.8280 - val_false_negatives: 380.0000 - val_false_positives: 222.0000 - val_true_negatives: 1094.0000 - val_true_positives: 1805.0000\n",
      "First training ID: ISIC_8702816\n",
      "150/174 [========================>.....] - ETA: 1:01 - loss: 0.4170 - binary_accuracy: 0.8144 - false_negatives: 492.0000 - false_positives: 399.0000 - true_negatives: 1883.0000 - true_positives: 2026.0000"
     ]
    }
   ],
   "source": [
    "#Run the model through epochs\n",
    "for epoch in range(25):\n",
    "    #Make datasets\n",
    "    #np.random.seed(87 + i)\n",
    "    np.random.shuffle(train_ids_mods)\n",
    "    print(\"First training ID:\", train_ids_mods[0][0])\n",
    "    train_dataset, _ = make_dataset(hdf5_file, metadata, train_ids_mods, batch_size=train_batch_size, is_training=True)\n",
    "    validate_dataset, _ = make_dataset(hdf5_file, metadata, val_ids_mods, batch_size = val_batch_size, is_training=False)\n",
    "\n",
    "    mod = model.fit(train_dataset, epochs=1, steps_per_epoch = nb_training_batches, validation_data = validate_dataset, validation_steps = nb_validate_batches, callbacks = [CustomCallback()],\n",
    "                    class_weight={0: weight_for_0, 1: weight_for_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "     46/Unknown \u001b[1m49s\u001b[0m 926ms/step - binary_accuracy: 0.5159 - false_negatives: 112.7609 - false_positives: 228.1739 - loss: 1.0996 - true_negatives: 323.1304 - true_positives: 87.7826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\env_DL_python3119\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 1s/step - binary_accuracy: 0.5161 - false_negatives: 114.9787 - false_positives: 233.4894 - loss: 1.0937 - true_negatives: 328.8723 - true_positives: 89.6809 - val_binary_accuracy: 0.3506 - val_false_negatives: 0.0000e+00 - val_false_positives: 502.0000 - val_loss: 0.6986 - val_true_negatives: 3.0000 - val_true_positives: 268.0000\n",
      "Epoch 2/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step - binary_accuracy: 0.3494 - false_negatives: 18.3830 - false_positives: 449.4043 - loss: 0.6916 - true_negatives: 112.9574 - true_positives: 186.2766 - val_binary_accuracy: 0.7827 - val_false_negatives: 139.0000 - val_false_positives: 29.0000 - val_loss: 0.6565 - val_true_negatives: 476.0000 - val_true_positives: 129.0000\n",
      "Epoch 3/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 1s/step - binary_accuracy: 0.7507 - false_negatives: 88.0000 - false_positives: 91.4894 - loss: 1.7777 - true_negatives: 470.8723 - true_positives: 116.6596 - val_binary_accuracy: 0.7930 - val_false_negatives: 86.0000 - val_false_positives: 74.0000 - val_loss: 0.4986 - val_true_negatives: 431.0000 - val_true_positives: 182.0000\n",
      "Epoch 4/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - binary_accuracy: 0.8237 - false_negatives: 36.5106 - false_positives: 99.7447 - loss: 0.4167 - true_negatives: 462.6170 - true_positives: 168.1489 - val_binary_accuracy: 0.8448 - val_false_negatives: 43.0000 - val_false_positives: 77.0000 - val_loss: 0.4608 - val_true_negatives: 428.0000 - val_true_positives: 225.0000\n",
      "Epoch 5/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 1s/step - binary_accuracy: 0.8482 - false_negatives: 19.4468 - false_positives: 96.6809 - loss: 0.3509 - true_negatives: 465.6808 - true_positives: 185.2128 - val_binary_accuracy: 0.8603 - val_false_negatives: 43.0000 - val_false_positives: 65.0000 - val_loss: 0.4414 - val_true_negatives: 440.0000 - val_true_positives: 225.0000\n",
      "Epoch 6/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 1s/step - binary_accuracy: 0.8675 - false_negatives: 17.8298 - false_positives: 87.0426 - loss: 0.3151 - true_negatives: 475.3192 - true_positives: 186.8298 - val_binary_accuracy: 0.8784 - val_false_negatives: 43.0000 - val_false_positives: 51.0000 - val_loss: 0.4188 - val_true_negatives: 454.0000 - val_true_positives: 225.0000\n",
      "Epoch 7/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - binary_accuracy: 0.9077 - false_negatives: 9.5532 - false_positives: 62.6383 - loss: 0.2698 - true_negatives: 499.7234 - true_positives: 195.1064 - val_binary_accuracy: 0.8887 - val_false_negatives: 43.0000 - val_false_positives: 43.0000 - val_loss: 0.4192 - val_true_negatives: 462.0000 - val_true_positives: 225.0000\n",
      "Epoch 8/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 1s/step - binary_accuracy: 0.9097 - false_negatives: 9.2553 - false_positives: 60.4255 - loss: 0.2369 - true_negatives: 501.9362 - true_positives: 195.4043 - val_binary_accuracy: 0.9017 - val_false_negatives: 25.0000 - val_false_positives: 51.0000 - val_loss: 0.4263 - val_true_negatives: 454.0000 - val_true_positives: 243.0000\n",
      "Epoch 9/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - binary_accuracy: 0.9206 - false_negatives: 7.2766 - false_positives: 51.8723 - loss: 0.2081 - true_negatives: 510.4893 - true_positives: 197.3830 - val_binary_accuracy: 0.9146 - val_false_negatives: 25.0000 - val_false_positives: 41.0000 - val_loss: 0.4309 - val_true_negatives: 464.0000 - val_true_positives: 243.0000\n",
      "Epoch 10/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - binary_accuracy: 0.9376 - false_negatives: 3.6809 - false_positives: 44.7872 - loss: 0.1860 - true_negatives: 517.5745 - true_positives: 200.9787 - val_binary_accuracy: 0.9185 - val_false_negatives: 25.0000 - val_false_positives: 38.0000 - val_loss: 0.4459 - val_true_negatives: 467.0000 - val_true_positives: 243.0000\n",
      "Epoch 11/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 1s/step - binary_accuracy: 0.9453 - false_negatives: 6.0638 - false_positives: 39.1064 - loss: 0.1742 - true_negatives: 523.2553 - true_positives: 198.5957 - val_binary_accuracy: 0.9198 - val_false_negatives: 25.0000 - val_false_positives: 37.0000 - val_loss: 0.4560 - val_true_negatives: 468.0000 - val_true_positives: 243.0000\n",
      "Epoch 12/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - binary_accuracy: 0.9488 - false_negatives: 4.8298 - false_positives: 36.9362 - loss: 0.1621 - true_negatives: 525.4255 - true_positives: 199.8298 - val_binary_accuracy: 0.9133 - val_false_negatives: 25.0000 - val_false_positives: 42.0000 - val_loss: 0.4594 - val_true_negatives: 463.0000 - val_true_positives: 243.0000\n",
      "Epoch 13/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - binary_accuracy: 0.9510 - false_negatives: 4.5957 - false_positives: 35.1064 - loss: 0.1473 - true_negatives: 527.2553 - true_positives: 200.0638 - val_binary_accuracy: 0.9237 - val_false_negatives: 25.0000 - val_false_positives: 34.0000 - val_loss: 0.4720 - val_true_negatives: 471.0000 - val_true_positives: 243.0000\n",
      "Epoch 14/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - binary_accuracy: 0.9453 - false_negatives: 3.6170 - false_positives: 37.9787 - loss: 0.1441 - true_negatives: 524.3830 - true_positives: 201.0426 - val_binary_accuracy: 0.9250 - val_false_negatives: 25.0000 - val_false_positives: 33.0000 - val_loss: 0.4935 - val_true_negatives: 472.0000 - val_true_positives: 243.0000\n",
      "Epoch 15/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - binary_accuracy: 0.9549 - false_negatives: 1.9574 - false_positives: 34.0638 - loss: 0.1325 - true_negatives: 528.2979 - true_positives: 202.7021 - val_binary_accuracy: 0.9263 - val_false_negatives: 25.0000 - val_false_positives: 32.0000 - val_loss: 0.5031 - val_true_negatives: 473.0000 - val_true_positives: 243.0000\n",
      "Epoch 16/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - binary_accuracy: 0.9527 - false_negatives: 4.0426 - false_positives: 32.1702 - loss: 0.1377 - true_negatives: 530.1915 - true_positives: 200.6170 - val_binary_accuracy: 0.9288 - val_false_negatives: 25.0000 - val_false_positives: 30.0000 - val_loss: 0.5193 - val_true_negatives: 475.0000 - val_true_positives: 243.0000\n",
      "Epoch 17/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - binary_accuracy: 0.9538 - false_negatives: 2.5957 - false_positives: 34.2553 - loss: 0.1316 - true_negatives: 528.1064 - true_positives: 202.0638 - val_binary_accuracy: 0.9288 - val_false_negatives: 25.0000 - val_false_positives: 30.0000 - val_loss: 0.5324 - val_true_negatives: 475.0000 - val_true_positives: 243.0000\n",
      "Epoch 18/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - binary_accuracy: 0.9495 - false_negatives: 4.7021 - false_positives: 34.2340 - loss: 0.1405 - true_negatives: 528.1277 - true_positives: 199.9574 - val_binary_accuracy: 0.9301 - val_false_negatives: 25.0000 - val_false_positives: 29.0000 - val_loss: 0.5161 - val_true_negatives: 476.0000 - val_true_positives: 243.0000\n",
      "Epoch 19/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2s/step - binary_accuracy: 0.9580 - false_negatives: 2.5532 - false_positives: 31.1489 - loss: 0.1295 - true_negatives: 531.2128 - true_positives: 202.1064 - val_binary_accuracy: 0.9263 - val_false_negatives: 25.0000 - val_false_positives: 32.0000 - val_loss: 0.5430 - val_true_negatives: 473.0000 - val_true_positives: 243.0000\n",
      "Epoch 20/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 2s/step - binary_accuracy: 0.9627 - false_negatives: 2.2979 - false_positives: 28.1489 - loss: 0.1117 - true_negatives: 534.2128 - true_positives: 202.3617 - val_binary_accuracy: 0.9288 - val_false_negatives: 25.0000 - val_false_positives: 30.0000 - val_loss: 0.5586 - val_true_negatives: 475.0000 - val_true_positives: 243.0000\n",
      "Epoch 21/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - binary_accuracy: 0.9550 - false_negatives: 2.4894 - false_positives: 32.5106 - loss: 0.1263 - true_negatives: 529.8511 - true_positives: 202.1702 - val_binary_accuracy: 0.9250 - val_false_negatives: 25.0000 - val_false_positives: 33.0000 - val_loss: 0.5585 - val_true_negatives: 472.0000 - val_true_positives: 243.0000\n",
      "Epoch 22/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - binary_accuracy: 0.9601 - false_negatives: 1.7021 - false_positives: 29.3404 - loss: 0.1049 - true_negatives: 533.0213 - true_positives: 202.9574 - val_binary_accuracy: 0.9263 - val_false_negatives: 25.0000 - val_false_positives: 32.0000 - val_loss: 0.5886 - val_true_negatives: 473.0000 - val_true_positives: 243.0000\n",
      "Epoch 23/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - binary_accuracy: 0.9621 - false_negatives: 2.2766 - false_positives: 28.0638 - loss: 0.0996 - true_negatives: 534.2979 - true_positives: 202.3830 - val_binary_accuracy: 0.9224 - val_false_negatives: 25.0000 - val_false_positives: 35.0000 - val_loss: 0.6010 - val_true_negatives: 470.0000 - val_true_positives: 243.0000\n",
      "Epoch 24/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - binary_accuracy: 0.9608 - false_negatives: 1.9787 - false_positives: 28.5319 - loss: 0.1100 - true_negatives: 533.8298 - true_positives: 202.6808 - val_binary_accuracy: 0.9263 - val_false_negatives: 25.0000 - val_false_positives: 32.0000 - val_loss: 0.6037 - val_true_negatives: 473.0000 - val_true_positives: 243.0000\n",
      "Epoch 25/25\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 3s/step - binary_accuracy: 0.9655 - false_negatives: 1.6383 - false_positives: 25.8723 - loss: 0.0987 - true_negatives: 536.4894 - true_positives: 203.0213 - val_binary_accuracy: 0.9250 - val_false_negatives: 25.0000 - val_false_positives: 33.0000 - val_loss: 0.6110 - val_true_negatives: 472.0000 - val_true_positives: 243.0000\n"
     ]
    }
   ],
   "source": [
    "#mod = model.fit(train_dataset, epochs=25, validation_data = validate_dataset,class_weight={0: weight_for_0, 1: weight_for_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasVariable shape=(5, 5, 3, 32), dtype=float32, path=hybrid_model/conv2d/kernel>,\n",
       " <KerasVariable shape=(32,), dtype=float32, path=hybrid_model/conv2d/bias>,\n",
       " <KerasVariable shape=(5, 5, 32, 64), dtype=float32, path=hybrid_model/conv2d_1/kernel>,\n",
       " <KerasVariable shape=(64,), dtype=float32, path=hybrid_model/conv2d_1/bias>,\n",
       " <KerasVariable shape=(33883, 36), dtype=float32, path=hybrid_model/dense/kernel>,\n",
       " <KerasVariable shape=(36,), dtype=float32, path=hybrid_model/dense/bias>,\n",
       " <KerasVariable shape=(36, 36), dtype=float32, path=hybrid_model/dense_1/kernel>,\n",
       " <KerasVariable shape=(36,), dtype=float32, path=hybrid_model/dense_1/bias>,\n",
       " <KerasVariable shape=(36, 1), dtype=float32, path=hybrid_model/dense_2/kernel>,\n",
       " <KerasVariable shape=(1,), dtype=float32, path=hybrid_model/dense_2/bias>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': [0.5255972743034363,\n",
       "  0.49897611141204834,\n",
       "  0.7665529251098633,\n",
       "  0.8184300065040588,\n",
       "  0.8470989465713501,\n",
       "  0.8600682616233826,\n",
       "  0.900341272354126,\n",
       "  0.9044368863105774,\n",
       "  0.920819103717804,\n",
       "  0.9317406415939331,\n",
       "  0.9378839731216431,\n",
       "  0.9447098970413208,\n",
       "  0.9481228590011597,\n",
       "  0.9467576742172241,\n",
       "  0.9535835981369019,\n",
       "  0.9542661905288696,\n",
       "  0.950170636177063,\n",
       "  0.9515358209609985,\n",
       "  0.9569965600967407,\n",
       "  0.958361804485321,\n",
       "  0.9549487829208374,\n",
       "  0.9610921740531921,\n",
       "  0.9617747664451599,\n",
       "  0.9617747664451599,\n",
       "  0.9638225436210632],\n",
       " 'false_negatives': [217.0,\n",
       "  62.0,\n",
       "  141.0,\n",
       "  54.0,\n",
       "  33.0,\n",
       "  33.0,\n",
       "  15.0,\n",
       "  18.0,\n",
       "  12.0,\n",
       "  7.0,\n",
       "  12.0,\n",
       "  9.0,\n",
       "  8.0,\n",
       "  6.0,\n",
       "  4.0,\n",
       "  6.0,\n",
       "  6.0,\n",
       "  7.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  4.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  3.0,\n",
       "  3.0],\n",
       " 'false_positives': [478.0,\n",
       "  672.0,\n",
       "  201.0,\n",
       "  212.0,\n",
       "  191.0,\n",
       "  172.0,\n",
       "  131.0,\n",
       "  122.0,\n",
       "  104.0,\n",
       "  93.0,\n",
       "  79.0,\n",
       "  72.0,\n",
       "  68.0,\n",
       "  72.0,\n",
       "  64.0,\n",
       "  61.0,\n",
       "  67.0,\n",
       "  64.0,\n",
       "  58.0,\n",
       "  56.0,\n",
       "  62.0,\n",
       "  54.0,\n",
       "  51.0,\n",
       "  53.0,\n",
       "  50.0],\n",
       " 'loss': [0.8238633871078491,\n",
       "  0.6850268244743347,\n",
       "  0.9775136709213257,\n",
       "  0.3967805504798889,\n",
       "  0.342041552066803,\n",
       "  0.3072007894515991,\n",
       "  0.2642504870891571,\n",
       "  0.23893065750598907,\n",
       "  0.20944510400295258,\n",
       "  0.18876242637634277,\n",
       "  0.17798954248428345,\n",
       "  0.16728650033473969,\n",
       "  0.15531355142593384,\n",
       "  0.14614899456501007,\n",
       "  0.13622212409973145,\n",
       "  0.13584008812904358,\n",
       "  0.1382179856300354,\n",
       "  0.1365029364824295,\n",
       "  0.1289350986480713,\n",
       "  0.11862093955278397,\n",
       "  0.1239934116601944,\n",
       "  0.10685966163873672,\n",
       "  0.10776080936193466,\n",
       "  0.11034638434648514,\n",
       "  0.1058138906955719],\n",
       " 'true_negatives': [593.0,\n",
       "  399.0,\n",
       "  870.0,\n",
       "  859.0,\n",
       "  880.0,\n",
       "  899.0,\n",
       "  940.0,\n",
       "  949.0,\n",
       "  967.0,\n",
       "  978.0,\n",
       "  992.0,\n",
       "  999.0,\n",
       "  1003.0,\n",
       "  999.0,\n",
       "  1007.0,\n",
       "  1010.0,\n",
       "  1004.0,\n",
       "  1007.0,\n",
       "  1013.0,\n",
       "  1015.0,\n",
       "  1009.0,\n",
       "  1017.0,\n",
       "  1020.0,\n",
       "  1018.0,\n",
       "  1021.0],\n",
       " 'true_positives': [177.0,\n",
       "  332.0,\n",
       "  253.0,\n",
       "  340.0,\n",
       "  361.0,\n",
       "  361.0,\n",
       "  379.0,\n",
       "  376.0,\n",
       "  382.0,\n",
       "  387.0,\n",
       "  382.0,\n",
       "  385.0,\n",
       "  386.0,\n",
       "  388.0,\n",
       "  390.0,\n",
       "  388.0,\n",
       "  388.0,\n",
       "  387.0,\n",
       "  389.0,\n",
       "  389.0,\n",
       "  390.0,\n",
       "  391.0,\n",
       "  389.0,\n",
       "  391.0,\n",
       "  391.0],\n",
       " 'val_binary_accuracy': [0.35058215260505676,\n",
       "  0.782664954662323,\n",
       "  0.7930142283439636,\n",
       "  0.8447606563568115,\n",
       "  0.8602846264839172,\n",
       "  0.8783958554267883,\n",
       "  0.888745129108429,\n",
       "  0.9016817808151245,\n",
       "  0.9146183729171753,\n",
       "  0.9184993505477905,\n",
       "  0.9197930097579956,\n",
       "  0.9133247137069702,\n",
       "  0.9236739873886108,\n",
       "  0.9249676465988159,\n",
       "  0.926261305809021,\n",
       "  0.9288486242294312,\n",
       "  0.9288486242294312,\n",
       "  0.9301422834396362,\n",
       "  0.926261305809021,\n",
       "  0.9288486242294312,\n",
       "  0.9249676465988159,\n",
       "  0.926261305809021,\n",
       "  0.9223803281784058,\n",
       "  0.926261305809021,\n",
       "  0.9249676465988159],\n",
       " 'val_false_negatives': [0.0,\n",
       "  139.0,\n",
       "  86.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  25.0],\n",
       " 'val_false_positives': [502.0,\n",
       "  29.0,\n",
       "  74.0,\n",
       "  77.0,\n",
       "  65.0,\n",
       "  51.0,\n",
       "  43.0,\n",
       "  51.0,\n",
       "  41.0,\n",
       "  38.0,\n",
       "  37.0,\n",
       "  42.0,\n",
       "  34.0,\n",
       "  33.0,\n",
       "  32.0,\n",
       "  30.0,\n",
       "  30.0,\n",
       "  29.0,\n",
       "  32.0,\n",
       "  30.0,\n",
       "  33.0,\n",
       "  32.0,\n",
       "  35.0,\n",
       "  32.0,\n",
       "  33.0],\n",
       " 'val_loss': [0.6985552310943604,\n",
       "  0.6564745306968689,\n",
       "  0.498636394739151,\n",
       "  0.4608114957809448,\n",
       "  0.44141891598701477,\n",
       "  0.4188295900821686,\n",
       "  0.41921982169151306,\n",
       "  0.42634811997413635,\n",
       "  0.430900901556015,\n",
       "  0.4459008276462555,\n",
       "  0.45599982142448425,\n",
       "  0.4594184160232544,\n",
       "  0.47201865911483765,\n",
       "  0.493490606546402,\n",
       "  0.5030717253684998,\n",
       "  0.5193485617637634,\n",
       "  0.5324451327323914,\n",
       "  0.5160530805587769,\n",
       "  0.542953610420227,\n",
       "  0.5586430430412292,\n",
       "  0.5584665536880493,\n",
       "  0.5885878801345825,\n",
       "  0.6009811162948608,\n",
       "  0.6037204265594482,\n",
       "  0.6109539866447449],\n",
       " 'val_true_negatives': [3.0,\n",
       "  476.0,\n",
       "  431.0,\n",
       "  428.0,\n",
       "  440.0,\n",
       "  454.0,\n",
       "  462.0,\n",
       "  454.0,\n",
       "  464.0,\n",
       "  467.0,\n",
       "  468.0,\n",
       "  463.0,\n",
       "  471.0,\n",
       "  472.0,\n",
       "  473.0,\n",
       "  475.0,\n",
       "  475.0,\n",
       "  476.0,\n",
       "  473.0,\n",
       "  475.0,\n",
       "  472.0,\n",
       "  473.0,\n",
       "  470.0,\n",
       "  473.0,\n",
       "  472.0],\n",
       " 'val_true_positives': [268.0,\n",
       "  129.0,\n",
       "  182.0,\n",
       "  225.0,\n",
       "  225.0,\n",
       "  225.0,\n",
       "  225.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0,\n",
       "  243.0]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BATCHES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Iterate through all batches in the dataset and print their shapes\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the current batch\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"  Image Batch Shape:\", img_batch.shape)\n",
    "    print(\"  Metadata Batch Shape:\", meta_batch.shape)\n",
    "    print(\"  Target Batch Shape:\", target_batch.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve test predictions and real test values\n",
    "predictions = model.predict(test_dataset, steps = nb_test_batches)\n",
    "y_pred = [round(i) for i  in predictions.flatten()]\n",
    "y_test = np.concatenate([y for x, y in test_dataset], axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the loss\n",
    "loss = sum(abs(y_test - y_pred))/len(y_pred)\n",
    "print(\"Shape of prediction data:\", predictions.shape)\n",
    "print(\"Loss on test data:\", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

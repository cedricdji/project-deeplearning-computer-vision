{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:29:17.974948: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 14:29:17.989546: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 14:29:18.017571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 14:29:18.050737: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 14:29:18.059654: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 14:29:18.074063: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 14:29:18.997327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) DATA LOADING - BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "metaPath = dataPath + \"train-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "file = dataPath + \"train-image.hdf5\"\n",
    "\n",
    "#Image subset: normal, hairs1, hairs2, wrinkles1, wrinkles2, protrusions, malignant, malignant\n",
    "image_files = [\"ISIC_0015670\", \"ISIC_0052213\", \"ISIC_0075726\", \"ISIC_0076172\", \"ISIC_8570031\", \"ISIC_5071401\", \"ISIC_0104229\", \"ISIC_9877311\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95855/2560820901.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(metaPath, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "#Import metadata\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "\n",
    "#Import images from hdf5 file and one image\n",
    "images = []\n",
    "f = h5py.File(file, mode=\"r\")\n",
    "for isic_id in image_files:\n",
    "    image = np.array(\n",
    "        Image.open(\n",
    "            io.BytesIO(f[isic_id][()])\n",
    "            )\n",
    "        )\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "clin_size_long_diam_mm         0\n",
      "tbp_lv_areaMM2                 0\n",
      "tbp_lv_area_perim_ratio        0\n",
      "tbp_lv_eccentricity            0\n",
      "tbp_lv_minorAxisMM             0\n",
      "tbp_lv_color_std_mean          0\n",
      "tbp_lv_deltaLBnorm             0\n",
      "tbp_lv_radial_color_std_max    0\n",
      "dtype: int64\n",
      "\n",
      "-- y NA count --\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#IMAGES: cropped to 100 pixels and cast to tensorflow compatible float32\n",
    "X_img = [tf.cast(img, tf.float32) for img in crop_image(images, nbPix=100)]\n",
    "\n",
    "#METADATA: color and size features having no NAs\n",
    "X_meta = metadata[[\"isic_id\",\n",
    "                   \"clin_size_long_diam_mm\",\n",
    "                   \"tbp_lv_areaMM2\",\n",
    "                   \"tbp_lv_area_perim_ratio\",\n",
    "                   \"tbp_lv_eccentricity\",\n",
    "                   \"tbp_lv_minorAxisMM\",\n",
    "                   \"tbp_lv_color_std_mean\",\n",
    "                   \"tbp_lv_deltaLBnorm\",\n",
    "                   \"tbp_lv_radial_color_std_max\"]]\n",
    "\n",
    "X_meta = X_meta[X_meta[\"isic_id\"].isin(image_files)].iloc[:,1:]\n",
    "\n",
    "#TARGET\n",
    "y = metadata[metadata[\"isic_id\"].isin(image_files)][\"target\"]\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(X_meta.isna().sum())\n",
    "print(\"\\n-- y NA count --\")\n",
    "print(y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates the image (standardized). Avoids multiple file open/read/close operations.\n",
    "#file: full path for file\n",
    "#imgs: list of images to load\n",
    "#imgSize: number of pixels for size/resolution adjustment in square form\n",
    "class hdf5_generator:\n",
    "    def __init__(self, file, imgs, imgSize):\n",
    "        self.file = file\n",
    "        self.imgs = imgs\n",
    "        self.imgSize = imgSize\n",
    "        self.f = h5py.File(file, mode=\"r\")\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as h5file:\n",
    "            for img in self.imgs:\n",
    "                img = np.array(Image.open(io.BytesIO(f[img][()])))\n",
    "                img = tf.image.resize(img, [self.imgSize, self.imgSize])\n",
    "                img = tf.constant(np.reshape(img/255,(1,100,100,3)), dtype=tf.float32) #standardized here\n",
    "                yield img/255\n",
    "\n",
    "imgSize = 100\n",
    "features_dataset = tf.data.Dataset.from_generator(\n",
    "    hdf5_generator(file, image_files, imgSize),\n",
    "    output_types=tf.float32,\n",
    "    output_shapes = tf.TensorShape([1, imgSize,imgSize,3])\n",
    "    )\n",
    "\n",
    "#Generate target dataset\n",
    "y = [np.reshape(element, (1,1)) for element in y]\n",
    "y = tf.cast(y, dtype=tf.int32)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(y, name = \"target\")\n",
    "\n",
    "#Generate metadata set\n",
    "X_meta = tf.cast(X_meta, dtype=tf.int32)\n",
    "meta_dataset = tf.data.Dataset.from_tensor_slices(X_meta, name = \"metadata\")\n",
    "\n",
    "#Combine datasets into one\n",
    "dataset = tf.data.Dataset.zip((features_dataset, meta_dataset))\n",
    "dataset = tf.data.Dataset.zip((dataset, labels_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(8,), dtype=tf.int32, name=None)>\n",
      "(<tf.Tensor: shape=(1, 100, 100, 3), dtype=float32, numpy=\n",
      "array([[[[0.00277958, 0.0022567 , 0.00207216],\n",
      "         [0.00277716, 0.00225429, 0.00206974],\n",
      "         [0.00282215, 0.00226928, 0.00208474],\n",
      "         ...,\n",
      "         [0.00300338, 0.002389  , 0.00226559],\n",
      "         [0.00291981, 0.00234181, 0.0022034 ],\n",
      "         [0.00290116, 0.00233215, 0.00219374]],\n",
      "\n",
      "        [[0.00287166, 0.00234879, 0.00216424],\n",
      "         [0.00286455, 0.00233115, 0.0021466 ],\n",
      "         [0.00288695, 0.00233364, 0.00214909],\n",
      "         ...,\n",
      "         [0.00290403, 0.00230719, 0.002175  ],\n",
      "         [0.00285521, 0.00227347, 0.00213506],\n",
      "         [0.00283383, 0.00226307, 0.00212466]],\n",
      "\n",
      "        [[0.00297855, 0.00242568, 0.00224114],\n",
      "         [0.00295762, 0.00240431, 0.00221976],\n",
      "         [0.00295156, 0.00239792, 0.00221338],\n",
      "         ...,\n",
      "         [0.00278582, 0.00220143, 0.00206302],\n",
      "         [0.00279953, 0.00221514, 0.00207673],\n",
      "         [0.002799  , 0.00221492, 0.00207651]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.00287112, 0.00227135, 0.00219431],\n",
      "         [0.00273965, 0.00213988, 0.00204467],\n",
      "         [0.00272054, 0.00213577, 0.00199813],\n",
      "         ...,\n",
      "         [0.00288432, 0.00223764, 0.00205271],\n",
      "         [0.00273236, 0.00208568, 0.00190075],\n",
      "         [0.00267037, 0.00202369, 0.00183876]],\n",
      "\n",
      "        [[0.00290696, 0.00229443, 0.00220764],\n",
      "         [0.00278582, 0.00217702, 0.00206828],\n",
      "         [0.00268381, 0.00208643, 0.00195486],\n",
      "         ...,\n",
      "         [0.00270731, 0.00203064, 0.00183072],\n",
      "         [0.00268228, 0.00200561, 0.00180569],\n",
      "         [0.00270365, 0.00202699, 0.00182707]],\n",
      "\n",
      "        [[0.00288461, 0.00225409, 0.00216181],\n",
      "         [0.0027787 , 0.00215717, 0.0020469 ],\n",
      "         [0.0026925 , 0.00207735, 0.00193018],\n",
      "         ...,\n",
      "         [0.00264591, 0.00196924, 0.00176932],\n",
      "         [0.00267714, 0.00200048, 0.00180055],\n",
      "         [0.00269127, 0.00201461, 0.00181469]]]], dtype=float32)>, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([ 3,  3, 27,  0,  1,  0,  5,  0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "#Examine the dataset objects\n",
    "iterator = iter(dataset)\n",
    "print(meta_dataset)\n",
    "print(iterator.get_next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image, x_meta = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, 5, activation='relu')\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #self.dropout = tf.keras.layers.dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool(x1)\n",
    "        #x1 = self.conv2(x1)\n",
    "        #x1 = self.pool(x1)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x1 = self.flatten(x1)\n",
    "        x_all = tf.keras.concatenate([x1,x_meta])\n",
    "        # Neural Network\n",
    "        x1 = self.dense1(x_all)\n",
    "        #x = self.dense2(x_all)\n",
    "        #if training:\n",
    "        #    x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "model = CNN_model(neurons=8, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - binary_accuracy: 0.5642 - false_negatives_5: 0.7778 - false_positives_4: 1.0000 - loss: 0.6600 - true_negatives_4: 3.1111 - true_positives_4: 0.0000e+00\n",
      "Epoch 2/4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.8786 - false_negatives_5: 0.7778 - false_positives_4: 0.0000e+00 - loss: 0.4049 - true_negatives_4: 4.1111 - true_positives_4: 0.0000e+00   \n",
      "Epoch 3/4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - binary_accuracy: 0.8786 - false_negatives_5: 0.7778 - false_positives_4: 0.0000e+00 - loss: 0.3794 - true_negatives_4: 4.1111 - true_positives_4: 0.0000e+00  \n",
      "Epoch 4/4\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.8786 - false_negatives_5: 0.7778 - false_positives_4: 0.0000e+00 - loss: 0.3582 - true_negatives_4: 4.1111 - true_positives_4: 0.0000e+00    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:50:55.027012: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "mod = model.fit(dataset, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': [0.6666666865348816,\n",
       "  0.6666666865348816,\n",
       "  0.6666666865348816,\n",
       "  0.6666666865348816],\n",
       " 'false_negatives_1': [2.0, 2.0, 2.0, 2.0],\n",
       " 'false_positives': [0.0, 0.0, 0.0, 0.0],\n",
       " 'loss': [0.5017471313476562,\n",
       "  0.5017471313476562,\n",
       "  0.5017470717430115,\n",
       "  0.5017469525337219],\n",
       " 'true_negatives': [6.0, 6.0, 6.0, 6.0],\n",
       " 'true_positives': [0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISIC24_skin_cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

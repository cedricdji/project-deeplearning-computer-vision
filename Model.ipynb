{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Declare file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "#metaPath = dataPath + \"train-metadata.csv\"\n",
    "metaPath = dataPath + \"sample-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "#hdf5_file = dataPath + \"train-image.hdf5\"\n",
    "hdf5_file = dataPath + \"sample-image.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Load metadata from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                        0\n",
      "target                         0\n",
      "clin_size_long_diam_mm         0\n",
      "tbp_lv_areaMM2                 0\n",
      "tbp_lv_area_perim_ratio        0\n",
      "tbp_lv_eccentricity            0\n",
      "tbp_lv_minorAxisMM             0\n",
      "tbp_lv_color_std_mean          0\n",
      "tbp_lv_deltaLBnorm             0\n",
      "tbp_lv_radial_color_std_max    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Import metadata\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "\n",
    "#METADATA: color and size features having no NAs\n",
    "metadata = metadata[[\"isic_id\",\n",
    "                     \"target\",\n",
    "                     \"clin_size_long_diam_mm\",\n",
    "                     \"tbp_lv_areaMM2\",\n",
    "                     \"tbp_lv_area_perim_ratio\",\n",
    "                     \"tbp_lv_eccentricity\",\n",
    "                     \"tbp_lv_minorAxisMM\",\n",
    "                     \"tbp_lv_color_std_mean\",\n",
    "                     \"tbp_lv_deltaLBnorm\",\n",
    "                     \"tbp_lv_radial_color_std_max\"]]\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Train, Validate, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform train-validate or train-test-validate split on a list of isic_ids\n",
    "def ttv_split(isic_ids, test_frac=0.2, validate_frac=0.2, random_state=88, shuffle=True, stratify=None):\n",
    "    if test_frac < 0 or validate_frac < 0:\n",
    "        print(\"ERROR: Test of validate fraction is negative\")\n",
    "        return None\n",
    "    if test_frac > 1 or validate_frac > 1:\n",
    "        print(\"ERROR: Test of validate fraction is above 0\")\n",
    "        return None\n",
    "    if test_frac + validate_frac >= 1:\n",
    "        print(\"ERROR: Test and validate fractions sum to 1 or more.\")\n",
    "        return None\n",
    "\n",
    "    #Split training from the rest\n",
    "    test_size = test_frac + validate_frac\n",
    "    train, temp = train_test_split(isic_ids, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "    #Split test and validate\n",
    "    if test_frac == 0 or validate_frac == 0:\n",
    "        return train.tolist(), temp.tolist()\n",
    "    else:\n",
    "        test_size = test_frac / (test_frac + validate_frac)\n",
    "        test, validate = train_test_split(temp, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "        return train.tolist(), test.tolist(), validate.tolist()\n",
    "\n",
    "#Generate the splits of the isic_ids\n",
    "train_ids, test_ids, val_ids = ttv_split(metadata[\"isic_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train-test-validate portions of metadata into X and y\n",
    "def Xy_split(metadata, ids):\n",
    "    #Generate X (features without target)\n",
    "    \n",
    "    X = metadata[metadata[\"isic_id\"].isin(ids)]\n",
    "    X = X.loc[:, ~X.columns.isin(['isic_id', 'target'])]\n",
    "    #Generate y\n",
    "    y = metadata[metadata[\"isic_id\"].isin(ids)][\"target\"]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = Xy_split(metadata, train_ids)\n",
    "X_test, y_test = Xy_split(metadata, test_ids)\n",
    "X_validate, y_validate = Xy_split(metadata, val_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Load images and create hybrid tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATOR FOR HDF5\n",
    "class hdf5_generator:\n",
    "    def __init__(self, file, img_names, imgSize):\n",
    "        self.file = file\n",
    "        self.img_names = img_names\n",
    "        self.imgSize = imgSize\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as h5file:\n",
    "            for img_name in self.img_names:\n",
    "                try:\n",
    "                    # Load image data from HDF5\n",
    "                    img = np.array(Image.open(io.BytesIO(h5file[img_name][()])))\n",
    "                    \n",
    "                    # Resize the image\n",
    "                    img = tf.image.resize(img, [self.imgSize, self.imgSize])\n",
    "                    \n",
    "                    # Data Augmentation \n",
    "                    img = tf.image.random_flip_left_right(img)\n",
    "                    img = tf.image.random_flip_up_down(img)\n",
    "                    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "\n",
    "                    # Standardize and return as TensorFlow constant\n",
    "                    img = tf.constant(img / 255, dtype=tf.float32)  # Standardize here\n",
    "               \n",
    "                    \n",
    "                    yield img\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_name}: {e}\")\n",
    "                    # log the error to a file for later analysis\n",
    "                    with open('image_errors.log', 'a') as f:\n",
    "                        f.write(f\"Error loading image {img_name}: {e}\\n\")\n",
    "                    continue\n",
    "\n",
    "#Generate the dataset with batch size and prefetching\n",
    "def make_dataset(hdf5_file, meta, target, img_names, imgSize=100, batch_size=6):\n",
    "   \n",
    "    # Get the number of metadata features\n",
    "    num_features = meta.shape[-1]\n",
    "    \n",
    "    # Generate image dataset\n",
    "    img_dataset = tf.data.Dataset.from_generator(\n",
    "        hdf5_generator(hdf5_file, img_names, imgSize),\n",
    "        output_types=tf.float32,\n",
    "        output_shapes=tf.TensorShape([imgSize, imgSize, 3])\n",
    "    )\n",
    "\n",
    "    # Generate target dataset\n",
    "    target = [np.reshape(element, (1, 1)) for element in target]\n",
    "    target = tf.cast(target, dtype=tf.int32)\n",
    "    target = tf.data.Dataset.from_tensor_slices(target, name=\"target\")\n",
    "\n",
    "    # Generate metadata set\n",
    "\n",
    "    meta = tf.cast(meta, dtype=tf.float32)\n",
    "    meta = tf.reshape(meta, shape=(len(img_names),1,num_features))\n",
    "    meta = tf.data.Dataset.from_tensor_slices(meta, name=\"metadata\")\n",
    "\n",
    "    # Combine datasets into one\n",
    "    dataset = tf.data.Dataset.zip((img_dataset, meta))\n",
    "    dataset = tf.data.Dataset.zip((dataset, target))\n",
    "\n",
    "    # Add shuffling, batching, and prefetching\n",
    "    dataset = dataset.shuffle(buffer_size=min(len(img_names), 10000)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make datasets\n",
    "train_dataset = make_dataset(hdf5_file, X_train, y_train, train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete duplicate data, keeping only the dataset\n",
    "#del metadata\n",
    "#del y_train\n",
    "#del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 8), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 1, 1), dtype=tf.int32, name=None))> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Examine the dataset objects\n",
    "print(train_dataset, \"\\n\")\n",
    "\n",
    "#iterator = iter(train_dataset)\n",
    "#print(iterator.get_next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image, x_meta = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, 5, activation='relu')\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #self.dropout = tf.keras.layers.dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x = self.conv1(x_image)\n",
    "        x = self.pool(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.pool(x)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x = self.flatten(x)\n",
    "        # Reshape metadata to match dimensions\n",
    "        x_meta = tf.reshape(x_meta, (tf.shape(x_meta)[0], 8))\n",
    "        #x_all = tf.concat([x,x_meta], axis=1)\n",
    "        x_all = keras.layers.Concatenate(axis=1)([x, x_meta])\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        #x_all = self.dense2(x_all)\n",
    "        #if training:\n",
    "        #    x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "#model = CNN_model(neurons=8, activ='tanh')\n",
    "model = Hybrid_model(neurons=8, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (6, 100, 100, 3)\n",
      "Metadata batch shape: (6, 1, 8)\n",
      "Target batch shape: (6, 1, 1)\n",
      "Total number of batches in the dataset: 14\n"
     ]
    }
   ],
   "source": [
    "# Take 1 batch from the dataset and check its content\n",
    "for batch in train_dataset.take(1):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the individual components\n",
    "    print(f\"Image batch shape: {img_batch.shape}\")\n",
    "    print(f\"Metadata batch shape: {meta_batch.shape}\")\n",
    "    print(f\"Target batch shape: {target_batch.shape}\")\n",
    "\n",
    "# To count the total number of batches\n",
    "batch_count = 0\n",
    "for _ in train_dataset:\n",
    "    batch_count += 1\n",
    "\n",
    "print(f\"Total number of batches in the dataset: {batch_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\anaconda3\\envs\\new_env\\Lib\\site-packages\\keras\\src\\layers\\layer.py:391: UserWarning: `build()` was called on layer 'hybrid_model_18', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - binary_accuracy: 0.5683 - false_negatives_22: 16.5333 - false_positives_22: 4.0000 - loss: 0.8759 - true_negatives_22: 24.4000 - true_positives_22: 2.0000\n",
      "Epoch 2/4\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - binary_accuracy: 0.5396 - false_negatives_22: 22.0000 - false_positives_22: 0.0000e+00 - loss: 0.8374 - true_negatives_22: 24.9333 - true_positives_22: 0.0000e+00\n",
      "Epoch 3/4\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - binary_accuracy: 0.5813 - false_negatives_22: 20.3333 - false_positives_22: 0.0000e+00 - loss: 0.6773 - true_negatives_22: 26.6000 - true_positives_22: 0.0000e+00\n",
      "Epoch 4/4\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - binary_accuracy: 0.5004 - false_negatives_22: 3.9333 - false_positives_22: 19.9333 - loss: 0.6937 - true_negatives_22: 7.6667 - true_positives_22: 15.4000\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "mod = model.fit(train_dataset, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': [0.5189873576164246,\n",
       "  0.5443037748336792,\n",
       "  0.5443037748336792,\n",
       "  0.5063291192054749],\n",
       " 'false_negatives_22': [34.0, 36.0, 36.0, 4.0],\n",
       " 'false_positives_22': [4.0, 0.0, 0.0, 35.0],\n",
       " 'loss': [1.0509973764419556,\n",
       "  0.8010803461074829,\n",
       "  0.6867920756340027,\n",
       "  0.6936358213424683],\n",
       " 'true_negatives_22': [39.0, 43.0, 43.0, 8.0],\n",
       " 'true_positives_22': [2.0, 0.0, 0.0, 32.0]}"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BATCHES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 2:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 3:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 4:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 5:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 6:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 7:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 8:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 9:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 10:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 11:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 12:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 13:\n",
      "  Image Batch Shape: (6, 100, 100, 3)\n",
      "  Metadata Batch Shape: (6, 1, 8)\n",
      "  Target Batch Shape: (6, 1, 1)\n",
      "Batch 14:\n",
      "  Image Batch Shape: (1, 100, 100, 3)\n",
      "  Metadata Batch Shape: (1, 1, 8)\n",
      "  Target Batch Shape: (1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all batches in the dataset and print their shapes\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the current batch\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"  Image Batch Shape:\", img_batch.shape)\n",
    "    print(\"  Metadata Batch Shape:\", meta_batch.shape)\n",
    "    print(\"  Target Batch Shape:\", target_batch.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISIC24_skin_cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 21:15:23.243903: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 21:15:23.248573: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 21:15:23.259446: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 21:15:23.277350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 21:15:23.282917: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 21:15:23.296323: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 21:15:24.787408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) DATA LOADING - BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "metaPath = dataPath + \"train-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "file = dataPath + \"train-image.hdf5\"\n",
    "\n",
    "#Image subset: normal, hairs1, hairs2, wrinkles1, wrinkles2, protrusions, malignant, malignant, other\n",
    "image_files = [\"ISIC_0015670\", \"ISIC_0052213\", \"ISIC_0075726\", \"ISIC_0076172\", \"ISIC_8570031\", \"ISIC_5071401\", \"ISIC_0104229\", \"ISIC_9877311\", \"ISIC_0024200\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27073/2560820901.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(metaPath, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "#Import metadata\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "\n",
    "#Import images from hdf5 file and one image\n",
    "images = []\n",
    "f = h5py.File(file, mode=\"r\")\n",
    "for isic_id in image_files:\n",
    "    image = np.array(\n",
    "        Image.open(\n",
    "            io.BytesIO(f[isic_id][()])\n",
    "            )\n",
    "        )\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Load metadata and target from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "clin_size_long_diam_mm         0\n",
      "tbp_lv_areaMM2                 0\n",
      "tbp_lv_area_perim_ratio        0\n",
      "tbp_lv_eccentricity            0\n",
      "tbp_lv_minorAxisMM             0\n",
      "tbp_lv_color_std_mean          0\n",
      "tbp_lv_deltaLBnorm             0\n",
      "tbp_lv_radial_color_std_max    0\n",
      "dtype: int64\n",
      "\n",
      "-- y NA count --\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#METADATA: color and size features having no NAs\n",
    "X_meta = metadata[[\"isic_id\",\n",
    "                   \"clin_size_long_diam_mm\",\n",
    "                   \"tbp_lv_areaMM2\",\n",
    "                   \"tbp_lv_area_perim_ratio\",\n",
    "                   \"tbp_lv_eccentricity\",\n",
    "                   \"tbp_lv_minorAxisMM\",\n",
    "                   \"tbp_lv_color_std_mean\",\n",
    "                   \"tbp_lv_deltaLBnorm\",\n",
    "                   \"tbp_lv_radial_color_std_max\"]]\n",
    "\n",
    "X_meta = X_meta[X_meta[\"isic_id\"].isin(image_files)].iloc[:,1:]\n",
    "\n",
    "#TARGET\n",
    "y = metadata[metadata[\"isic_id\"].isin(image_files)][\"target\"]\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(X_meta.isna().sum())\n",
    "print(\"\\n-- y NA count --\")\n",
    "print(y.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>tbp_lv_areaMM2</th>\n",
       "      <th>tbp_lv_area_perim_ratio</th>\n",
       "      <th>tbp_lv_eccentricity</th>\n",
       "      <th>tbp_lv_minorAxisMM</th>\n",
       "      <th>tbp_lv_color_std_mean</th>\n",
       "      <th>tbp_lv_deltaLBnorm</th>\n",
       "      <th>tbp_lv_radial_color_std_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.04</td>\n",
       "      <td>3.152561</td>\n",
       "      <td>27.476170</td>\n",
       "      <td>0.901302</td>\n",
       "      <td>1.543016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.784302</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.73</td>\n",
       "      <td>2.101708</td>\n",
       "      <td>19.902560</td>\n",
       "      <td>0.946448</td>\n",
       "      <td>0.929916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.531302</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.25</td>\n",
       "      <td>7.374742</td>\n",
       "      <td>16.400927</td>\n",
       "      <td>0.862139</td>\n",
       "      <td>2.054795</td>\n",
       "      <td>1.739398</td>\n",
       "      <td>8.800130</td>\n",
       "      <td>1.909609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>4.50</td>\n",
       "      <td>8.556953</td>\n",
       "      <td>30.651852</td>\n",
       "      <td>0.829499</td>\n",
       "      <td>2.719287</td>\n",
       "      <td>0.794746</td>\n",
       "      <td>4.745211</td>\n",
       "      <td>1.035859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2.60</td>\n",
       "      <td>3.152561</td>\n",
       "      <td>16.701670</td>\n",
       "      <td>0.851353</td>\n",
       "      <td>1.372272</td>\n",
       "      <td>0.992478</td>\n",
       "      <td>5.973864</td>\n",
       "      <td>1.134277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>6.55</td>\n",
       "      <td>12.103580</td>\n",
       "      <td>38.025960</td>\n",
       "      <td>0.907116</td>\n",
       "      <td>3.481341</td>\n",
       "      <td>1.401430</td>\n",
       "      <td>5.621653</td>\n",
       "      <td>1.340916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201543</th>\n",
       "      <td>10.57</td>\n",
       "      <td>36.742353</td>\n",
       "      <td>21.024594</td>\n",
       "      <td>0.924676</td>\n",
       "      <td>4.549288</td>\n",
       "      <td>9.952932</td>\n",
       "      <td>15.934890</td>\n",
       "      <td>9.018130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343041</th>\n",
       "      <td>2.42</td>\n",
       "      <td>3.640458</td>\n",
       "      <td>14.674190</td>\n",
       "      <td>0.773552</td>\n",
       "      <td>1.549823</td>\n",
       "      <td>1.729533</td>\n",
       "      <td>10.369350</td>\n",
       "      <td>1.601183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396165</th>\n",
       "      <td>8.16</td>\n",
       "      <td>24.544943</td>\n",
       "      <td>21.434010</td>\n",
       "      <td>0.860139</td>\n",
       "      <td>4.503774</td>\n",
       "      <td>2.179194</td>\n",
       "      <td>8.754266</td>\n",
       "      <td>2.432117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clin_size_long_diam_mm  tbp_lv_areaMM2  tbp_lv_area_perim_ratio  \\\n",
       "0                         3.04        3.152561                27.476170   \n",
       "4                         2.73        2.101708                19.902560   \n",
       "26                        4.25        7.374742                16.400927   \n",
       "100                       4.50        8.556953                30.651852   \n",
       "112                       2.60        3.152561                16.701670   \n",
       "1245                      6.55       12.103580                38.025960   \n",
       "201543                   10.57       36.742353                21.024594   \n",
       "343041                    2.42        3.640458                14.674190   \n",
       "396165                    8.16       24.544943                21.434010   \n",
       "\n",
       "        tbp_lv_eccentricity  tbp_lv_minorAxisMM  tbp_lv_color_std_mean  \\\n",
       "0                  0.901302            1.543016               0.000000   \n",
       "4                  0.946448            0.929916               0.000000   \n",
       "26                 0.862139            2.054795               1.739398   \n",
       "100                0.829499            2.719287               0.794746   \n",
       "112                0.851353            1.372272               0.992478   \n",
       "1245               0.907116            3.481341               1.401430   \n",
       "201543             0.924676            4.549288               9.952932   \n",
       "343041             0.773552            1.549823               1.729533   \n",
       "396165             0.860139            4.503774               2.179194   \n",
       "\n",
       "        tbp_lv_deltaLBnorm  tbp_lv_radial_color_std_max  \n",
       "0                 5.784302                     0.000000  \n",
       "4                 6.531302                     0.000000  \n",
       "26                8.800130                     1.909609  \n",
       "100               4.745211                     1.035859  \n",
       "112               5.973864                     1.134277  \n",
       "1245              5.621653                     1.340916  \n",
       "201543           15.934890                     9.018130  \n",
       "343041           10.369350                     1.601183  \n",
       "396165            8.754266                     2.432117  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display X_meta in order to inspect the tensor values and shapes\n",
    "X_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Load images and create hybrid tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_27073/2869423975.py:21: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /tmp/ipykernel_27073/2869423975.py:21: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n"
     ]
    }
   ],
   "source": [
    "#Generates the image (standardized). Avoids multiple file open/read/close operations.\n",
    "#file: full path for file\n",
    "#imgs: list of images to load\n",
    "#imgSize: number of pixels for size/resolution adjustment in square form\n",
    "class hdf5_generator:\n",
    "    def __init__(self, file, imgs, imgSize):\n",
    "        self.file = file\n",
    "        self.imgs = imgs\n",
    "        self.imgSize = imgSize\n",
    "        self.f = h5py.File(file, mode=\"r\")\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as h5file:\n",
    "            for img in self.imgs:\n",
    "                img = np.array(Image.open(io.BytesIO(f[img][()])))\n",
    "                img = tf.image.resize(img, [self.imgSize, self.imgSize])\n",
    "                img = tf.constant(np.reshape(img/255,(1,100,100,3)), dtype=tf.float32) #standardized here\n",
    "                yield img\n",
    "\n",
    "#Generate image dataset\n",
    "imgSize = 100\n",
    "features_dataset = tf.data.Dataset.from_generator(\n",
    "    hdf5_generator(file, image_files, imgSize),\n",
    "    output_types=tf.float32,\n",
    "    output_shapes = tf.TensorShape([1, imgSize,imgSize,3])\n",
    "    )\n",
    "\n",
    "#Generate target dataset\n",
    "y = [np.reshape(element, (1,1)) for element in y]\n",
    "y = tf.cast(y, dtype=tf.int32)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(y, name = \"target\")\n",
    "\n",
    "#Generate metadata set\n",
    "X_meta = tf.cast(X_meta, dtype=tf.float32)\n",
    "X_meta = tf.reshape(X_meta, shape=(9,1,8))\n",
    "meta_dataset = tf.data.Dataset.from_tensor_slices(X_meta, name = \"metadata\")\n",
    "\n",
    "#Combine datasets into one\n",
    "subset = tf.data.Dataset.zip((features_dataset, meta_dataset))\n",
    "dataset = tf.data.Dataset.zip((subset, labels_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_ZipDataset element_spec=((TensorSpec(shape=(1, 100, 100, 3), dtype=tf.float32, name=None), TensorSpec(shape=(1, 8), dtype=tf.float32, name=None)), TensorSpec(shape=(1, 1), dtype=tf.int32, name=None))> \n",
      "\n",
      "((<tf.Tensor: shape=(1, 100, 100, 3), dtype=float32, numpy=\n",
      "array([[[[0.70879203, 0.5754587 , 0.5283999 ],\n",
      "         [0.7081765 , 0.57484317, 0.52778435],\n",
      "         [0.7196471 , 0.57866675, 0.53160787],\n",
      "         ...,\n",
      "         [0.7658624 , 0.60919565, 0.5777251 ],\n",
      "         [0.7445527 , 0.5971605 , 0.56186634],\n",
      "         [0.73979616, 0.59469813, 0.559404  ]],\n",
      "\n",
      "        [[0.7322745 , 0.59894115, 0.5518823 ],\n",
      "         [0.7304597 , 0.5944422 , 0.54738337],\n",
      "         [0.7361721 , 0.595077  , 0.54801816],\n",
      "         ...,\n",
      "         [0.74052656, 0.58833337, 0.55462605],\n",
      "         [0.7280784 , 0.5797342 , 0.5444401 ],\n",
      "         [0.72262746, 0.5770821 , 0.541788  ]],\n",
      "\n",
      "        [[0.7595294 , 0.618549  , 0.57149017],\n",
      "         [0.7541931 , 0.613098  , 0.5660392 ],\n",
      "         [0.75264704, 0.6114706 , 0.56441176],\n",
      "         ...,\n",
      "         [0.7103848 , 0.5613652 , 0.5260711 ],\n",
      "         [0.7138809 , 0.5648613 , 0.5295672 ],\n",
      "         [0.71374464, 0.5648039 , 0.5295098 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7321362 , 0.579195  , 0.559549  ],\n",
      "         [0.6986107 , 0.54566956, 0.5213921 ],\n",
      "         [0.69373786, 0.54462016, 0.50952214],\n",
      "         ...,\n",
      "         [0.73550045, 0.57059854, 0.5234417 ],\n",
      "         [0.6967511 , 0.5318492 , 0.4846924 ],\n",
      "         [0.68094313, 0.5160412 , 0.46888444]],\n",
      "\n",
      "        [[0.7412745 , 0.5850785 , 0.56294847],\n",
      "         [0.7103834 , 0.5551394 , 0.52741176],\n",
      "         [0.68437254, 0.5320407 , 0.49848872],\n",
      "         ...,\n",
      "         [0.69036347, 0.5178144 , 0.46683407],\n",
      "         [0.68398035, 0.51143134, 0.46045095],\n",
      "         [0.68943137, 0.5168823 , 0.46590194]],\n",
      "\n",
      "        [[0.73557645, 0.57479215, 0.55126274],\n",
      "         [0.7085687 , 0.55007845, 0.5219608 ],\n",
      "         [0.68658775, 0.529725  , 0.49219662],\n",
      "         ...,\n",
      "         [0.67470586, 0.5021568 , 0.45117643],\n",
      "         [0.6826703 , 0.5101213 , 0.4591409 ],\n",
      "         [0.6862745 , 0.5137255 , 0.4627451 ]]]], dtype=float32)>, <tf.Tensor: shape=(1, 8), dtype=float32, numpy=\n",
      "array([[ 3.04      ,  3.1525614 , 27.47617   ,  0.90130174,  1.543016  ,\n",
      "         0.        ,  5.784302  ,  0.        ]], dtype=float32)>), <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[0]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "#Examine the dataset objects\n",
    "iterator = iter(dataset)\n",
    "print(dataset, \"\\n\")\n",
    "print(iterator.get_next())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image, x_meta = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, 5, activation='relu')\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #self.dropout = tf.keras.layers.dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x = self.conv1(x_image)\n",
    "        x = self.pool(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.pool(x)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x = self.flatten(x)\n",
    "        #x_all = tf.concat([x,x_meta], axis=1)\n",
    "        x_all = keras.layers.Concatenate(axis=1)([x, x_meta])\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        #x_all = self.dense2(x_all)\n",
    "        #if training:\n",
    "        #    x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "#model = CNN_model(neurons=8, activ='tanh')\n",
    "model = Hybrid_model(neurons=8, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'hybrid_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n",
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/backend/tensorflow/nn.py:707: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - binary_accuracy: 0.6114 - false_negatives: 0.7000 - false_positives: 1.0000 - loss: 0.5971 - true_negatives: 3.7000 - true_positives: 0.0000e+00\n",
      "Epoch 2/4\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - binary_accuracy: 0.9043 - false_negatives: 0.7000 - false_positives: 0.0000e+00 - loss: 0.2920 - true_negatives: 4.7000 - true_positives: 0.0000e+00   \n",
      "Epoch 3/4\n",
      "\u001b[1m1/9\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - binary_accuracy: 1.0000 - false_negatives: 0.0000e+00 - false_positives: 0.0000e+00 - loss: 0.0683 - true_negatives: 1.0000 - true_positives: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 21:15:32.641005: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n",
      "2024-09-09 21:15:32.755181: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9043 - false_negatives: 0.7000 - false_positives: 0.0000e+00 - loss: 0.2845 - true_negatives: 4.7000 - true_positives: 0.0000e+00    \n",
      "Epoch 4/4\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - binary_accuracy: 0.9043 - false_negatives: 0.7000 - false_positives: 0.0000e+00 - loss: 0.2838 - true_negatives: 4.7000 - true_positives: 0.0000e+00    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 21:15:32.967375: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "mod = model.fit(dataset, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': [0.6000000238418579,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071,\n",
       "  0.699999988079071],\n",
       " 'false_negatives': [2.0, 2.0, 2.0, 2.0],\n",
       " 'false_positives': [1.0, 0.0, 0.0, 0.0],\n",
       " 'loss': [0.7504349946975708,\n",
       "  0.6019914746284485,\n",
       "  0.5589548945426941,\n",
       "  0.524715006351471],\n",
       " 'true_negatives': [6.0, 7.0, 7.0, 7.0],\n",
       " 'true_positives': [0.0, 0.0, 0.0, 0.0]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISIC24_skin_cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

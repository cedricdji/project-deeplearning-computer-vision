{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 11:40:27.317047: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 11:40:27.320338: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-09 11:40:27.330144: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 11:40:27.346704: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 11:40:27.351443: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 11:40:27.363703: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 11:40:28.805940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) DATA LOADING - BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "metaPath = dataPath + \"train-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "file = dataPath + \"train-image.hdf5\"\n",
    "\n",
    "#Image subset: normal, hairs1, hairs2, wrinkles1, wrinkles2, protrusions, malignant, malignant\n",
    "image_files = [\"ISIC_0015670\", \"ISIC_0052213\", \"ISIC_0075726\", \"ISIC_0076172\", \"ISIC_8570031\", \"ISIC_5071401\", \"ISIC_0104229\", \"ISIC_9877311\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22514/2560820901.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  metadata = pd.read_csv(metaPath, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "#Import metadata\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "\n",
    "#Import images from hdf5 file and one image\n",
    "images = []\n",
    "f = h5py.File(file, mode=\"r\")\n",
    "for isic_id in image_files:\n",
    "    image = np.array(\n",
    "        Image.open(\n",
    "            io.BytesIO(f[isic_id][()])\n",
    "            )\n",
    "        )\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "clin_size_long_diam_mm         0\n",
      "tbp_lv_areaMM2                 0\n",
      "tbp_lv_area_perim_ratio        0\n",
      "tbp_lv_eccentricity            0\n",
      "tbp_lv_minorAxisMM             0\n",
      "tbp_lv_color_std_mean          0\n",
      "tbp_lv_deltaLBnorm             0\n",
      "tbp_lv_radial_color_std_max    0\n",
      "dtype: int64\n",
      "\n",
      "-- y NA count --\n",
      "y\t\t\t       0\n"
     ]
    }
   ],
   "source": [
    "#IMAGES: cropped to 100 pixels and cast to tensorflow compatible float32\n",
    "X_img = [tf.cast(img, tf.float32) for img in crop_image(images, nbPix=100)]\n",
    "#METADATA: color and size features having no NAs\n",
    "X_meta = metadata[[\"clin_size_long_diam_mm\",\n",
    "                        \"tbp_lv_areaMM2\",\n",
    "                        \"tbp_lv_area_perim_ratio\",\n",
    "                        \"tbp_lv_eccentricity\",\n",
    "                        \"tbp_lv_minorAxisMM\",\n",
    "                        \"tbp_lv_color_std_mean\",\n",
    "                        \"tbp_lv_deltaLBnorm\",\n",
    "                        \"tbp_lv_radial_color_std_max\"]]\n",
    "#TARGET\n",
    "y = metadata[metadata[\"isic_id\"].isin(image_files)][\"target\"]\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(X_meta.isna().sum())\n",
    "print(\"\\n-- y NA count --\")\n",
    "print(\"y\\t\\t\\t      \", y.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, 5, activation='relu')\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #self.dropout = tf.keras.layers.dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool(x1)\n",
    "        #x1 = self.conv2(x1)\n",
    "        #x1 = self.pool(x1)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x1 = self.flatten(x1)\n",
    "        x_all = tf.keras.concatenate([x1,x_meta])\n",
    "        # Neural Network\n",
    "        x1 = self.dense1(x_all)\n",
    "        #x = self.dense2(x_all)\n",
    "        #if training:\n",
    "        #    x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "model = CNN_model(neurons=8, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/layers/layer.py:1383: UserWarning: Layer 'cnn_model' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Layer \"conv2d\" expects 1 input(s), but it received 8 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_1:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_2:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_3:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_4:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_5:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_6:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_7:0' shape=(None, 100, 3) dtype=float32>]''\n",
      "  warnings.warn(\n",
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'cnn_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling CNN_model.call().\n\n\u001b[1mLayer \"conv2d\" expects 1 input(s), but it received 8 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_1:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_2:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_3:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_4:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_5:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_6:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_7:0' shape=(None, 100, 3) dtype=float32>]\u001b[0m\n\nArguments received by CNN_model.call():\n  • inputs=('tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mCNN_model.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     12\u001b[0m x_image \u001b[38;5;241m=\u001b[39m inputs\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convolutions\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(x1)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Flattening of images for input layer\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling CNN_model.call().\n\n\u001b[1mLayer \"conv2d\" expects 1 input(s), but it received 8 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_1:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_2:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_3:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_4:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_5:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_6:0' shape=(None, 100, 3) dtype=float32>, <tf.Tensor 'data_7:0' shape=(None, 100, 3) dtype=float32>]\u001b[0m\n\nArguments received by CNN_model.call():\n  • inputs=('tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)', 'tf.Tensor(shape=(None, 100, 3), dtype=float32)')"
     ]
    }
   ],
   "source": [
    "#Fit the model\n",
    "model.fit(X_img, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISIC24_skin_cancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

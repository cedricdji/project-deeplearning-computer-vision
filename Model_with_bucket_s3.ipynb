{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b358fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "\n",
    "# Function to download images from S3\n",
    "def download_images_from_s3(bucket_name, image_keys, local_dir=\"images\"):\n",
    "    s3 = boto3.client('s3', aws_access_key_id='YOUR_AWS_ACCESS_KEY',\n",
    "                      aws_secret_access_key='YOUR_AWS_SECRET_KEY')\n",
    "    \n",
    "    if not os.path.exists(local_dir):\n",
    "        os.makedirs(local_dir)\n",
    "\n",
    "    downloaded_images = []\n",
    "    \n",
    "    for key in image_keys:\n",
    "        local_file = os.path.join(local_dir, key.split('/')[-1])\n",
    "        try:\n",
    "            s3.download_file(bucket_name, key, local_file)\n",
    "            print(f\"Downloaded {key} to {local_file}\")\n",
    "            # Assuming images are to be loaded using PIL after download\n",
    "            image = Image.open(local_file)\n",
    "            downloaded_images.append(np.array(image))\n",
    "        except NoCredentialsError:\n",
    "            print(\"Credentials not available\")\n",
    "    \n",
    "    return downloaded_images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL - IMAGE LOADING & NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\__init__.py:50\u001b[0m\n\u001b[0;32m     43\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     51\u001b[0m     get_option,\n\u001b[0;32m     52\u001b[0m     set_option,\n\u001b[0;32m     53\u001b[0m     reset_option,\n\u001b[0;32m     54\u001b[0m     describe_option,\n\u001b[0;32m     55\u001b[0m     option_context,\n\u001b[0;32m     56\u001b[0m     options,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\_config\\__init__.py:20\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mpandas._config is considered explicitly upstream of everything else in pandas,\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mshould have no intra-pandas dependencies.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mare initialized.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect_console_encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn_copy_on_write\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m ]\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dates  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     _global_config,\n\u001b[0;32m     24\u001b[0m     describe_option,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     set_option,\n\u001b[0;32m     30\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\_config\\config.py:68\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     59\u001b[0m     TYPE_CHECKING,\n\u001b[0;32m     60\u001b[0m     Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     cast,\n\u001b[0;32m     65\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     69\u001b[0m     F,\n\u001b[0;32m     70\u001b[0m     T,\n\u001b[0;32m     71\u001b[0m )\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\pandas\\_typing.py:198\u001b[0m\n\u001b[0;32m    192\u001b[0m Frequency \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseOffset\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    193\u001b[0m Axes \u001b[38;5;241m=\u001b[39m ListLike\n\u001b[0;32m    195\u001b[0m RandomState \u001b[38;5;241m=\u001b[39m Union[\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m    197\u001b[0m     np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m--> 198\u001b[0m     \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241m.\u001b[39mGenerator,\n\u001b[0;32m    199\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mBitGenerator,\n\u001b[0;32m    200\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState,\n\u001b[0;32m    201\u001b[0m ]\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# dtypes\u001b[39;00m\n\u001b[0;32m    204\u001b[0m NpDtype \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mdtype, type_t[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mobject\u001b[39m]]]\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\numpy\\__init__.py:354\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__dir__\u001b[39m():\n\u001b[0;32m    351\u001b[0m     public_symbols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m|\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m    352\u001b[0m     public_symbols \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    353\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrixlib\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 354\u001b[0m         \u001b[38;5;66;03m# These were moved in 1.25 and may be deprecated eventually:\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModuleDeprecationWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisibleDeprecationWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplexWarning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTooHardError\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAxisError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m     }\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(public_symbols)\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\numpy\\random\\__init__.py:180\u001b[0m\n\u001b[0;32m    126\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbeta\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinomial\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzipf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    177\u001b[0m ]\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# add these for module-freeze analysis (like PyInstaller)\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pickle\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _common\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _bounded_integers\n",
      "File \u001b[1;32mc:\\Users\\Cedric DJIVO\\OneDrive\\DATA SCIENCE\\DSTI\\Projects\\deep-learning\\.venv\\Lib\\site-packages\\numpy\\random\\_pickle.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmtrand\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomState\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_philox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Philox\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pcg64\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCG64, PCG64DXSM\n",
      "File \u001b[1;32mnumpy\\\\random\\\\mtrand.pyx:1\u001b[0m, in \u001b[0;36minit numpy.random.mtrand\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "import csv\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) GENERAL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to show image\n",
    "def show_img(image):\n",
    "    plt.imshow(image, interpolation=None)\n",
    "    plt.grid(None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image cropping\n",
    "def crop_image(images_list, nbPix = 100):\n",
    "    output_images = []\n",
    "    for image in images_list:\n",
    "        #Height adjustments\n",
    "        h = len(image)\n",
    "        adj = len(image) - nbPix\n",
    "        h1 = round(adj / 2) #Top\n",
    "        h2 = h - (adj - h1) #Bottom\n",
    "\n",
    "        #Width adjustments\n",
    "        w = len(image[0])\n",
    "        w_adj = w - nbPix\n",
    "        w1 = round(w_adj / 2) #Left\n",
    "        w2 = w - (w_adj - w1) #Right\n",
    "\n",
    "        img = image[h1:h2,w1:w2]\n",
    "        output_images.append(img)\n",
    "        \n",
    "    return np.array(output_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) IMPORT DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Declare file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#General file paths\n",
    "projectDir = os.getcwd() + \"/\"\n",
    "parentDir = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/\"\n",
    "dataPath = os.path.abspath(os.path.join(projectDir, os.pardir)) + \"/isic-2024-challenge/\"\n",
    "\n",
    "#Metadata file paths\n",
    "#metaPath = dataPath + \"train-metadata.csv\"\n",
    "metaPath = dataPath + \"sample-metadata.csv\"\n",
    "\n",
    "#Image file path\n",
    "#hdf5_file = dataPath + \"train-image.hdf5\"\n",
    "hdf5_file = dataPath + \"sample-image.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Load metadata from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- X_meta NA counts --\n",
      "isic_id                        0\n",
      "target                         0\n",
      "clin_size_long_diam_mm         0\n",
      "tbp_lv_areaMM2                 0\n",
      "tbp_lv_area_perim_ratio        0\n",
      "tbp_lv_eccentricity            0\n",
      "tbp_lv_minorAxisMM             0\n",
      "tbp_lv_color_std_mean          0\n",
      "tbp_lv_deltaLBnorm             0\n",
      "tbp_lv_radial_color_std_max    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Import metadata\n",
    "metadata = pd.read_csv(metaPath, sep=\",\")\n",
    "\n",
    "#METADATA: color and size features having no NAs\n",
    "metadata = metadata[[\"isic_id\",\n",
    "                     \"target\",\n",
    "                     \"clin_size_long_diam_mm\",\n",
    "                     \"tbp_lv_areaMM2\",\n",
    "                     \"tbp_lv_area_perim_ratio\",\n",
    "                     \"tbp_lv_eccentricity\",\n",
    "                     \"tbp_lv_minorAxisMM\",\n",
    "                     \"tbp_lv_color_std_mean\",\n",
    "                     \"tbp_lv_deltaLBnorm\",\n",
    "                     \"tbp_lv_radial_color_std_max\"]]\n",
    "\n",
    "#Verify that there are no NAs\n",
    "print(\"-- X_meta NA counts --\")\n",
    "print(metadata.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4a - Train, Validate, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform train-validate or train-test-validate split on a list of isic_ids\n",
    "def ttv_split(isic_ids, test_frac=0.2, validate_frac=0.2, random_state=88, shuffle=True, stratify=None):\n",
    "    if test_frac < 0 or validate_frac < 0:\n",
    "        print(\"ERROR: Test of validate fraction is negative\")\n",
    "        return None\n",
    "    if test_frac > 1 or validate_frac > 1:\n",
    "        print(\"ERROR: Test of validate fraction is above 0\")\n",
    "        return None\n",
    "    if test_frac + validate_frac >= 1:\n",
    "        print(\"ERROR: Test and validate fractions sum to 1 or more.\")\n",
    "        return None\n",
    "\n",
    "    #Split training from the rest\n",
    "    test_size = test_frac + validate_frac\n",
    "    train, temp = train_test_split(isic_ids, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "    #Split test and validate\n",
    "    if test_frac == 0 or validate_frac == 0:\n",
    "        return train.tolist(), temp.tolist()\n",
    "    else:\n",
    "        test_size = test_frac / (test_frac + validate_frac)\n",
    "        test, validate = train_test_split(temp, test_size = test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
    "        return train.tolist(), test.tolist(), validate.tolist()\n",
    "\n",
    "#Generate the splits of the isic_ids\n",
    "train_ids, test_ids, val_ids = ttv_split(metadata[\"isic_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Split train-test-validate portions of metadata into X and y\\ndef Xy_split(metadata, ids):\\n    #Generate X (features without target)\\n    \\n    X = metadata[metadata[\"isic_id\"].isin(ids)]\\n    X = X.loc[:, ~X.columns.isin([\\'isic_id\\', \\'target\\'])]\\n    #Generate y\\n    y = metadata[metadata[\"isic_id\"].isin(ids)][\"target\"]\\n    return X, y\\n\\nX_train, y_train = Xy_split(metadata, train_ids)\\nX_test, y_test = Xy_split(metadata, test_ids)\\nX_validate, y_validate = Xy_split(metadata, val_ids)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Split train-test-validate portions of metadata into X and y\n",
    "def Xy_split(metadata, ids):\n",
    "    #Generate X (features without target)\n",
    "    \n",
    "    X = metadata[metadata[\"isic_id\"].isin(ids)]\n",
    "    X = X.loc[:, ~X.columns.isin(['isic_id', 'target'])]\n",
    "    #Generate y\n",
    "    y = metadata[metadata[\"isic_id\"].isin(ids)][\"target\"]\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = Xy_split(metadata, train_ids)\n",
    "X_test, y_test = Xy_split(metadata, test_ids)\n",
    "X_validate, y_validate = Xy_split(metadata, val_ids)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4b - Data augmentation\n",
    "- Augment only the malignant data in the training set\n",
    "- Reformat all lists (train_ids, test_ids, val_ids) to be compatible: list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make list of ids compatible with data augmentations\n",
    "#Base data takes a value of 0, meaning it should not be modified\n",
    "train_ids_mods = [(id, 0) for id in train_ids]\n",
    "test_ids_mods = [(id, 0) for id in test_ids]\n",
    "val_ids_mods = [(id, 0) for id in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positives in training data: 36\n"
     ]
    }
   ],
   "source": [
    "#Identify the malignant cases in the training data\n",
    "all_pos = metadata[metadata[\"target\"]==1][\"isic_id\"]\n",
    "pos_in_train = all_pos[all_pos.isin(train_ids)]\n",
    "print(\"Number of positives in training data:\", len(pos_in_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ISIC_0104229', 0.23820295593020158),\n",
       " ('ISIC_6016458', 0),\n",
       " ('ISIC_9454701', 0.736650921942243),\n",
       " ('ISIC_9762220', 0.23820295593020158),\n",
       " ('ISIC_2023222', 0.23820295593020158),\n",
       " ('ISIC_7464445', 0.23820295593020158),\n",
       " ('ISIC_6269100', 0.736650921942243),\n",
       " ('ISIC_5609822', 0.736650921942243),\n",
       " ('ISIC_4027733', 0.23820295593020158),\n",
       " ('ISIC_6255931', 0),\n",
       " ('ISIC_3450877', 0.23820295593020158),\n",
       " ('ISIC_6448076', 0),\n",
       " ('ISIC_5609822', 0),\n",
       " ('ISIC_4567455', 0),\n",
       " ('ISIC_4114301', 0),\n",
       " ('ISIC_3472364', 0),\n",
       " ('ISIC_3156688', 0.23820295593020158),\n",
       " ('ISIC_6784337', 0.23820295593020158),\n",
       " ('ISIC_5609822', 0.23820295593020158),\n",
       " ('ISIC_7928246', 0.736650921942243),\n",
       " ('ISIC_5475654', 0),\n",
       " ('ISIC_4824767', 0),\n",
       " ('ISIC_3516326', 0),\n",
       " ('ISIC_1805261', 0),\n",
       " ('ISIC_2604412', 0.23820295593020158),\n",
       " ('ISIC_9762220', 0),\n",
       " ('ISIC_7928246', 0),\n",
       " ('ISIC_2439617', 0.23820295593020158),\n",
       " ('ISIC_0528190', 0),\n",
       " ('ISIC_4766910', 0),\n",
       " ('ISIC_7575093', 0.23820295593020158),\n",
       " ('ISIC_2604412', 0),\n",
       " ('ISIC_9972877', 0.23820295593020158),\n",
       " ('ISIC_3450877', 0),\n",
       " ('ISIC_7464445', 0.736650921942243),\n",
       " ('ISIC_2439617', 0),\n",
       " ('ISIC_8952587', 0.23820295593020158),\n",
       " ('ISIC_8591808', 0),\n",
       " ('ISIC_6784337', 0.736650921942243),\n",
       " ('ISIC_1111537', 0.736650921942243),\n",
       " ('ISIC_8644072', 0),\n",
       " ('ISIC_0682245', 0),\n",
       " ('ISIC_0528190', 0.23820295593020158),\n",
       " ('ISIC_7692477', 0),\n",
       " ('ISIC_2483649', 0),\n",
       " ('ISIC_1034966', 0.23820295593020158),\n",
       " ('ISIC_0104229', 0),\n",
       " ('ISIC_2031355', 0.23820295593020158),\n",
       " ('ISIC_9972877', 0.736650921942243),\n",
       " ('ISIC_2234813', 0),\n",
       " ('ISIC_5557065', 0),\n",
       " ('ISIC_0638180', 0.23820295593020158),\n",
       " ('ISIC_3289176', 0),\n",
       " ('ISIC_4027733', 0),\n",
       " ('ISIC_5078833', 0),\n",
       " ('ISIC_7748442', 0.23820295593020158),\n",
       " ('ISIC_3955107', 0.736650921942243),\n",
       " ('ISIC_2031355', 0),\n",
       " ('ISIC_9454701', 0),\n",
       " ('ISIC_0386460', 0.23820295593020158),\n",
       " ('ISIC_1805261', 0.736650921942243),\n",
       " ('ISIC_7464445', 0),\n",
       " ('ISIC_1001603', 0),\n",
       " ('ISIC_1034966', 0),\n",
       " ('ISIC_2023222', 0),\n",
       " ('ISIC_9060519', 0.23820295593020158),\n",
       " ('ISIC_7235721', 0.736650921942243),\n",
       " ('ISIC_6016458', 0.23820295593020158),\n",
       " ('ISIC_9972877', 0),\n",
       " ('ISIC_4218634', 0),\n",
       " ('ISIC_6016458', 0.736650921942243),\n",
       " ('ISIC_0528190', 0.736650921942243),\n",
       " ('ISIC_3175557', 0),\n",
       " ('ISIC_6665759', 0.736650921942243),\n",
       " ('ISIC_2346081', 0.736650921942243),\n",
       " ('ISIC_0386460', 0),\n",
       " ('ISIC_6269100', 0.23820295593020158),\n",
       " ('ISIC_5475654', 0.736650921942243),\n",
       " ('ISIC_8857626', 0),\n",
       " ('ISIC_5595794', 0),\n",
       " ('ISIC_6784337', 0),\n",
       " ('ISIC_7905844', 0),\n",
       " ('ISIC_7748442', 0),\n",
       " ('ISIC_9454701', 0.23820295593020158),\n",
       " ('ISIC_7655277', 0),\n",
       " ('ISIC_7797933', 0),\n",
       " ('ISIC_7748442', 0.736650921942243),\n",
       " ('ISIC_5350639', 0),\n",
       " ('ISIC_6148717', 0),\n",
       " ('ISIC_3955107', 0),\n",
       " ('ISIC_4027733', 0.736650921942243),\n",
       " ('ISIC_7575093', 0.736650921942243),\n",
       " ('ISIC_9060519', 0.736650921942243),\n",
       " ('ISIC_1805261', 0.23820295593020158),\n",
       " ('ISIC_2604412', 0.736650921942243),\n",
       " ('ISIC_0638180', 0),\n",
       " ('ISIC_8952587', 0),\n",
       " ('ISIC_7037308', 0),\n",
       " ('ISIC_3156688', 0),\n",
       " ('ISIC_1111537', 0.23820295593020158),\n",
       " ('ISIC_7318303', 0),\n",
       " ('ISIC_2401841', 0),\n",
       " ('ISIC_7655277', 0.736650921942243),\n",
       " ('ISIC_3869741', 0),\n",
       " ('ISIC_3156688', 0.736650921942243),\n",
       " ('ISIC_5993301', 0),\n",
       " ('ISIC_0157834', 0.736650921942243),\n",
       " ('ISIC_2346081', 0.23820295593020158),\n",
       " ('ISIC_6255931', 0.736650921942243),\n",
       " ('ISIC_2031355', 0.736650921942243),\n",
       " ('ISIC_6269100', 0),\n",
       " ('ISIC_6665759', 0.23820295593020158),\n",
       " ('ISIC_3955107', 0.23820295593020158),\n",
       " ('ISIC_8954977', 0),\n",
       " ('ISIC_7575093', 0),\n",
       " ('ISIC_6665759', 0),\n",
       " ('ISIC_0367166', 0),\n",
       " ('ISIC_5945837', 0),\n",
       " ('ISIC_9762220', 0.736650921942243),\n",
       " ('ISIC_0157834', 0),\n",
       " ('ISIC_5475654', 0.23820295593020158),\n",
       " ('ISIC_3450877', 0.736650921942243),\n",
       " ('ISIC_0104229', 0.736650921942243),\n",
       " ('ISIC_1111537', 0),\n",
       " ('ISIC_7235721', 0),\n",
       " ('ISIC_0386460', 0.736650921942243),\n",
       " ('ISIC_7928246', 0.23820295593020158),\n",
       " ('ISIC_8355368', 0),\n",
       " ('ISIC_8704966', 0),\n",
       " ('ISIC_0157834', 0.23820295593020158),\n",
       " ('ISIC_9060519', 0),\n",
       " ('ISIC_4883569', 0),\n",
       " ('ISIC_1034966', 0.736650921942243),\n",
       " ('ISIC_3985863', 0),\n",
       " ('ISIC_3368054', 0),\n",
       " ('ISIC_9007689', 0),\n",
       " ('ISIC_2023222', 0.736650921942243),\n",
       " ('ISIC_9084841', 0),\n",
       " ('ISIC_4114301', 0.736650921942243),\n",
       " ('ISIC_6255931', 0.23820295593020158),\n",
       " ('ISIC_9085828', 0),\n",
       " ('ISIC_2346081', 0),\n",
       " ('ISIC_6007750', 0),\n",
       " ('ISIC_7655277', 0.23820295593020158),\n",
       " ('ISIC_4114301', 0.23820295593020158),\n",
       " ('ISIC_6928210', 0),\n",
       " ('ISIC_7235721', 0.23820295593020158),\n",
       " ('ISIC_0638180', 0.736650921942243),\n",
       " ('ISIC_1528957', 0),\n",
       " ('ISIC_2439617', 0.736650921942243),\n",
       " ('ISIC_8952587', 0.736650921942243)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Augment the training list\n",
    "#Duplicates of ids will each have a different number, indicating a specific augmentation to be used\n",
    "nb_of_augments = 2\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "for i in range(nb_of_augments):\n",
    "    rand_nb = rng.random()\n",
    "    #Option 1: use random float between 0 and 1\n",
    "    train_ids_mods += [(id, rand_nb) for id in pos_in_train]\n",
    "    #Option 2: use integer\n",
    "    #train_ids_mods += [(id, nb_of_augments + 1) for id in pos_in_train]\n",
    "\n",
    "#Shuffle the list\n",
    "np.random.shuffle(train_ids_mods)\n",
    "train_ids_mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Load images and create hybrid tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATOR FOR HDF5 AND METADATA\n",
    "\"\"\"\n",
    "file = filepath to the hdf5 file containing the image data\n",
    "metadata = the full metadata dataframe (col1 = \"isic_id\", col2 = \"target\")\n",
    "img_names = list of tuples, each containing the isic_id followed by a number, signifying:\n",
    "            * 0 when original data is to be used\n",
    "            * random number - data augmentation is to be applied\n",
    "imgSize = images are to be adjusted to this size (square) in pixels\n",
    "\"\"\"\n",
    "class hdf5_generator:\n",
    "    def __init__(self, file, metadata, img_names, imgSize):\n",
    "        self.file = file\n",
    "        self.metadata = metadata\n",
    "        self.img_names = img_names\n",
    "        self.imgSize = imgSize\n",
    "\n",
    "    def __call__(self):\n",
    "        with h5py.File(self.file, 'r') as h5file:\n",
    "            for img_name_tuple in self.img_names:\n",
    "                img_name, mod = img_name_tuple\n",
    "                try:\n",
    "                    # Load image data from HDF5\n",
    "                    img = np.array(Image.open(io.BytesIO(h5file[img_name][()])))\n",
    "                    \n",
    "                    # Resize the image\n",
    "                    img = tf.image.resize(img, [self.imgSize, self.imgSize])\n",
    "                    \n",
    "                    if mod != 0:\n",
    "                        # Data Augmentation \n",
    "                        img = tf.image.random_flip_left_right(img)\n",
    "                        img = tf.image.random_flip_up_down(img)\n",
    "                        img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "\n",
    "                    # Standardize and return as TensorFlow constant\n",
    "                    img = tf.constant(img / 255, dtype=tf.float32)  # Standardize here\n",
    "\n",
    "                    #Retrieve corresponding metadata\n",
    "                    meta = self.metadata[self.metadata[\"isic_id\"] == img_name].iloc[:,2:]\n",
    "\n",
    "                    #Retrieve corresponding target\n",
    "                    target = self.metadata[self.metadata[\"isic_id\"] == img_name][\"target\"]\n",
    "                    target = np.reshape(target, (1, 1))\n",
    "                    \n",
    "                    yield (img, meta), target\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {img_name}: {e}\")\n",
    "                    # log the error to a file for later analysis\n",
    "                    with open('image_errors.log', 'a') as f:\n",
    "                        f.write(f\"Error loading image {img_name}: {e}\\n\")\n",
    "                    continue\n",
    "\n",
    "#Generate the dataset with batch size and prefetching\n",
    "def make_dataset(hdf5_file, metadata, img_names, imgSize=100, batch_size=32):\n",
    "   \n",
    "    # Get the number of metadata features (isic_id and target are present, so subtract)\n",
    "    num_features = metadata.shape[-1] - 2\n",
    "    \n",
    "    # Generate image dataset\n",
    "    element_spec = ((tf.TensorSpec(shape=(imgSize, imgSize, 3), dtype=tf.float32),\n",
    "                 tf.TensorSpec(shape=(1, num_features), dtype=tf.float32)),\n",
    "                tf.TensorSpec(shape=(1, 1), dtype=tf.int32))\n",
    "    \n",
    "    img_dataset = tf.data.Dataset.from_generator(\n",
    "        hdf5_generator(hdf5_file, metadata, img_names, imgSize),\n",
    "        output_signature=element_spec\n",
    "    )\n",
    "\n",
    "    # Add shuffling, batching, and prefetching\n",
    "    dataset = img_dataset.shuffle(buffer_size=min(len(img_names), 10000)).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make datasets\n",
    "train_dataset = make_dataset(hdf5_file, metadata, train_ids_mods)\n",
    "validate_dataset = make_dataset(hdf5_file, metadata, val_ids_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 8), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 1, 1), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=((TensorSpec(shape=(None, 100, 100, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 8), dtype=tf.float32, name=None)), TensorSpec(shape=(None, 1, 1), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) CNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple CNN model using only images and target\n",
    "class CNN_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_image, x_meta = inputs\n",
    "\n",
    "        # Convolutions\n",
    "        x1 = self.conv1(x_image)\n",
    "        x1 = self.pool1(x1)\n",
    "\n",
    "        # Flattening of images for input layer\n",
    "        x1 = self.flatten(x1)\n",
    "\n",
    "        # Hidden layers of neural network\n",
    "        x1 = self.dense1(x1)\n",
    "\n",
    "        # Output layer of neural network\n",
    "        output = self.dense2(x1)\n",
    "\n",
    "        return output\n",
    "\n",
    "#Hybrid CNN model taking metadata\n",
    "class Hybrid_model(tf.keras.Model):\n",
    "    def __init__(self, neurons = 8, activ = 'tanh'):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), activation='relu', padding='same', input_shape=(100, 100, 3))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, 5, activation='relu')\n",
    "        self.pool = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense2 = tf.keras.layers.Dense(neurons, activation = activ)\n",
    "        self.dense3 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        #self.dropout = tf.keras.layers.dropout(0.25)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x_image, x_meta = inputs\n",
    "        # Convolutions\n",
    "        x = self.conv1(x_image)\n",
    "        x = self.pool(x)\n",
    "        #x = self.conv2(x)\n",
    "        #x = self.pool(x)\n",
    "        # Flattening of images and concatenation with other data\n",
    "        x = self.flatten(x)\n",
    "        # Reshape metadata to match dimensions\n",
    "        x_meta = tf.reshape(x_meta, (tf.shape(x_meta)[0], 8))\n",
    "        #x_all = tf.concat([x,x_meta], axis=1)\n",
    "        x_all = keras.layers.Concatenate(axis=1)([x, x_meta])\n",
    "        # Neural Network\n",
    "        x_all = self.dense1(x_all)\n",
    "        #x_all = self.dense2(x_all)\n",
    "        #if training:\n",
    "        #    x_all = self.dropout(x_all, training=training)\n",
    "        output = self.dense3(x_all)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Model compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Set seed\n",
    "tf.random.set_seed(71)\n",
    "\n",
    "#Initialize model\n",
    "#model = CNN_model(neurons=8, activ='tanh')\n",
    "model = Hybrid_model(neurons=8, activ='tanh')\n",
    "\n",
    "#Define optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True,\n",
    "                                          label_smoothing=0.0,\n",
    "                                          axis=-1,\n",
    "                                          reduction='sum_over_batch_size',\n",
    "                                          name='binary_crossentropy')\n",
    "\n",
    "#Compile the model with loss, optimizer, and metrics\n",
    "model.compile(loss = loss,\n",
    "              optimizer = optimizer,\n",
    "              metrics = [\n",
    "                  tf.keras.metrics.BinaryAccuracy(),\n",
    "                  tf.keras.metrics.FalseNegatives(),\n",
    "                  tf.keras.metrics.FalsePositives(),\n",
    "                  tf.keras.metrics.TrueNegatives(),\n",
    "                  tf.keras.metrics.TruePositives()\n",
    "                  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (32, 100, 100, 3)\n",
      "Metadata batch shape: (32, 1, 8)\n",
      "Target batch shape: (32, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 12:09:47.540942: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches in the dataset: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-19 12:09:48.386420: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Take 1 batch from the dataset and check its content\n",
    "for batch in train_dataset.take(1):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the individual components\n",
    "    print(f\"Image batch shape: {img_batch.shape}\")\n",
    "    print(f\"Metadata batch shape: {meta_batch.shape}\")\n",
    "    print(f\"Target batch shape: {target_batch.shape}\")\n",
    "\n",
    "# To count the total number of batches\n",
    "batch_count = 0\n",
    "for _ in train_dataset:\n",
    "    batch_count += 1\n",
    "\n",
    "print(f\"Total number of batches in the dataset: {batch_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - binary_accuracy: 0.7102 - false_negatives: 0.0000e+00 - false_positives: 29.6667 - loss: 0.6021 - true_negatives: 0.0000e+00 - true_positives: 74.0000 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8045 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awieber/miniconda3/envs/ISIC24_skin_cancer/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - binary_accuracy: 0.7150 - false_negatives: 0.0000e+00 - false_positives: 28.8333 - loss: 0.5980 - true_negatives: 0.0000e+00 - true_positives: 74.8333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8081 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - binary_accuracy: 0.7393 - false_negatives: 0.0000e+00 - false_positives: 28.5000 - loss: 0.5760 - true_negatives: 0.0000e+00 - true_positives: 75.1667 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8105 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - binary_accuracy: 0.7011 - false_negatives: 0.0000e+00 - false_positives: 30.6667 - loss: 0.6105 - true_negatives: 0.0000e+00 - true_positives: 73.0000 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8081 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - binary_accuracy: 0.7145 - false_negatives: 0.0000e+00 - false_positives: 29.1667 - loss: 0.5983 - true_negatives: 0.0000e+00 - true_positives: 74.5000 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8141 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - binary_accuracy: 0.7328 - false_negatives: 0.0000e+00 - false_positives: 28.3333 - loss: 0.5812 - true_negatives: 0.0000e+00 - true_positives: 75.3333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8179 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - binary_accuracy: 0.7041 - false_negatives: 0.0000e+00 - false_positives: 30.3333 - loss: 0.6080 - true_negatives: 0.0000e+00 - true_positives: 73.3333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8113 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - binary_accuracy: 0.6881 - false_negatives: 0.0000e+00 - false_positives: 31.5000 - loss: 0.6226 - true_negatives: 0.0000e+00 - true_positives: 72.1667 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8072 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - binary_accuracy: 0.7384 - false_negatives: 0.0000e+00 - false_positives: 28.3333 - loss: 0.5771 - true_negatives: 0.0000e+00 - true_positives: 75.3333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8176 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 99ms/step - binary_accuracy: 0.7228 - false_negatives: 0.0000e+00 - false_positives: 29.3333 - loss: 0.5906 - true_negatives: 0.0000e+00 - true_positives: 74.3333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8180 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - binary_accuracy: 0.7297 - false_negatives: 0.0000e+00 - false_positives: 28.5000 - loss: 0.5838 - true_negatives: 0.0000e+00 - true_positives: 75.1667 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8178 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - binary_accuracy: 0.7267 - false_negatives: 0.0000e+00 - false_positives: 28.5000 - loss: 0.5867 - true_negatives: 0.0000e+00 - true_positives: 75.1667 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8132 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - binary_accuracy: 0.7501 - false_negatives: 0.0000e+00 - false_positives: 27.1667 - loss: 0.5655 - true_negatives: 0.0000e+00 - true_positives: 76.5000 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8121 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - binary_accuracy: 0.6950 - false_negatives: 0.0000e+00 - false_positives: 30.1667 - loss: 0.6168 - true_negatives: 0.0000e+00 - true_positives: 73.5000 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.7996 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - binary_accuracy: 0.7037 - false_negatives: 0.0000e+00 - false_positives: 30.1667 - loss: 0.6079 - true_negatives: 0.0000e+00 - true_positives: 73.5000 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.7956 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - binary_accuracy: 0.7119 - false_negatives: 0.0000e+00 - false_positives: 29.8333 - loss: 0.6007 - true_negatives: 0.0000e+00 - true_positives: 73.8333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8008 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - binary_accuracy: 0.7375 - false_negatives: 0.0000e+00 - false_positives: 28.0000 - loss: 0.5785 - true_negatives: 0.0000e+00 - true_positives: 75.6667 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8143 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - binary_accuracy: 0.6737 - false_negatives: 0.0000e+00 - false_positives: 32.3333 - loss: 0.6365 - true_negatives: 0.0000e+00 - true_positives: 71.3333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8067 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - binary_accuracy: 0.7310 - false_negatives: 0.0000e+00 - false_positives: 29.0000 - loss: 0.5838 - true_negatives: 0.0000e+00 - true_positives: 74.6667 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8174 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - binary_accuracy: 0.7067 - false_negatives: 0.0000e+00 - false_positives: 29.8333 - loss: 0.6055 - true_negatives: 0.0000e+00 - true_positives: 73.8333 - val_binary_accuracy: 0.4815 - val_false_negatives: 0.0000e+00 - val_false_positives: 14.0000 - val_loss: 0.8199 - val_true_negatives: 0.0000e+00 - val_true_positives: 13.0000\n"
     ]
    }
   ],
   "source": [
    "mod = model.fit(train_dataset, epochs=20, validation_data=validate_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_accuracy': [0.695364236831665,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878,\n",
       "  0.7152317762374878],\n",
       " 'false_negatives': [16.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'false_positives': [30.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  43.0],\n",
       " 'loss': [0.6219391226768494,\n",
       "  0.644404947757721,\n",
       "  0.699401319026947,\n",
       "  0.6613954305648804,\n",
       "  0.6257321834564209,\n",
       "  0.6011008620262146,\n",
       "  0.5987812280654907,\n",
       "  0.6016252040863037,\n",
       "  0.7412620186805725,\n",
       "  0.7371280789375305,\n",
       "  0.6816633939743042,\n",
       "  0.6229310035705566,\n",
       "  0.6030370593070984,\n",
       "  0.5999707579612732,\n",
       "  0.6021730303764343,\n",
       "  0.6038586497306824,\n",
       "  0.6003897786140442,\n",
       "  0.598908007144928,\n",
       "  0.5971395969390869,\n",
       "  0.5975100994110107],\n",
       " 'true_negatives': [13.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'true_positives': [92.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0,\n",
       "  108.0],\n",
       " 'val_binary_accuracy': [0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866,\n",
       "  0.48148149251937866],\n",
       " 'val_false_negatives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_false_positives': [14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0,\n",
       "  14.0],\n",
       " 'val_loss': [0.7378630042076111,\n",
       "  1.19057297706604,\n",
       "  1.1217427253723145,\n",
       "  1.007880687713623,\n",
       "  0.8955255150794983,\n",
       "  0.8176999092102051,\n",
       "  0.7759072184562683,\n",
       "  0.7634230852127075,\n",
       "  1.2951066493988037,\n",
       "  1.169586420059204,\n",
       "  1.0181523561477661,\n",
       "  0.9006890058517456,\n",
       "  0.8142305016517639,\n",
       "  0.7707276940345764,\n",
       "  0.7628635764122009,\n",
       "  0.7745689153671265,\n",
       "  0.7829046845436096,\n",
       "  0.8022822737693787,\n",
       "  0.8138150572776794,\n",
       "  0.8230421543121338],\n",
       " 'val_true_negatives': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_true_positives': [13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0,\n",
       "  13.0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BATCHES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Image Batch Shape: (32, 100, 100, 3)\n",
      "  Metadata Batch Shape: (32, 1, 8)\n",
      "  Target Batch Shape: (32, 1, 1)\n",
      "Batch 2:\n",
      "  Image Batch Shape: (32, 100, 100, 3)\n",
      "  Metadata Batch Shape: (32, 1, 8)\n",
      "  Target Batch Shape: (32, 1, 1)\n",
      "Batch 3:\n",
      "  Image Batch Shape: (32, 100, 100, 3)\n",
      "  Metadata Batch Shape: (32, 1, 8)\n",
      "  Target Batch Shape: (32, 1, 1)\n",
      "Batch 4:\n",
      "  Image Batch Shape: (32, 100, 100, 3)\n",
      "  Metadata Batch Shape: (32, 1, 8)\n",
      "  Target Batch Shape: (32, 1, 1)\n",
      "Batch 5:\n",
      "  Image Batch Shape: (23, 100, 100, 3)\n",
      "  Metadata Batch Shape: (23, 1, 8)\n",
      "  Target Batch Shape: (23, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all batches in the dataset and print their shapes\n",
    "for i, batch in enumerate(train_dataset):\n",
    "    (img_batch, meta_batch), target_batch = batch\n",
    "    \n",
    "    # Print the shapes of the current batch\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"  Image Batch Shape:\", img_batch.shape)\n",
    "    print(\"  Metadata Batch Shape:\", meta_batch.shape)\n",
    "    print(\"  Target Batch Shape:\", target_batch.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_env",
   "language": "python",
   "name": "deep_learning_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

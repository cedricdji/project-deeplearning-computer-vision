name: SageMaker Notebook Deployment with Terraform Setup

on:
  push:
    branches:
      - ingeneurie

jobs:
  setup_infrastructure:
    name: Setup S3 Buckets with Terraform
    runs-on: ubuntu-latest

    steps:
    - name: Checkout the code
      uses: actions/checkout@v3
    # Récupère le code du dépôt GitHub pour l'exécution du workflow.

    - name: Setup AWS Credentials
      uses: aws-actions/configure-aws-credentials@v2
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
        aws-session-token : ${{ secrets.AWS_SESSION_TOKEN }}
    # Configure les identifiants AWS pour que les actions GitHub puissent interagir avec les services AWS.

    - name: Ensure Backend Bucket Exists
      run: |
        if ! aws s3 ls "s3://backend-terraform-a23dsti-deep-learning-project" > /dev/null 2>&1; then
          aws s3 mb s3://backend-terraform-a23dsti-deep-learning-project --region ${{ secrets.AWS_REGION }}
          echo "Backend bucket créé."
        else
          echo "Backend bucket déjà existant."
        fi
    # Vérifie l'existence du bucket backend pour Terraform. Si le bucket n'existe pas, il est créé avant d’initialiser Terraform.

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
    # Installe Terraform dans l'environnement GitHub Actions.

    - name: Terraform Init
      run: terraform init -input=false -backend-config="bucket=backend-terraform-a23dsti-deep-learning-project"
      working-directory: terraform/
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}

    # Initialise Terraform avec le backend S3. Ce backend enregistre l'état Terraform dans le bucket `backend-terraform-a23dsti-deep-learning-project`.

    - name: Terraform Apply
      run: terraform apply -auto-approve
      working-directory: terraform/
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}

    # Exécute Terraform pour créer les ressources spécifiées dans le fichier `main.tf`, en utilisant `-auto-approve` pour ignorer la confirmation manuelle.

  deploy_sagemaker:
    name: Deploy and Execute SageMaker Notebook
    runs-on: ubuntu-latest
    needs: setup_infrastructure

    steps:
    - name: Checkout the code
      uses: actions/checkout@v3
    # Récupère le code du dépôt GitHub pour l'exécution du workflow.

    - name: Setup AWS Credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ secrets.AWS_REGION }}
        aws-session-token : ${{ secrets.AWS_SESSION_TOKEN }}

    # Configure les identifiants AWS pour que les actions GitHub puissent interagir avec les services AWS.

    - name: Copy Model and Requirements to S3
      run: |
        aws s3 cp Model.ipynb s3://images-projet-deep-learning/Model.ipynb
        aws s3 cp requirements.txt s3://images-projet-deep-learning/requirements.txt
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}

    # Copie le modèle (`Model.ipynb`) et `requirements.txt` dans le bucket S3 `images-projet-deep-learning`.

    - name: Launch SageMaker Notebook
      run: |
        import boto3

        client = boto3.client('sagemaker')
        notebook_instance_name = "deep-learning-notebook-instance"

        # Création du Notebook SageMaker avec le rôle défini dans AWS_ROLE
        client.create_notebook_instance(
          NotebookInstanceName=notebook_instance_name,
          InstanceType='ml.t2.medium',
          RoleArn='arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/${{ secrets.AWS_ROLE }}',
          DirectInternetAccess='Enabled',
          RootAccess='Enabled',
          VolumeSizeInGB=10,
        )

        # Attendre que le notebook soit prêt
        waiter = client.get_waiter('notebook_instance_in_service')
        waiter.wait(NotebookInstanceName=notebook_instance_name)

        # Exécuter le notebook
        client.start_notebook_instance(NotebookInstanceName=notebook_instance_name)
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}

    # Lance une instance SageMaker Notebook en utilisant le rôle IAM spécifié dans `AWS_ROLE`, et attend qu'elle soit prête pour exécuter le modèle.

    - name: Download Model and Requirements in SageMaker Notebook
      run: |
        import boto3
        import os

        s3 = boto3.client('s3')
        local_path = '/home/ec2-user/SageMaker'

        if not os.path.exists(local_path):
            os.makedirs(local_path)

        s3.download_file('images-projet-deep-learning', 'Model.ipynb', os.path.join(local_path, 'Model.ipynb'))
        s3.download_file('images-projet-deep-learning', 'requirements.txt', os.path.join(local_path, 'requirements.txt'))

        print("Modèle et fichier requirements.txt téléchargés avec succès dans le répertoire du notebook.")
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_REGION: ${{ secrets.AWS_REGION }}
        AWS_SESSION_TOKEN: ${{ secrets.AWS_SESSION_TOKEN }}

    # Télécharge le modèle et `requirements.txt` dans le répertoire de travail du notebook SageMaker, pour qu’ils soient disponibles localement lors de l'exécution.

    - name: Monitor SageMaker Notebook Execution
      run: |
        python - <<EOF
        import boto3
        import time

        logs_client = boto3.client('logs')
        notebook_instance_name = "deep-learning-notebook-instance"
        log_group_name = f'/aws/sagemaker/NotebookInstances/{notebook_instance_name}'

        print(f"Suivi des logs pour {notebook_instance_name}...")

        while True:
            log_streams = logs_client.describe_log_streams(
                logGroupName=log_group_name,
                orderBy='LastEventTime',
                descending=True,
                limit=1
            )

            if log_streams['logStreams']:
                log_stream_name = log_streams['logStreams'][0]['logStreamName']
                log_events = logs_client.get_log_events(
                    logGroupName=log_group_name,
                    logStreamName=log_stream_name,
                    startFromHead=True
                )
                for event in log_events['events']:
                    print(event['message'])
            else:
                print("Aucun log trouvé pour le moment. En attente...")

            time.sleep(10)
        EOF
    # Surveille les logs CloudWatch du notebook pour suivre l'exécution du modèle en temps réel.

    - name: Stop and Clean Up SageMaker Notebook
      run: |
        client = boto3.client('sagemaker')
        notebook_instance_name = "deep-learning-notebook-instance"
        
        client.stop_notebook_instance(NotebookInstanceName=notebook_instance_name)
        client.delete_notebook_instance(NotebookInstanceName=notebook_instance_name)
    # Arrête et supprime l’instance de notebook SageMaker pour libérer les ressources après l'exécution du modèle.
